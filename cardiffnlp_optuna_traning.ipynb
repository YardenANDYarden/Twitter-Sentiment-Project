{"cells":[{"cell_type":"markdown","metadata":{"id":"rbqCksYh25QU"},"source":["Installs:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8698,"status":"ok","timestamp":1754831416412,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"tL3neiaDq5ua","outputId":"4f8e4f62-a6b3-4754-9b5c-515a8f1f6f41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n","Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.14.1\n","Collecting optuna\n","  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.42)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n","Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"]}],"source":["! pip install emoji\n","! pip install optuna"]},{"cell_type":"markdown","metadata":{"id":"1xMDrxSX28_M"},"source":["Imports:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92333,"status":"ok","timestamp":1754831508752,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"Upn8WneUSktr","outputId":"10bf8fa1-cac6-4a9b-f660-23efefba712b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","# HuggingFace Transformers\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n","\n","\n","# Sklearn tools\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, accuracy_score, precision_recall_fscore_support\n","\n","# Data and preprocessing\n","import pandas as pd\n","import numpy as np\n","import re\n","import html\n","import emoji\n","\n","\n","# Optimization & logging\n","import optuna\n","import wandb\n","\n","#collab\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10961,"status":"ok","timestamp":1754831519715,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"HWdtEUMIR03Q","outputId":"b4e55fc8-1e6d-49d3-f5c4-c2950b7e572d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n","Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.0.2)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.2.2)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.32.3)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (5.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2025.8.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.7)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n","Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}],"source":["# Install required packages\n","!pip install nlpaug transformers\n","\n","import nlpaug.augmenter.word as naw\n","import random\n","from tqdm import tqdm\n","import os\n","os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Avoid tokenizer warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"executionInfo":{"elapsed":14884,"status":"ok","timestamp":1754831534601,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"k-z_gGWASkrm","outputId":"95ffb996-e93c-4969-a2e3-c07e3bfa956e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myardenr1\u001b[0m (\u001b[33myardenr1-tel-aviv-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["# Check if GPU is available and select device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"90zqu7yr3Ejd"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"6P90Vhh0bmyP"},"source":["f423cfbdb50d571d7922fe745356685617100809"]},{"cell_type":"markdown","metadata":{"id":"FbsE_taI3BnF"},"source":["Load data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaVf77pgSkpO"},"outputs":[],"source":["# === Load data ===\n","train_df = pd.read_csv('/content/drive/MyDrive/deep_learning/train_processed.csv', encoding='latin1')\n","eval_df = pd.read_csv('/content/drive/MyDrive/deep_learning/val_processed.csv', encoding='latin1')\n","test_df = pd.read_csv('/content/drive/MyDrive/deep_learning/test_processed.csv', encoding='latin1')\n","\n","# Create label mappings\n","ordered_labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']\n","label2id = {label: i for i, label in enumerate(ordered_labels)}\n","id2label = {i: label for label, i in label2id.items()}\n","\n","train_df[\"label\"] = train_df[\"Sentiment\"].map(label2id)\n","eval_df[\"label\"] = eval_df[\"Sentiment\"].map(label2id)\n","test_df[\"label\"] = test_df[\"Sentiment\"].map(label2id)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1754638312257,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"UInGnzisSknK","outputId":"21784b87-e2fb-4e03-e725-e8522c05d38a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                                                                                                                                                                                                                                           ProcessedTweet  \\\n","17977                                             new survey by user finds that only 2% of #consumers think #brands should pause all #advertising; 49% want #ads to make them feel informed and 37% want ads to make them feel warm/happy #digitalmarketing #covid #consumerbehavior http   \n","31793                                                         some #costco stores say their prohibiting people from returning #toiletpaper. who returns toilet paper? probably the same people who think their rectums go into remission? #trending #covid user #jimmy #kimmel #for #real   \n","8808                                                                                         after increasing the prices of platform tickets, the indian railways withdrew most concessional ticket facilities in trains as a precautionary measure to contain the spread of #covid. http   \n","23027                                                           user money hdelacerda. oil prices caused a massive slow down and now the covid 19 has caused layoffs, i havent worked since the beginning of february just trying to make sure my wife and 2 daughters are taken care of.   \n","6409                                                                                                                                                                     my wife just messaged me to say the supermarket shelves were empty. i know what's for dinner tonight #covid http   \n","28137                                                                        i nominate the global coronavirus responders for the 2020 time magazines person of the year: (including nurses, paramedics, doctors, hospital admin and cleaning staff, grocery store employees, etc) #covid   \n","22277  wed like to take a moment to thank all of the grocery store personnel, cleaners, maintenance workers, truck drivers and warehouse workers for their perseverance and commitment. we are incredibly grateful to those who are making sacrifices to support the covid 19 fight. http   \n","21206                                                 this is too much! no fizzy san pelegrno water for my wine spritzer or houmous! what in gods name do you expect the middle classes to do! to die like dinosaurs! #covid #stay #home #24 #in #48 #stockpiling #uk #toiletpaper #covid   \n","15208                                                                                                                                                      ? money cag money gis money k money ko consumer brands association ceo on the state of global supply chains amid covid 19 http   \n","28598                                                                breaking: govt. has announced good news for shoppers who have been battling to buy essential products at inflated prices. retailers on the naughty list could face hefty fines or even prison sentences. #covid http   \n","\n","                Sentiment  label  \n","17977  Extremely Positive      4  \n","31793             Neutral      2  \n","8808              Neutral      2  \n","23027  Extremely Positive      4  \n","6409             Negative      1  \n","28137             Neutral      2  \n","22277  Extremely Positive      4  \n","21206  Extremely Negative      0  \n","15208             Neutral      2  \n","28598            Negative      1  "],"text/html":["\n","  <div id=\"df-bd477888-7d42-49ab-961a-e5562d4cf51d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ProcessedTweet</th>\n","      <th>Sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17977</th>\n","      <td>new survey by user finds that only 2% of #consumers think #brands should pause all #advertising; 49% want #ads to make them feel informed and 37% want ads to make them feel warm/happy #digitalmarketing #covid #consumerbehavior http</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>31793</th>\n","      <td>some #costco stores say their prohibiting people from returning #toiletpaper. who returns toilet paper? probably the same people who think their rectums go into remission? #trending #covid user #jimmy #kimmel #for #real</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8808</th>\n","      <td>after increasing the prices of platform tickets, the indian railways withdrew most concessional ticket facilities in trains as a precautionary measure to contain the spread of #covid. http</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>23027</th>\n","      <td>user money hdelacerda. oil prices caused a massive slow down and now the covid 19 has caused layoffs, i havent worked since the beginning of february just trying to make sure my wife and 2 daughters are taken care of.</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6409</th>\n","      <td>my wife just messaged me to say the supermarket shelves were empty. i know what's for dinner tonight #covid http</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>28137</th>\n","      <td>i nominate the global coronavirus responders for the 2020 time magazines person of the year: (including nurses, paramedics, doctors, hospital admin and cleaning staff, grocery store employees, etc) #covid</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>22277</th>\n","      <td>wed like to take a moment to thank all of the grocery store personnel, cleaners, maintenance workers, truck drivers and warehouse workers for their perseverance and commitment. we are incredibly grateful to those who are making sacrifices to support the covid 19 fight. http</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>21206</th>\n","      <td>this is too much! no fizzy san pelegrno water for my wine spritzer or houmous! what in gods name do you expect the middle classes to do! to die like dinosaurs! #covid #stay #home #24 #in #48 #stockpiling #uk #toiletpaper #covid</td>\n","      <td>Extremely Negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15208</th>\n","      <td>? money cag money gis money k money ko consumer brands association ceo on the state of global supply chains amid covid 19 http</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>28598</th>\n","      <td>breaking: govt. has announced good news for shoppers who have been battling to buy essential products at inflated prices. retailers on the naughty list could face hefty fines or even prison sentences. #covid http</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd477888-7d42-49ab-961a-e5562d4cf51d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bd477888-7d42-49ab-961a-e5562d4cf51d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bd477888-7d42-49ab-961a-e5562d4cf51d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-38e241df-cd9c-45aa-b263-0ed8f028e60f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38e241df-cd9c-45aa-b263-0ed8f028e60f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-38e241df-cd9c-45aa-b263-0ed8f028e60f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_0b13c8c2-a2c5-4a3b-a9f5-2edf6b781384\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0b13c8c2-a2c5-4a3b-a9f5-2edf6b781384 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('sample');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"sample","summary":"{\n  \"name\": \"sample\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"ProcessedTweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"? money cag money gis money k money ko consumer brands association ceo on the state of global supply chains amid covid 19 http\",\n          \"some #costco stores say their prohibiting people from returning #toiletpaper. who returns toilet paper? probably the same people who think their rectums go into remission? #trending #covid user #jimmy #kimmel #for #real\",\n          \"i nominate the global coronavirus responders for the 2020 time magazines person of the year: (including nurses, paramedics, doctors, hospital admin and cleaning staff, grocery store employees, etc) #covid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Neutral\",\n          \"Extremely Negative\",\n          \"Extremely Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["# Display\n","pd.set_option('display.max_colwidth', None)  # so full text is shown\n","sample = train_df[['ProcessedTweet','Sentiment','label']].sample(10, random_state=24)\n","display(sample)"]},{"cell_type":"markdown","metadata":{"id":"GKKTj0S_ZVhx"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"UjYFLRBE3LMy"},"source":["Dataset class:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bKOtm18SkWw"},"outputs":[],"source":["class CoronaTweetDataset(Dataset):\n","    \"\"\"\n","    Dataset class for loading COVID-19 tweets for sentiment classification.\n","    Compatible with HuggingFace transformers and PyTorch.\n","    \"\"\"\n","    def __init__(self, dataframe, tokenizer):\n","        self.texts = dataframe['ProcessedTweet'].tolist()  # Cleaned tweets\n","        self.labels = dataframe['label'].tolist()          # Encoded sentiment labels\n","        self.tokenizer = tokenizer                         # Tokenizer for the model\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","\n","        # Tokenize input text with padding and truncation\n","        encoding = self.tokenizer(\n","            text,\n","            padding='max_length',\n","            truncation=True,\n","            max_length=128,       # 128 is enough for tweets\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(),             # Tensor of token IDs\n","            'attention_mask': encoding['attention_mask'].squeeze(),   # Tensor mask\n","            'labels': torch.tensor(label, dtype=torch.long)           # Ground truth label\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"AWO3AWnK3OIE"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Nb5V7Hiu3N7l"},"source":["Traning:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ltMmojfVOh9"},"outputs":[],"source":["def early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, current_val_accuracy, current_val_accuracy_epoch):\n","    early_stop_flag = False\n","    if current_val_accuracy > best_val_accuracy:\n","        best_val_accuracy = current_val_accuracy\n","        best_val_accuracy_epoch = current_val_accuracy_epoch\n","    else:\n","        if current_val_accuracy_epoch - best_val_accuracy_epoch > patience:\n","            early_stop_flag = True\n","    return best_val_accuracy, best_val_accuracy_epoch, early_stop_flag"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_GylT0ccr1Vv"},"outputs":[],"source":["# ============ UPDATED TRAINING FUNCTION WITH GRADIENT CLIPPING ============\n","def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial, gradient_clip_val=None):\n","    \"\"\"\n","    Updated training function with gradient clipping and enhanced monitoring\n","    \"\"\"\n","    best_val_accuracy = 0.0\n","    best_val_accuracy_epoch = 0\n","    early_stop_flag = False\n","    best_model_state = None\n","\n","    for epoch in range(1, epochs + 1):\n","        # Training phase\n","        model.train()\n","        train_loss = 0.0\n","        total_train_samples = 0\n","        correct_train_predictions = 0\n","\n","        for batch in train_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            loss = criterion(logits, labels)\n","\n","            loss.backward()\n","\n","            # NEW: Gradient Clipping\n","            if gradient_clip_val is not None:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n","\n","            optimizer.step()\n","\n","            # Accumulate training metrics\n","            train_loss += loss.item() * input_ids.size(0)\n","            total_train_samples += input_ids.size(0)\n","            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n","\n","        train_loss /= total_train_samples\n","        train_accuracy = correct_train_predictions / total_train_samples\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0.0\n","        total_val_samples = 0\n","        correct_val_predictions = 0\n","        all_val_labels = []\n","        all_val_preds = []\n","\n","        with torch.no_grad():\n","            for batch in val_loader:\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                labels = batch['labels'].to(device)\n","\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                logits = outputs.logits\n","                loss = criterion(logits, labels)\n","\n","                val_loss += loss.item() * input_ids.size(0)\n","                total_val_samples += input_ids.size(0)\n","                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n","\n","                all_val_labels.extend(labels.cpu().numpy())\n","                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","\n","        # Calculate per-class metrics\n","        class_names = ['Extremely Negative', 'Extremely Positive', 'Negative','Neutral','Positive']\n","        precisions, recalls, f1s, _ = precision_recall_fscore_support( all_val_labels, all_val_preds, average=None, labels=[0, 1, 2, 3, 4], zero_division=0)\n","\n","        # Log per-class metrics to wandb\n","        for i, class_name in enumerate(class_names):\n","            wandb.log({\n","                f\"Class_{class_name}_Precision\": precisions[i] if i < len(precisions) else 0.0,\n","                f\"Class_{class_name}_Recall\": recalls[i] if i < len(recalls) else 0.0,\n","                f\"Class_{class_name}_F1\": f1s[i] if i < len(f1s) else 0.0\n","            })\n","\n","        # Calculate overall metrics\n","        val_loss /= total_val_samples\n","        val_accuracy = correct_val_predictions / total_val_samples\n","        val_precision = precision_score(all_val_labels, all_val_preds, average='macro', zero_division=0)\n","        val_recall = recall_score(all_val_labels, all_val_preds, average='macro', zero_division=0)\n","        val_f1 = f1_score(all_val_labels, all_val_preds, average='macro', zero_division=0)\n","\n","        # Early stopping check\n","        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check(\n","            patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch\n","        )\n","\n","        # Save best model\n","        if val_accuracy == best_val_accuracy:\n","            best_model_state = model.state_dict()\n","\n","        # Log metrics to wandb\n","        wandb.log({\n","            \"Epoch\": epoch,\n","            \"Train Loss\": train_loss,\n","            \"Train Accuracy\": train_accuracy,\n","            \"Validation Loss\": val_loss,\n","            \"Validation Accuracy\": val_accuracy,\n","            \"Validation Precision\": val_precision,\n","            \"Validation Recall\": val_recall,\n","            \"Validation F1\": val_f1\n","        })\n","\n","        # Print progress\n","        print(f\"Epoch {epoch:2d}/{epochs}: \"\n","              f\"Train Acc: {train_accuracy:.4f}, \"\n","              f\"Val Acc: {val_accuracy:.4f}, \"\n","              f\"Val F1: {val_f1:.4f}, \"\n","              f\"Gap: {(train_accuracy - val_accuracy):.4f}\")\n","\n","        if len(f1s) == 3:\n","            print(f\"          Per-class F1: \"\n","                  f\"Neg: {f1s[0]:.3f}, \"\n","                  f\"Neu: {f1s[1]:.3f}, \"\n","                  f\"Pos: {f1s[2]:.3f}\")\n","\n","        if early_stop_flag:\n","            print(f\"Early stopping at epoch {epoch}\")\n","            break\n","\n","    if best_model_state is not None:\n","        torch.save(best_model_state, f\"best_model_trial_{trial.number}.pt\")\n","\n","    return best_val_accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PeuU17Ujr5RE"},"outputs":[],"source":["# ============ CLASS WEIGHTS COMPUTATION ============\n","from sklearn.utils.class_weight import compute_class_weight\n","def compute_class_weights(train_labels):\n","    \"\"\"\n","    Compute class weights for your imbalanced dataset\n","    \"\"\"\n","    train_labels = np.array(train_labels)\n","    unique_labels = np.unique(train_labels)\n","\n","    print(f\"Computing class weights for {len(train_labels)} samples\")\n","    print(f\"Label distribution: {np.bincount(train_labels)}\")\n","\n","    class_weights = compute_class_weight(\n","        'balanced',\n","        classes=unique_labels,\n","        y=train_labels\n","    )\n","\n","    print(f\"Class weights computed:\")\n","    for i, label in enumerate(unique_labels):\n","        label_name = ['Extremely Negative', 'Extremely Positive', 'Negative','Neutral','Positive'][label]\n","        print(f\"{label_name} ({label}): {class_weights[i]:.3f}\")\n","\n","    return torch.tensor(class_weights, dtype=torch.float)\n","\n","#=============== manual class weight=====================\n","#def compute_class_weights(train_labels):\n","   #Weighting more for harder classes\n"," # manual_weights = torch.tensor([\n","  #  1.0,  # Extremely Negative – no recall issue\n","  #  1.0,  # Negative – balanced\n","  #  1.2,  # Neutral – low recall (0.81)\n","  #  1.0,  # Positive – high recall (0.91)\n","   # 1.3   # Extremely Positive – lowest recall (0.80\n","    #  ], dtype=torch.float).to(device)\n"," # return torch.tensor(manual_weights, dtype=torch.float)\n","\n","\n","\n","# ============ CUSTOM ROBERTA WITH DROPOUT ============\n","class RobertaWithDropout(nn.Module):\n","    \"\"\"\n","    Custom RoBERTa model with configurable dropout\n","    \"\"\"\n","    def __init__(self, model_name, num_labels, dropout_rate=0.1):\n","        super(RobertaWithDropout, self).__init__()\n","\n","        self.roberta = AutoModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_labels)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        return type('obj', (object,), {'logits': logits})()\n"]},{"cell_type":"markdown","metadata":{"id":"c4V3KclijwbS"},"source":["Zero study hippper parameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKdVPeUFLtTv"},"outputs":[],"source":["# Define your hyperparameter ranges here - easy to change between studies\n","learning_rate_from = 2e-6\n","learning_rate_to = 5e-5\n","weight_decay_from = 1e-6\n","weight_decay_to = 1e-4\n","patience_choices = [5, 7]\n","batch_size_choices = [32, 64, 128]\n","num_layers_choices = [0,1]\n","dropout_rate_choices =  [0.1, 0.2, 0.3, 0.4]\n","gradient_clip_val_choices = [0.5, 1.0, 2.0]\n","use_class_weights_choices = [True, False]\n","\n","# Optional features flags\n","enable_gradient_clipping = True\n","enable_class_weights = True\n"]},{"cell_type":"markdown","metadata":{"id":"4kZjQYdj2UN0"},"source":["First study hippper parameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DO6XHRHyn3T"},"outputs":[],"source":["# Define your hyperparameter ranges here - easy to change between studies\n","learning_rate_from = 1e-4\n","learning_rate_to = 3e-4\n","weight_decay_from = 1e-6\n","weight_decay_to = 1e-4\n","patience_choices = [5, 7]\n","batch_size_choices = [64, 128]\n","num_layers_choices = [3, 4, 5]\n","dropout_rate_choices = [0.2, 0.25]\n","gradient_clip_val_choices = [0.5, 1.0, 1.5]\n","use_class_weights_choices = [True, False]\n","\n","# Optional features flags\n","enable_gradient_clipping = True\n","enable_class_weights = False\n"]},{"cell_type":"markdown","metadata":{"id":"Ep4BeQyLk2u0"},"source":["Seconed study hippper parameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqohUvd3k7v9"},"outputs":[],"source":["# Focused Search Configuration: Based ONLY on Experiment 0 insights\n","learning_rate_from = 5e-6                # Narrow range around good low LR\n","learning_rate_to = 3e-5\n","weight_decay_from = 1e-6                 # Same as before, works well\n","weight_decay_to = 5e-5\n","\n","batch_size_choices = [32, 64]            # Batch size 32 gave best generalization\n","dropout_rate_choices = [0.1, 0.2]        # 0.1–0.2 showed stability\n","num_layers_choices = [0]              # Stick to shallow setup\n","gradient_clip_val_choices = [0.5, 1.0, 1.5]\n","patience_choices = [5, 7]                # Let Optuna decide stopping horizon\n","\n","use_class_weights_choices = [True, False]     # Still worth comparing\n","enable_class_weights = True\n","enable_gradient_clipping = True"]},{"cell_type":"markdown","metadata":{"id":"-jaH3v-yrxDm"},"source":["Third + Fourth study hippper parameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hiTBAOxesA0R"},"outputs":[],"source":["learning_rate_from = 2e-6\n","learning_rate_to = 5e-5\n","weight_decay_from = 1e-6\n","weight_decay_to = 1e-4\n","patience_choices = [7]\n","batch_size_choices = [32]\n","\n","num_layers_choices = [0]\n","dropout_rate_choices =  [0.1, 0.4]\n","gradient_clip_val_choices = [0.5, 1.0]\n","use_class_weights_choices = [True, False]\n","\n","# Optional features flags\n","enable_gradient_clipping = True\n","enable_class_weights = True\n"]},{"cell_type":"markdown","metadata":{"id":"Lrj8tHZvlRxX"},"source":["Fifth studt hupper parameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7zGeHIFlRKU"},"outputs":[],"source":["# Define your hyperparameter ranges here - easy to change between studies\n","learning_rate_from = 2e-6\n","learning_rate_to = 5e-5\n","weight_decay_from = 1e-6\n","weight_decay_to = 1e-4\n","patience_choices = [5, 7]\n","batch_size_choices = [32, 64, 128]\n","num_layers_choices = [0,1,2]\n","dropout_rate_choices =  [0.1, 0.2, 0.3, 0.4]\n","gradient_clip_val_choices = [0.5, 1.0, 2.0]\n","use_class_weights_choices = [True, False]\n","\n","# Optional features flags\n","enable_gradient_clipping = True\n","enable_class_weights = True"]},{"cell_type":"markdown","metadata":{"id":"YIXhXI_6xs5-"},"source":["Sixth study hipper paramaters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtuMq3tDxtX6"},"outputs":[],"source":["# Define your hyperparameter ranges here - easy to change between studies\n","learning_rate_from = 1.8e-5\n","learning_rate_to   = 2.1e-5\n","weight_decay_from = 1e-6\n","weight_decay_to = 1e-4\n","patience_choices = [5]\n","batch_size_choices = [32]\n","num_layers_choices = [0]\n","dropout_rate_choices =  [ 0.2, 0.3]\n","gradient_clip_val_choices = [0.5, 1.0]\n","use_class_weights_choices = [True, False]\n","\n","# Optional features flags\n","enable_gradient_clipping = True\n","enable_class_weights = True"]},{"cell_type":"markdown","metadata":{"id":"wrY0Dp593Ypb"},"source":["OBJECTIVE:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xv1B-a7_L1r8"},"outputs":[],"source":["# ============ OBJECTIVE FUNCTION ============\n","\n","def objective(trial,\n","              learning_rate_from=learning_rate_from, learning_rate_to=learning_rate_to,\n","              weight_decay_from=weight_decay_from, weight_decay_to=weight_decay_to,\n","              patience_choices=patience_choices, batch_size_choices=batch_size_choices,\n","              num_layers_choices=num_layers_choices, dropout_rate_choices=dropout_rate_choices,\n","              gradient_clip_val_choices=gradient_clip_val_choices, use_class_weights_choices=use_class_weights_choices,\n","              enable_gradient_clipping=enable_gradient_clipping, enable_class_weights=enable_class_weights):\n","\n","    # Suggest hyperparameters using the ranges passed in\n","    learning_rate = trial.suggest_float(\"learning_rate\", learning_rate_from, learning_rate_to, log=True)\n","    weight_decay = trial.suggest_float(\"weight_decay\", weight_decay_from, weight_decay_to, log=True)\n","    patience = trial.suggest_categorical(\"patience\", patience_choices)\n","    #patience =7\n","    batch_size = trial.suggest_categorical(\"batch_size\", batch_size_choices)\n","    num_layers = trial.suggest_categorical(\"num_layers\", num_layers_choices)\n","    dropout_rate = trial.suggest_categorical(\"dropout_rate\", dropout_rate_choices)\n","\n","    # Optional parameters\n","    if enable_gradient_clipping:\n","        gradient_clip_val = trial.suggest_categorical(\"gradient_clip_val\", gradient_clip_val_choices)\n","    else:\n","        gradient_clip_val = None\n","\n","    if enable_class_weights:\n","        use_class_weights = trial.suggest_categorical(\"use_class_weights\", use_class_weights_choices)\n","    else:\n","        use_class_weights = False\n","\n","    # Load tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n","\n","    # Class weights computation\n","    class_weights = None\n","    if use_class_weights:\n","        print(\"Computing class weights...\")\n","        train_labels = train_df['label'].values\n","        class_weights = compute_class_weights(train_labels)\n","\n","    # Dataset and DataLoader\n","    train_dataset = CoronaTweetDataset(train_df, tokenizer)\n","    val_dataset = CoronaTweetDataset(eval_df, tokenizer)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    # Use custom model with dropout\n","    model = RobertaWithDropout(\n","        \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","        num_labels=5,\n","        dropout_rate=dropout_rate\n","    ).to(device)\n","\n","    # Freeze/unfreeze layers\n","    for param in model.roberta.parameters():\n","        param.requires_grad = False\n","    for param in model.roberta.encoder.layer[-num_layers:].parameters():\n","        param.requires_grad = True\n","    for param in model.classifier.parameters():\n","        param.requires_grad = True\n","\n","    # Use class weights in loss if specified\n","    if use_class_weights and class_weights is not None:\n","        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n","        print(\"Using weighted CrossEntropyLoss\")\n","    else:\n","        criterion = nn.CrossEntropyLoss()\n","        print(\"Using standard CrossEntropyLoss\")\n","\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Initialize wandb\n","    wandb.init(\n","        project=\"cardiffnlp_new5_6.3\",\n","        config={\n","            \"learning_rate\": learning_rate,\n","            \"weight_decay\": weight_decay,\n","            \"patience\": patience,\n","            \"batch_size\": batch_size,\n","            \"num_layers\": num_layers,\n","            \"dropout_rate\": dropout_rate,\n","            \"gradient_clip_val\": gradient_clip_val,\n","            \"use_class_weights\": use_class_weights,\n","            \"enable_gradient_clipping\": enable_gradient_clipping,\n","            \"enable_class_weights\": enable_class_weights,\n","            \"architecture\": \"Twitter-RoBERTa\",\n","            \"dataset\": \"Corona_NLP\"\n","        },\n","        name=f\"trial_{trial.number}\"\n","    )\n","\n","    # Train with optional gradient clipping\n","    best_val_accuracy = train_model_with_hyperparams(\n","        model, train_loader, val_loader, optimizer, criterion,\n","        epochs=12, patience=patience, trial=trial,\n","        gradient_clip_val=gradient_clip_val\n","    )\n","\n","    wandb.finish()\n","    return best_val_accuracy"]},{"cell_type":"markdown","metadata":{"id":"9cfPddteglZV"},"source":["##Hyperparameter Search Rationale\n","To systematically explore the effect of different hyperparameter configurations, we split the tuning process into two separate experiments:\n","\n","### **Experiment 0 — Broad & Conservative Search**\n","This experiment was designed to cover a wide search space with low model complexity (0–1 added layers), lower learning rates, and more dropout values. The idea was to identify whether a minimal configuration, possibly with strong regularization, could yield a robust baseline.\n","\n","**Motivation:** This configuration tests robustness under shallow models and regularization techniques. It is especially useful to detect underfitting trends, noisy gradients, or improvements from weighted loss.\n","\n","### **Experiment 1 — Focused Search on High-Capacity Models**\n","Here, we narrow the ranges and intentionally increase model complexity (3–5 layers), focusing on fine-tuning deeper classification heads with a tighter learning rate range and less dropout.\n","\n","**Motivation:** This setting assumes the base encoder requires more capacity at the classifier level. With reduced regularization and stronger classifiers, the goal was to improve validation accuracy and F1 without overfitting.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PriymDkCLoqw"},"source":["# **ZERO STUDY:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jlAHPTJiL3yQ","outputId":"59c94a4b-320e-4022-c61a-dfcf6ae37339"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 05:32:27,436] A new study created in memory with name: no-name-d6ca0547-445c-419e-b2ce-99fa3073e483\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 0:\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_053230-i2goehg7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/i2goehg7' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/i2goehg7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/i2goehg7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6525, Val Acc: 0.7064, Val F1: 0.7145, Gap: -0.0538\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8084, Val Acc: 0.8154, Val F1: 0.8207, Gap: -0.0070\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8631, Val Acc: 0.8362, Val F1: 0.8414, Gap: 0.0269\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8945, Val Acc: 0.8496, Val F1: 0.8536, Gap: 0.0449\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9187, Val Acc: 0.8342, Val F1: 0.8385, Gap: 0.0845\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9291, Val Acc: 0.8587, Val F1: 0.8631, Gap: 0.0703\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9402, Val Acc: 0.8328, Val F1: 0.8372, Gap: 0.1073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9499, Val Acc: 0.8534, Val F1: 0.8567, Gap: 0.0965\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9549, Val Acc: 0.8440, Val F1: 0.8474, Gap: 0.1109\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9619, Val Acc: 0.8542, Val F1: 0.8580, Gap: 0.1077\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9645, Val Acc: 0.8310, Val F1: 0.8330, Gap: 0.1334\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9685, Val Acc: 0.8461, Val F1: 0.8495, Gap: 0.1224\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9715, Val Acc: 0.8508, Val F1: 0.8543, Gap: 0.1207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9749, Val Acc: 0.8627, Val F1: 0.8652, Gap: 0.1122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9774, Val Acc: 0.8599, Val F1: 0.8627, Gap: 0.1174\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▇▇█▆█▇█▅▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▅▆▅▇▄▇▆▆▃▆█▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▆▆▅▅▄▇▄▅▅█▅▁▃▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▇▇▇▆▇▇▇▅▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▅▆▇▅▅██▅▇█▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▆▇▆█▆▆▆█▃▆█▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇▇▇█▆▅▄▇▆▇▅▆█</td></tr><tr><td>Class_Negative_Precision</td><td>▆▇█▇▇█▅▁▄▇▄▅▁▄▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▅▆▆▆▆█▅▆▇▇█▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇▇▆█▇█▇██▇▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄█▇█▇▆▆▄▆▆██▅▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▆▇▆▇▇▇█▇▇▆▆██</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇█▆█▇█▇▇█▇██▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▆▆▄██▇▇▇▇▅▆▇█</td></tr><tr><td>Class_Positive_Recall</td><td>▇▆▆▆█▄▂▅▄▃▄█▆▄▁</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇▇█▇█▇█▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇█▇█▇█▇▇▇██</td></tr><tr><td>Validation Loss</td><td>▅▂▁▁▂▂▄▃▄▅▆▆▇▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▇▇▆█▆▇▇█▆▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▆▇█▇█▇█▇█▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86844</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84662</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89142</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8402</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83726</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84317</td></tr><tr><td>Class_Negative_F1</td><td>0.89178</td></tr><tr><td>Class_Negative_Precision</td><td>0.89439</td></tr><tr><td>Class_Negative_Recall</td><td>0.88918</td></tr><tr><td>Class_Neutral_F1</td><td>0.85034</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82679</td></tr><tr><td>Class_Neutral_Recall</td><td>0.87527</td></tr><tr><td>Class_Positive_F1</td><td>0.86262</td></tr><tr><td>Class_Positive_Precision</td><td>0.93794</td></tr><tr><td>Class_Positive_Recall</td><td>0.79849</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97737</td></tr><tr><td>Train Loss</td><td>0.08546</td></tr><tr><td>Validation Accuracy</td><td>0.85994</td></tr><tr><td>Validation F1</td><td>0.86268</td></tr><tr><td>Validation Loss</td><td>0.80594</td></tr><tr><td>Validation Precision</td><td>0.8686</td></tr><tr><td>Validation Recall</td><td>0.85951</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/i2goehg7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/i2goehg7</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_053230-i2goehg7/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 06:16:30,740] Trial 0 finished with value: 0.8627308066083577 and parameters: {'learning_rate': 2.241766124366312e-05, 'weight_decay': 5.1609147714517094e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_061631-yzpncvyk</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/yzpncvyk' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/yzpncvyk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/yzpncvyk</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4104, Val Acc: 0.4541, Val F1: 0.4638, Gap: -0.0437\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4534, Val Acc: 0.4745, Val F1: 0.4833, Gap: -0.0211\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4710, Val Acc: 0.4843, Val F1: 0.4961, Gap: -0.0133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.4836, Val Acc: 0.4983, Val F1: 0.5078, Gap: -0.0147\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.4911, Val Acc: 0.5101, Val F1: 0.5189, Gap: -0.0190\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.5048, Val Acc: 0.5131, Val F1: 0.5249, Gap: -0.0084\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.5099, Val Acc: 0.5243, Val F1: 0.5369, Gap: -0.0144\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.5193, Val Acc: 0.5336, Val F1: 0.5471, Gap: -0.0143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.5226, Val Acc: 0.5377, Val F1: 0.5496, Gap: -0.0151\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.5348, Val Acc: 0.5469, Val F1: 0.5609, Gap: -0.0121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.5414, Val Acc: 0.5476, Val F1: 0.5612, Gap: -0.0063\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.5436, Val Acc: 0.5553, Val F1: 0.5693, Gap: -0.0117\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.5490, Val Acc: 0.5633, Val F1: 0.5773, Gap: -0.0143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5540, Val Acc: 0.5720, Val F1: 0.5855, Gap: -0.0180\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.5623, Val Acc: 0.5640, Val F1: 0.5763, Gap: -0.0017\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▁▃▄▃▅▅▆▆▇▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▂▃▆▄▅▄▄▇▆▇██▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▁▄▅▂▅▅▆▇▅▇▆▆▆█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▃▂▆▃▅▅▄▆▅▆▇█▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▁▄▃▄▄▃▆▆▇▇█▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▃▁▇▃▅▆▃▆▄▅▅█▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▃▅▅▄▅▆▄▆▇▆▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▂▁▃▃▂▅▄▅█▆▅█▆▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▃▅▇▂▅▅▁▅▆▃▆██</td></tr><tr><td>Class_Neutral_F1</td><td>▂▁▂▆▂▅▄▇█▆▆███▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▃▅▄▆▆▅▅▆▆▆██</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▁▁▆▁▅▂▅█▆▄▇▆▅▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▄▃▄▆▆▆▇▇█████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▂▅▄▃▃█▆▄▄▄▅█▅</td></tr><tr><td>Class_Positive_Recall</td><td>▃▃▄▁▄▆▆▂▅▇█▇▆▄▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▃▄▄▅▅▆▆▇▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▂▃▄▄▅▅▆▆▇▇▇██▇</td></tr><tr><td>Validation Loss</td><td>█▇▆▅▅▄▄▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▂▃▄▄▄▅▆▆▇▆▇▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▂▃▃▄▅▅▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.62544</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.54764</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.72901</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.48508</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.51959</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.45487</td></tr><tr><td>Class_Negative_F1</td><td>0.6471</td></tr><tr><td>Class_Negative_Precision</td><td>0.63734</td></tr><tr><td>Class_Negative_Recall</td><td>0.65716</td></tr><tr><td>Class_Neutral_F1</td><td>0.49587</td></tr><tr><td>Class_Neutral_Precision</td><td>0.52149</td></tr><tr><td>Class_Neutral_Recall</td><td>0.47265</td></tr><tr><td>Class_Positive_F1</td><td>0.62815</td></tr><tr><td>Class_Positive_Precision</td><td>0.61673</td></tr><tr><td>Class_Positive_Recall</td><td>0.64</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.56234</td></tr><tr><td>Train Loss</td><td>1.03986</td></tr><tr><td>Validation Accuracy</td><td>0.56402</td></tr><tr><td>Validation F1</td><td>0.57633</td></tr><tr><td>Validation Loss</td><td>1.02264</td></tr><tr><td>Validation Precision</td><td>0.56855</td></tr><tr><td>Validation Recall</td><td>0.59074</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/yzpncvyk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/yzpncvyk</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_061631-yzpncvyk/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 06:35:42,343] Trial 1 finished with value: 0.5720359572400389 and parameters: {'learning_rate': 1.8633945217080905e-05, 'weight_decay': 1.8614626125753484e-05, 'patience': 7, 'batch_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_063543-wpzj1bb7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/wpzj1bb7' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/wpzj1bb7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/wpzj1bb7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5082, Val Acc: 0.5939, Val F1: 0.6052, Gap: -0.0857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6652, Val Acc: 0.6918, Val F1: 0.7001, Gap: -0.0266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7324, Val Acc: 0.7481, Val F1: 0.7567, Gap: -0.0157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7712, Val Acc: 0.7704, Val F1: 0.7778, Gap: 0.0008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8009, Val Acc: 0.7860, Val F1: 0.7928, Gap: 0.0150\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8222, Val Acc: 0.8058, Val F1: 0.8118, Gap: 0.0165\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8382, Val Acc: 0.7979, Val F1: 0.8038, Gap: 0.0403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8556, Val Acc: 0.7935, Val F1: 0.7990, Gap: 0.0621\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8663, Val Acc: 0.8183, Val F1: 0.8235, Gap: 0.0480\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8781, Val Acc: 0.8313, Val F1: 0.8356, Gap: 0.0468\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8870, Val Acc: 0.8416, Val F1: 0.8454, Gap: 0.0454\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9003, Val Acc: 0.8360, Val F1: 0.8398, Gap: 0.0643\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9067, Val Acc: 0.8344, Val F1: 0.8392, Gap: 0.0722\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9134, Val Acc: 0.8161, Val F1: 0.8197, Gap: 0.0973\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9222, Val Acc: 0.8437, Val F1: 0.8471, Gap: 0.0785\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▆▆▆▇▇▆▇▇█▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▆▅▅▆▆▅▆▇█▇█▆█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▇▁▆▇▆▆█▆▇▅▇▃█▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▆▆▆▇▇▆▇▇█▇█▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▆▆▆▆▇▇▇▇█████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▆▆▆▇▇▆▇▇█▇█▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▇▇▇████████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▄▆▇▆▆▇██▆█▇▇▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▆▅▆▇▇▇▇▇█▇▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▆▇▆▆▇███▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▅▆▇▇▇▇▆▇▇▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▄▆▆▇▅▅▇█▇█▇▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▆▇▇▆▆▇▇██▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▃▆▅▆▃▃▅█▆▆▅▄▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▆▃▆▄██▇▂▆▆▇█▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▆▇▇▇▇████▇█</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▆▇▇▇▇████▇█</td></tr><tr><td>Validation Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▂▂▁</td></tr><tr><td>Validation Precision</td><td>▁▄▅▆▆▇▇▇▇████▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇▇▇▇███▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85066</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81575</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88869</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81705</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82227</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.8119</td></tr><tr><td>Class_Negative_F1</td><td>0.86197</td></tr><tr><td>Class_Negative_Precision</td><td>0.86393</td></tr><tr><td>Class_Negative_Recall</td><td>0.86001</td></tr><tr><td>Class_Neutral_F1</td><td>0.83382</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85754</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81138</td></tr><tr><td>Class_Positive_F1</td><td>0.87181</td></tr><tr><td>Class_Positive_Precision</td><td>0.85384</td></tr><tr><td>Class_Positive_Recall</td><td>0.89057</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.92216</td></tr><tr><td>Train Loss</td><td>0.21653</td></tr><tr><td>Validation Accuracy</td><td>0.84366</td></tr><tr><td>Validation F1</td><td>0.84706</td></tr><tr><td>Validation Loss</td><td>0.47715</td></tr><tr><td>Validation Precision</td><td>0.84266</td></tr><tr><td>Validation Recall</td><td>0.85251</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/wpzj1bb7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/wpzj1bb7</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_063543-wpzj1bb7/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 07:17:28,004] Trial 2 finished with value: 0.8436588921282799 and parameters: {'learning_rate': 5.5900582242457515e-06, 'weight_decay': 4.1612525839107873e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 2.0, 'use_class_weights': True}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_071729-6fjzvufl</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/6fjzvufl' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/6fjzvufl' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/6fjzvufl</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5547, Val Acc: 0.6678, Val F1: 0.6783, Gap: -0.1131\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7155, Val Acc: 0.7406, Val F1: 0.7495, Gap: -0.0251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7765, Val Acc: 0.7822, Val F1: 0.7889, Gap: -0.0057\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8152, Val Acc: 0.8090, Val F1: 0.8165, Gap: 0.0062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8428, Val Acc: 0.8011, Val F1: 0.8065, Gap: 0.0416\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8628, Val Acc: 0.8381, Val F1: 0.8431, Gap: 0.0247\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8808, Val Acc: 0.8286, Val F1: 0.8338, Gap: 0.0522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8958, Val Acc: 0.8395, Val F1: 0.8434, Gap: 0.0563\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9080, Val Acc: 0.8280, Val F1: 0.8327, Gap: 0.0800\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9181, Val Acc: 0.8403, Val F1: 0.8453, Gap: 0.0778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9270, Val Acc: 0.8486, Val F1: 0.8522, Gap: 0.0783\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9333, Val Acc: 0.8446, Val F1: 0.8488, Gap: 0.0886\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9424, Val Acc: 0.8411, Val F1: 0.8444, Gap: 0.1013\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9477, Val Acc: 0.8502, Val F1: 0.8531, Gap: 0.0975\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9526, Val Acc: 0.8392, Val F1: 0.8424, Gap: 0.1134\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▆▅▇▇▇▇█▇█▇▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▄▆▄▇▆▆▆▇▇█▇▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▆▅▁█▁▆▇▇▄▅▂▃▃▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▆▆▇▇▇▇█████▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▅▆▇▆▇██▇▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▄▇▅▇▇▇▆▇██▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▇▇█▇████▆▇█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▆▇█▇▇█▇██▅▅▆▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▅▅▆▇▇▆▇▇▇▇██▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▆▆▇▇█▇▇█████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▅▆▇▆▇▇▇▆▇▇█▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▆▆▅█▇█▆▇█▇▇█▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▇▆█▇█▆▇█████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▆▇▃▇█▇▄▅█▇▆▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▄▄▇▅▄▅█▇▄▅▇▆▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▆█▇█▇██████</td></tr><tr><td>Validation F1</td><td>▁▄▅▇▆█▇█▇██████</td></tr><tr><td>Validation Loss</td><td>█▅▃▂▂▁▁▁▂▁▂▂▂▃▃</td></tr><tr><td>Validation Precision</td><td>▁▄▅▇▆█▇█▇███▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇█▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83876</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.76524</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92792</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.79979</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81881</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78164</td></tr><tr><td>Class_Negative_F1</td><td>0.8666</td></tr><tr><td>Class_Negative_Precision</td><td>0.88566</td></tr><tr><td>Class_Negative_Recall</td><td>0.84835</td></tr><tr><td>Class_Neutral_F1</td><td>0.8347</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86739</td></tr><tr><td>Class_Neutral_Recall</td><td>0.80438</td></tr><tr><td>Class_Positive_F1</td><td>0.87217</td></tr><tr><td>Class_Positive_Precision</td><td>0.84501</td></tr><tr><td>Class_Positive_Recall</td><td>0.90113</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95259</td></tr><tr><td>Train Loss</td><td>0.13516</td></tr><tr><td>Validation Accuracy</td><td>0.83916</td></tr><tr><td>Validation F1</td><td>0.8424</td></tr><tr><td>Validation Loss</td><td>0.55268</td></tr><tr><td>Validation Precision</td><td>0.83642</td></tr><tr><td>Validation Recall</td><td>0.85268</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/6fjzvufl' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/6fjzvufl</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_071729-6fjzvufl/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 07:59:17,237] Trial 3 finished with value: 0.8502186588921283 and parameters: {'learning_rate': 9.143598213259003e-06, 'weight_decay': 1.0563159878650104e-05, 'patience': 5, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 2.0, 'use_class_weights': True}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_075918-eg0lcog1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/eg0lcog1' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/eg0lcog1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/eg0lcog1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5523, Val Acc: 0.6561, Val F1: 0.6688, Gap: -0.1038\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6985, Val Acc: 0.6838, Val F1: 0.6950, Gap: 0.0147\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7554, Val Acc: 0.7584, Val F1: 0.7674, Gap: -0.0030\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7952, Val Acc: 0.8008, Val F1: 0.8081, Gap: -0.0056\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8249, Val Acc: 0.8124, Val F1: 0.8191, Gap: 0.0125\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8473, Val Acc: 0.8258, Val F1: 0.8312, Gap: 0.0215\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8619, Val Acc: 0.8248, Val F1: 0.8295, Gap: 0.0370\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8757, Val Acc: 0.8171, Val F1: 0.8235, Gap: 0.0586\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8921, Val Acc: 0.8314, Val F1: 0.8359, Gap: 0.0608\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8990, Val Acc: 0.8397, Val F1: 0.8442, Gap: 0.0593\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9099, Val Acc: 0.8435, Val F1: 0.8484, Gap: 0.0663\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9183, Val Acc: 0.8448, Val F1: 0.8489, Gap: 0.0736\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9250, Val Acc: 0.8437, Val F1: 0.8476, Gap: 0.0813\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9317, Val Acc: 0.8387, Val F1: 0.8434, Gap: 0.0930\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9385, Val Acc: 0.8477, Val F1: 0.8507, Gap: 0.0908\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▆▇▇▆▇▇▇██▇█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▅▅▇▆▅▇▆▇█▇▆▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▆▄▅▄▄█▄█▆▄▇▇▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▅▆▇▇▇▇▇▇██▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅▅▆▆▇▇▇▇██▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▁▅▆▇▇▆█▆██▇▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▅▆▇▇█▇███████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▆▆▅▆▇▇██▇████▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▄▇▇▆▇▆▇▇▇▇▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▅▆▆▇▇▆▇█▇██▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▄▆▆▆▆▇▆▇▇▇▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▄▆▆█▇▅▇▇▇██▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▅▇▇█▇▆▇█▇██▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▃▁▄█▆█▇▄▇▇▆▇▇▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▅▃▅▄▆█▆▆▇▆▆█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▆▇▇▇▇▇██████</td></tr><tr><td>Validation F1</td><td>▁▂▅▆▇▇▇▇▇██████</td></tr><tr><td>Validation Loss</td><td>█▇▄▂▂▁▁▂▂▁▁▁▁▂▂</td></tr><tr><td>Validation Precision</td><td>▁▂▅▆▇▇▇▇▇██████</td></tr><tr><td>Validation Recall</td><td>▁▂▅▆▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84872</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.79823</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90602</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81462</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83219</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79778</td></tr><tr><td>Class_Negative_F1</td><td>0.87095</td></tr><tr><td>Class_Negative_Precision</td><td>0.88979</td></tr><tr><td>Class_Negative_Recall</td><td>0.85288</td></tr><tr><td>Class_Neutral_F1</td><td>0.84189</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86339</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82144</td></tr><tr><td>Class_Positive_F1</td><td>0.87713</td></tr><tr><td>Class_Positive_Precision</td><td>0.84379</td></tr><tr><td>Class_Positive_Recall</td><td>0.91321</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.9385</td></tr><tr><td>Train Loss</td><td>0.19155</td></tr><tr><td>Validation Accuracy</td><td>0.84767</td></tr><tr><td>Validation F1</td><td>0.85066</td></tr><tr><td>Validation Loss</td><td>0.52874</td></tr><tr><td>Validation Precision</td><td>0.84548</td></tr><tr><td>Validation Recall</td><td>0.85827</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/eg0lcog1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/eg0lcog1</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_075918-eg0lcog1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 08:41:06,101] Trial 4 finished with value: 0.847667638483965 and parameters: {'learning_rate': 6.9195713168559195e-06, 'weight_decay': 5.0584272826102095e-06, 'patience': 5, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_084107-iv9x70ts</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/iv9x70ts' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/iv9x70ts' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/iv9x70ts</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6325, Val Acc: 0.6680, Val F1: 0.6728, Gap: -0.0355\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7904, Val Acc: 0.7897, Val F1: 0.7947, Gap: 0.0007\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8453, Val Acc: 0.8076, Val F1: 0.8122, Gap: 0.0377\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8765, Val Acc: 0.8422, Val F1: 0.8459, Gap: 0.0343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8994, Val Acc: 0.8466, Val F1: 0.8518, Gap: 0.0529\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9180, Val Acc: 0.8563, Val F1: 0.8602, Gap: 0.0617\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9291, Val Acc: 0.8315, Val F1: 0.8338, Gap: 0.0976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9417, Val Acc: 0.8301, Val F1: 0.8334, Gap: 0.1116\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9486, Val Acc: 0.8541, Val F1: 0.8576, Gap: 0.0945\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9541, Val Acc: 0.8557, Val F1: 0.8591, Gap: 0.0985\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9585, Val Acc: 0.8557, Val F1: 0.8589, Gap: 0.1028\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9633, Val Acc: 0.8478, Val F1: 0.8505, Gap: 0.1155\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9664, Val Acc: 0.8522, Val F1: 0.8551, Gap: 0.1142\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9698, Val Acc: 0.8592, Val F1: 0.8624, Gap: 0.1106\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9730, Val Acc: 0.8553, Val F1: 0.8591, Gap: 0.1177\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▇██▆▆███▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▅▇▇█▅▅▇██▆▇██</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▆▇▄▆▂▇▆▅▁▂▆▂▂▂</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▇▇█▆▇▇██▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅█▆▇▇▇▇██▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▆▇██▆▇███▇███</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▇▇█▇██▆▆█▆▆█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▇▄▆▅▇█▅▂▃▆▄▁█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▅▆▅▇▅▅▇█▆▆▅█▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▆▇▇██▇███████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄█▄█▆▆▆▆▆▅▇▆▇▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▅█▇██▇█▇███▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▆▇███▆█▇████▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▅▇▇▇▇▅█▇▇▇▇▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▇▅█▅▅▄▄█▁▅▅▆▃▅▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇██▇▇███████</td></tr><tr><td>Validation F1</td><td>▁▆▆▇██▇▇███████</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▁▁▃▄▃▄▄▅▆▆▆</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇██▇▇███▇███</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇██▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86273</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84069</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88595</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82867</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83547</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82199</td></tr><tr><td>Class_Negative_F1</td><td>0.88511</td></tr><tr><td>Class_Negative_Precision</td><td>0.93066</td></tr><tr><td>Class_Negative_Recall</td><td>0.84381</td></tr><tr><td>Class_Neutral_F1</td><td>0.843</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84007</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84595</td></tr><tr><td>Class_Positive_F1</td><td>0.87605</td></tr><tr><td>Class_Positive_Precision</td><td>0.84502</td></tr><tr><td>Class_Positive_Recall</td><td>0.90943</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97303</td></tr><tr><td>Train Loss</td><td>0.09684</td></tr><tr><td>Validation Accuracy</td><td>0.85532</td></tr><tr><td>Validation F1</td><td>0.85911</td></tr><tr><td>Validation Loss</td><td>0.65763</td></tr><tr><td>Validation Precision</td><td>0.85838</td></tr><tr><td>Validation Recall</td><td>0.86143</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/iv9x70ts' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/iv9x70ts</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_084107-iv9x70ts/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 09:25:15,270] Trial 5 finished with value: 0.8592079689018465 and parameters: {'learning_rate': 1.595434152647316e-05, 'weight_decay': 7.206536987864947e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_092516-n38i3zdu</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/n38i3zdu' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/n38i3zdu' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/n38i3zdu</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4805, Val Acc: 0.5417, Val F1: 0.5457, Gap: -0.0612\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5996, Val Acc: 0.6249, Val F1: 0.6348, Gap: -0.0253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6599, Val Acc: 0.6748, Val F1: 0.6859, Gap: -0.0149\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7060, Val Acc: 0.7075, Val F1: 0.7177, Gap: -0.0015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7300, Val Acc: 0.7098, Val F1: 0.7187, Gap: 0.0202\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7579, Val Acc: 0.7515, Val F1: 0.7601, Gap: 0.0065\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7726, Val Acc: 0.7665, Val F1: 0.7744, Gap: 0.0061\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.7905, Val Acc: 0.7707, Val F1: 0.7795, Gap: 0.0198\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8043, Val Acc: 0.7906, Val F1: 0.7985, Gap: 0.0137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8184, Val Acc: 0.7782, Val F1: 0.7847, Gap: 0.0402\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8281, Val Acc: 0.7801, Val F1: 0.7871, Gap: 0.0479\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8370, Val Acc: 0.8003, Val F1: 0.8062, Gap: 0.0367\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8467, Val Acc: 0.7834, Val F1: 0.7892, Gap: 0.0632\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8535, Val Acc: 0.8064, Val F1: 0.8122, Gap: 0.0472\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8612, Val Acc: 0.8112, Val F1: 0.8164, Gap: 0.0500\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▅▅▇▇▇█▇▇▇▆██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▄▅▄▆▇▇█▆▆▇▅▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▃▁▂▆▃▃▃▂▆▆▅█▅▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▅▅▇▇▇█▇▇█▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▅▅▇▇▆▇▇▇█▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▅▆▅▇▇██▇▇█▆██</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▅▅▆▇▇▇▇██████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▅▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▅▄▆▇▆▇█▇█▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▆▆▇▇▇▇▇█▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▄▅▆▆▇▇▇██████</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▅▅▅▆▇▆▇▇▆▇▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▅▆▇▇▇▇▇█▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▄▅▅▆▇▇▇▆▆█▇▇█</td></tr><tr><td>Class_Positive_Recall</td><td>▃▁▂▃▅▆▆▆▆██▆█▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▅▆▇▇▇▇▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▃▅▅▅▇▇▇█▇▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▄▃▂▂▂▂▂▁▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▅▅▅▆▇▇█▇▇█▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▅▆▇▇▇▇▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.81344</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.73091</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91697</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.75769</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.78383</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.73323</td></tr><tr><td>Class_Negative_F1</td><td>0.85408</td></tr><tr><td>Class_Negative_Precision</td><td>0.91549</td></tr><tr><td>Class_Negative_Recall</td><td>0.80039</td></tr><tr><td>Class_Neutral_F1</td><td>0.80142</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81001</td></tr><tr><td>Class_Neutral_Recall</td><td>0.793</td></tr><tr><td>Class_Positive_F1</td><td>0.85516</td></tr><tr><td>Class_Positive_Precision</td><td>0.82768</td></tr><tr><td>Class_Positive_Recall</td><td>0.88453</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.86123</td></tr><tr><td>Train Loss</td><td>0.3701</td></tr><tr><td>Validation Accuracy</td><td>0.81122</td></tr><tr><td>Validation F1</td><td>0.81636</td></tr><tr><td>Validation Loss</td><td>0.50899</td></tr><tr><td>Validation Precision</td><td>0.81359</td></tr><tr><td>Validation Recall</td><td>0.82562</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/n38i3zdu' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/n38i3zdu</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_092516-n38i3zdu/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 10:09:25,413] Trial 6 finished with value: 0.8112244897959183 and parameters: {'learning_rate': 2.028245441775596e-06, 'weight_decay': 1.5810167029892693e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_100926-y3idcq5e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/y3idcq5e' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/y3idcq5e' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/y3idcq5e</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.3908, Val Acc: 0.4323, Val F1: 0.4381, Gap: -0.0416\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4335, Val Acc: 0.4518, Val F1: 0.4595, Gap: -0.0183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4475, Val Acc: 0.4662, Val F1: 0.4748, Gap: -0.0187\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.4572, Val Acc: 0.4718, Val F1: 0.4809, Gap: -0.0146\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.4665, Val Acc: 0.4802, Val F1: 0.4911, Gap: -0.0137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.4736, Val Acc: 0.4848, Val F1: 0.4945, Gap: -0.0112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.4770, Val Acc: 0.4893, Val F1: 0.4994, Gap: -0.0123\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.4819, Val Acc: 0.4906, Val F1: 0.5023, Gap: -0.0088\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.4880, Val Acc: 0.5002, Val F1: 0.5109, Gap: -0.0122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.4914, Val Acc: 0.5010, Val F1: 0.5122, Gap: -0.0096\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.4935, Val Acc: 0.5064, Val F1: 0.5179, Gap: -0.0130\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.4947, Val Acc: 0.4999, Val F1: 0.5118, Gap: -0.0051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.4974, Val Acc: 0.5121, Val F1: 0.5245, Gap: -0.0147\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5044, Val Acc: 0.5137, Val F1: 0.5258, Gap: -0.0093\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.5061, Val Acc: 0.5138, Val F1: 0.5245, Gap: -0.0078\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▅▅▅▅▆▆▇▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▄▂▄▇█▅▇▅▇▅▆█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▁▃▆▅▄▄▆▅▇▆██▇█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▅▄▄▁▅▇▇▇█▅▇▆██▃</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▇▅▅▆▅▆▇▇▆▆▆█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>█▅▄▁▄▆▅▆▆▄▅▄▆▆▂</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▅▆▆▆▇▆▇▇▆▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▃▁▃▅▅▄▆▆▇▆▇███▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▇▅▆▇▆▆▅▇▇▅▇▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▃▅▄▃▄▃▆▇▆▅▆▆█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▂▁▄▄▄▆▄▅▆▆██▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▄▇▃▃▄▁▆▆▅▃▄▄█</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▃▄▅▅▆▆▆▆▇▇▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▃▃▃▃▂▂▁▂▆▇▅▁▆▃█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▃▄▅▅▆▆▄▄▆█▅▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▄▅▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▅▅▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▄▅▆▆▆▇▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▃▄▄▅▆▆▆▇▇▇▇███</td></tr><tr><td>Validation Loss</td><td>█▆▅▅▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▂▃▄▄▅▆▅▇▇▇▆▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▅▆▆▆▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.54284</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.53398</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.55201</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.41769</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.48095</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.36914</td></tr><tr><td>Class_Negative_F1</td><td>0.5941</td></tr><tr><td>Class_Negative_Precision</td><td>0.59391</td></tr><tr><td>Class_Negative_Recall</td><td>0.5943</td></tr><tr><td>Class_Neutral_F1</td><td>0.4833</td></tr><tr><td>Class_Neutral_Precision</td><td>0.4385</td></tr><tr><td>Class_Neutral_Recall</td><td>0.53829</td></tr><tr><td>Class_Positive_F1</td><td>0.58441</td></tr><tr><td>Class_Positive_Precision</td><td>0.60749</td></tr><tr><td>Class_Positive_Recall</td><td>0.56302</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.50606</td></tr><tr><td>Train Loss</td><td>1.15216</td></tr><tr><td>Validation Accuracy</td><td>0.51385</td></tr><tr><td>Validation F1</td><td>0.52447</td></tr><tr><td>Validation Loss</td><td>1.14164</td></tr><tr><td>Validation Precision</td><td>0.53097</td></tr><tr><td>Validation Recall</td><td>0.52335</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/y3idcq5e' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/y3idcq5e</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_100926-y3idcq5e/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 10:30:26,729] Trial 7 finished with value: 0.5138483965014577 and parameters: {'learning_rate': 3.513904278985465e-06, 'weight_decay': 3.545369510481612e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 1, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_103027-o0htnb55</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/o0htnb55' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/o0htnb55' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/o0htnb55</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4123, Val Acc: 0.4557, Val F1: 0.4643, Gap: -0.0434\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4534, Val Acc: 0.4793, Val F1: 0.4859, Gap: -0.0260\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4702, Val Acc: 0.4917, Val F1: 0.5019, Gap: -0.0216\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.4849, Val Acc: 0.5032, Val F1: 0.5132, Gap: -0.0183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.4960, Val Acc: 0.5022, Val F1: 0.5133, Gap: -0.0062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.5041, Val Acc: 0.5090, Val F1: 0.5211, Gap: -0.0049\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.5136, Val Acc: 0.5202, Val F1: 0.5319, Gap: -0.0065\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.5187, Val Acc: 0.5285, Val F1: 0.5407, Gap: -0.0098\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.5273, Val Acc: 0.5374, Val F1: 0.5510, Gap: -0.0101\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.5347, Val Acc: 0.5430, Val F1: 0.5565, Gap: -0.0083\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.5392, Val Acc: 0.5409, Val F1: 0.5548, Gap: -0.0017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.5445, Val Acc: 0.5552, Val F1: 0.5694, Gap: -0.0106\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.5492, Val Acc: 0.5594, Val F1: 0.5738, Gap: -0.0102\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5534, Val Acc: 0.5593, Val F1: 0.5720, Gap: -0.0059\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.5569, Val Acc: 0.5679, Val F1: 0.5817, Gap: -0.0110\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▁▃▄▅▅▆▆▇▇▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▆▄▄▁▅▂▆▅▅▄█▆▅▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▁▃▄▇▄▇▆▇██▆▇██</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▄▄▃▄▁▂▂▂▅▆▆█▇▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▅▄▆▅▆▆▅▆▆▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>█▇▄▄▁▂▂▁▅▆▅█▇▅▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▃▄▄▅▅▆▆▅▆▇▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▄▃▄▅▆▄▅▇▆▆█▅█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▂▄▄▃▃▅▅▃▅▅▄█▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▅▅▇▇▆█▅▇▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▂▃▄▃▅▄▆▆▇▇▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▇▇▅▅▇█▆▇▃▇▆▅▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▄▃▅▆▅▆▇▆▇▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▃▅▄▁▅▅▅█▄▆▅▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▁▃▁▄█▄▅▅▃▇▅▇▆▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▃▄▄▄▅▆▆▆▆▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▂▃▄▄▄▅▆▆▆▆▇█▇█</td></tr><tr><td>Validation Loss</td><td>█▇▆▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▃▄▃▄▅▅▆▇▆▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▂▃▄▅▅▅▆▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.62886</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.54479</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.74361</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.49081</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.52034</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.46445</td></tr><tr><td>Class_Negative_F1</td><td>0.64363</td></tr><tr><td>Class_Negative_Precision</td><td>0.69743</td></tr><tr><td>Class_Negative_Recall</td><td>0.59754</td></tr><tr><td>Class_Neutral_F1</td><td>0.5154</td></tr><tr><td>Class_Neutral_Precision</td><td>0.50397</td></tr><tr><td>Class_Neutral_Recall</td><td>0.52735</td></tr><tr><td>Class_Positive_F1</td><td>0.62995</td></tr><tr><td>Class_Positive_Precision</td><td>0.64804</td></tr><tr><td>Class_Positive_Recall</td><td>0.61283</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.55693</td></tr><tr><td>Train Loss</td><td>1.0407</td></tr><tr><td>Validation Accuracy</td><td>0.56791</td></tr><tr><td>Validation F1</td><td>0.58173</td></tr><tr><td>Validation Loss</td><td>1.02475</td></tr><tr><td>Validation Precision</td><td>0.58291</td></tr><tr><td>Validation Recall</td><td>0.58916</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/o0htnb55' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/o0htnb55</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_103027-o0htnb55/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 10:50:30,482] Trial 8 finished with value: 0.5679057337220602 and parameters: {'learning_rate': 1.291019039127209e-05, 'weight_decay': 6.203354081007243e-06, 'patience': 7, 'batch_size': 64, 'num_layers': 1, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_105031-woz3z3go</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/woz3z3go' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/woz3z3go' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/woz3z3go</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5239, Val Acc: 0.6102, Val F1: 0.6236, Gap: -0.0863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6504, Val Acc: 0.6815, Val F1: 0.6948, Gap: -0.0311\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7097, Val Acc: 0.7207, Val F1: 0.7296, Gap: -0.0110\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7478, Val Acc: 0.7547, Val F1: 0.7642, Gap: -0.0070\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7745, Val Acc: 0.7693, Val F1: 0.7780, Gap: 0.0052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8003, Val Acc: 0.7753, Val F1: 0.7819, Gap: 0.0250\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8155, Val Acc: 0.8053, Val F1: 0.8121, Gap: 0.0102\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8341, Val Acc: 0.7965, Val F1: 0.8026, Gap: 0.0376\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8462, Val Acc: 0.7875, Val F1: 0.7959, Gap: 0.0587\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8593, Val Acc: 0.8212, Val F1: 0.8271, Gap: 0.0381\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8688, Val Acc: 0.8162, Val F1: 0.8213, Gap: 0.0526\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8759, Val Acc: 0.8174, Val F1: 0.8228, Gap: 0.0585\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8828, Val Acc: 0.8324, Val F1: 0.8367, Gap: 0.0504\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8926, Val Acc: 0.8098, Val F1: 0.8134, Gap: 0.0828\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9004, Val Acc: 0.8412, Val F1: 0.8456, Gap: 0.0592\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▃▅▆▅▇▆▇▇▇▇▇▅█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▃▅▆▃▇▅▆▇▅▆▆▄█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▁▆▅▅▇▄▇▆▆▇▇▆█▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▄▅▆▅▇▆▇▇▇▇▇▆█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▄▆▆▇▇█▇▇▇▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▄▆▆▅▇▆▆█▇▇█▅█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▅▅▆▇▇▇▇▇████▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▅▆▆▆▇▆▇▇▇▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▅▅▆▇▇▆▇▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▅▆▆▇▆▇▆▇█▇███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▅▅▆▇▆▅▇▇▇█▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▆▆▇▇▇▆▇▇▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▄▆▄▇▆▅▂▇▆▅█▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▄▄▆▅▆▆█▆▇▇▆▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▆▆▇▇▆▇▇▇█▇█</td></tr><tr><td>Validation F1</td><td>▁▃▄▅▆▆▇▇▆▇▇▇█▇█</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▃▂▂▃▁▂▁▁▂▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▆▆▇▇▆▇▇▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▅▅▆▆▇▇▇▇▇▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8502</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83851</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86223</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81077</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81679</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80484</td></tr><tr><td>Class_Negative_F1</td><td>0.86881</td></tr><tr><td>Class_Negative_Precision</td><td>0.89827</td></tr><tr><td>Class_Negative_Recall</td><td>0.84122</td></tr><tr><td>Class_Neutral_F1</td><td>0.82771</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82394</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83151</td></tr><tr><td>Class_Positive_F1</td><td>0.87046</td></tr><tr><td>Class_Positive_Precision</td><td>0.84714</td></tr><tr><td>Class_Positive_Recall</td><td>0.89509</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.90038</td></tr><tr><td>Train Loss</td><td>0.2924</td></tr><tr><td>Validation Accuracy</td><td>0.84123</td></tr><tr><td>Validation F1</td><td>0.84559</td></tr><tr><td>Validation Loss</td><td>0.49246</td></tr><tr><td>Validation Precision</td><td>0.84493</td></tr><tr><td>Validation Recall</td><td>0.84698</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/woz3z3go' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/woz3z3go</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_105031-woz3z3go/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 11:32:38,347] Trial 9 finished with value: 0.8412293488824101 and parameters: {'learning_rate': 4.1083446329831565e-06, 'weight_decay': 4.43108825371218e-06, 'patience': 7, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 2.0, 'use_class_weights': False}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_113239-h0xx6ts3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/h0xx6ts3' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/h0xx6ts3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/h0xx6ts3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4080, Val Acc: 0.4372, Val F1: 0.4405, Gap: -0.0291\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4547, Val Acc: 0.4784, Val F1: 0.4825, Gap: -0.0236\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4809, Val Acc: 0.5086, Val F1: 0.5167, Gap: -0.0277\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.5025, Val Acc: 0.5172, Val F1: 0.5231, Gap: -0.0147\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.5173, Val Acc: 0.5298, Val F1: 0.5365, Gap: -0.0125\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.5291, Val Acc: 0.5227, Val F1: 0.5212, Gap: 0.0064\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.5367, Val Acc: 0.5417, Val F1: 0.5482, Gap: -0.0050\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.5530, Val Acc: 0.5463, Val F1: 0.5514, Gap: 0.0067\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.5570, Val Acc: 0.5629, Val F1: 0.5725, Gap: -0.0059\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.5636, Val Acc: 0.5578, Val F1: 0.5648, Gap: 0.0058\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.5760, Val Acc: 0.5758, Val F1: 0.5827, Gap: 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.5775, Val Acc: 0.5781, Val F1: 0.5866, Gap: -0.0006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.5899, Val Acc: 0.6029, Val F1: 0.6142, Gap: -0.0130\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5943, Val Acc: 0.5875, Val F1: 0.5959, Gap: 0.0068\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.6063, Val Acc: 0.5836, Val F1: 0.5966, Gap: 0.0228\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▅▅▅▆▅▇▆▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▅▅▄▄▅▄▆▅▆▆█▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▄▁▄█▇▆█▇▇▇▇▄▆▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▄▅▃▅▄▆▆▆▆█▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▃▅▄▇▅▆▇▅▇▇▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▄▃▄▂▄▃▅▅▅▅█▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▄▅▆▅▆▆▇▇▇████</td></tr><tr><td>Class_Negative_Precision</td><td>▃▂▁▃▅▂▄▅▅▆▄▅▆▅█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▇▆▅█▇▆▆▆█▇▇█▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▃▄▄▃▄▆▆▅▇▇█▆▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▄▄▆▅▆▆▅▇█▆█▇▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▁▃▄▂▂▃▆▇▃▆▇█▆█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▄▅▆▆▇▇▇████▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▅▃▅▄▆▆▆▆█▇█▆▄</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▁▆▄▆▄▅▅▆▄▆▄▇█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▄▅▅▅▆▆▆▇▇█▇▇</td></tr><tr><td>Validation F1</td><td>▁▃▄▄▅▄▅▅▆▆▇▇█▇▇</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▄▃▃▃▂▂▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▂▄▄▅▄▅▆▆▆▇▇█▇▇</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▆▆▆▆▇▇▇███▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.67347</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.59091</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.78285</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.51566</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.57266</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.46899</td></tr><tr><td>Class_Negative_F1</td><td>0.68043</td></tr><tr><td>Class_Negative_Precision</td><td>0.73973</td></tr><tr><td>Class_Negative_Recall</td><td>0.62994</td></tr><tr><td>Class_Neutral_F1</td><td>0.47788</td></tr><tr><td>Class_Neutral_Precision</td><td>0.53745</td></tr><tr><td>Class_Neutral_Recall</td><td>0.4302</td></tr><tr><td>Class_Positive_F1</td><td>0.63571</td></tr><tr><td>Class_Positive_Precision</td><td>0.52707</td></tr><tr><td>Class_Positive_Recall</td><td>0.80075</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.60635</td></tr><tr><td>Train Loss</td><td>0.87716</td></tr><tr><td>Validation Accuracy</td><td>0.58358</td></tr><tr><td>Validation F1</td><td>0.59663</td></tr><tr><td>Validation Loss</td><td>0.92081</td></tr><tr><td>Validation Precision</td><td>0.59356</td></tr><tr><td>Validation Recall</td><td>0.62255</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/h0xx6ts3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/h0xx6ts3</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_113239-h0xx6ts3/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 11:51:51,471] Trial 10 finished with value: 0.6028911564625851 and parameters: {'learning_rate': 4.854020292403083e-05, 'weight_decay': 1.130654093627716e-06, 'patience': 7, 'batch_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_115152-38dlzopm</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/38dlzopm' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/38dlzopm' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/38dlzopm</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6401, Val Acc: 0.7696, Val F1: 0.7774, Gap: -0.1294\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8020, Val Acc: 0.7888, Val F1: 0.7937, Gap: 0.0133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8528, Val Acc: 0.8291, Val F1: 0.8339, Gap: 0.0237\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8860, Val Acc: 0.8386, Val F1: 0.8427, Gap: 0.0474\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9086, Val Acc: 0.8291, Val F1: 0.8357, Gap: 0.0795\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9258, Val Acc: 0.8490, Val F1: 0.8530, Gap: 0.0768\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9375, Val Acc: 0.8529, Val F1: 0.8559, Gap: 0.0846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9486, Val Acc: 0.8251, Val F1: 0.8274, Gap: 0.1235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9539, Val Acc: 0.8580, Val F1: 0.8608, Gap: 0.0959\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9581, Val Acc: 0.8277, Val F1: 0.8305, Gap: 0.1303\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9623, Val Acc: 0.8622, Val F1: 0.8655, Gap: 0.1001\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9694, Val Acc: 0.8556, Val F1: 0.8587, Gap: 0.1139\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9717, Val Acc: 0.8458, Val F1: 0.8495, Gap: 0.1258\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9731, Val Acc: 0.8388, Val F1: 0.8426, Gap: 0.1343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9751, Val Acc: 0.8392, Val F1: 0.8429, Gap: 0.1359\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▁▆▅▇▇▆▃▇▁█▇▇▄▅</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▅▁▅▃▇▇▅▂█▁█▆▅▃▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁█▆▇▄▄▆█▃█▃▆▆▇█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▁▆▄▆▆▆▃▇▂█▇▆▄▅</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅▃▇█▆▆▅▄▆█▆▄▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▁▆▅▅▅▅▂█▂█▅▆▅▃</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▇▅▇█▇▇▇▇█▄▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▅▅▆▇▆▅▇▅▅█▆▅▁▆█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▅▄▇▅▇▆▄▅▇█▅▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▅█▄▇█▆█▇██▇▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▇▆▃▅▅█▆▇▆▆█▆▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▁▃▇▅▇█▄█▆▇▇▅▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▇▅▇▇▅█▇▇▇█▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▂█▂▄▇▃▇▅▅▅▇▇▄</td></tr><tr><td>Class_Positive_Recall</td><td>▄▇▇▁█▇▃▇▃▆▆▆▄▂▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▆▅▇▇▅█▅█▇▇▆▆</td></tr><tr><td>Validation F1</td><td>▁▂▅▆▆▇▇▅█▅█▇▇▆▆</td></tr><tr><td>Validation Loss</td><td>▃▂▁▁▂▂▂▄▃▅▅▅▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▂▅▆▆▇▇▄█▅█▇▆▆▆</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▆▇▇▆▇▆██▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83434</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.74445</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.94891</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.79442</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86746</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.73273</td></tr><tr><td>Class_Negative_F1</td><td>0.89548</td></tr><tr><td>Class_Negative_Precision</td><td>0.95723</td></tr><tr><td>Class_Negative_Recall</td><td>0.84122</td></tr><tr><td>Class_Neutral_F1</td><td>0.82612</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82995</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82232</td></tr><tr><td>Class_Positive_F1</td><td>0.86422</td></tr><tr><td>Class_Positive_Precision</td><td>0.8039</td></tr><tr><td>Class_Positive_Recall</td><td>0.93434</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97506</td></tr><tr><td>Train Loss</td><td>0.09297</td></tr><tr><td>Validation Accuracy</td><td>0.83916</td></tr><tr><td>Validation F1</td><td>0.84292</td></tr><tr><td>Validation Loss</td><td>0.89076</td></tr><tr><td>Validation Precision</td><td>0.8406</td></tr><tr><td>Validation Recall</td><td>0.8559</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/38dlzopm' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/38dlzopm</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_115152-38dlzopm/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 12:36:01,644] Trial 11 finished with value: 0.8622448979591837 and parameters: {'learning_rate': 2.573074315751937e-05, 'weight_decay': 2.7154221329159057e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 0 with value: 0.8627308066083577.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_123602-onoj3or0</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/onoj3or0' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/onoj3or0' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/onoj3or0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6600, Val Acc: 0.7809, Val F1: 0.7897, Gap: -0.1208\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8200, Val Acc: 0.7966, Val F1: 0.8027, Gap: 0.0234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8672, Val Acc: 0.8454, Val F1: 0.8495, Gap: 0.0218\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8955, Val Acc: 0.8479, Val F1: 0.8514, Gap: 0.0476\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9194, Val Acc: 0.8446, Val F1: 0.8487, Gap: 0.0747\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9322, Val Acc: 0.8517, Val F1: 0.8557, Gap: 0.0805\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9414, Val Acc: 0.8474, Val F1: 0.8510, Gap: 0.0939\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9499, Val Acc: 0.8633, Val F1: 0.8665, Gap: 0.0865\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9564, Val Acc: 0.8321, Val F1: 0.8367, Gap: 0.1243\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9604, Val Acc: 0.8466, Val F1: 0.8507, Gap: 0.1138\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9672, Val Acc: 0.8563, Val F1: 0.8596, Gap: 0.1109\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9707, Val Acc: 0.8659, Val F1: 0.8687, Gap: 0.1048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9737, Val Acc: 0.8428, Val F1: 0.8464, Gap: 0.1309\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9764, Val Acc: 0.8535, Val F1: 0.8562, Gap: 0.1229\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9773, Val Acc: 0.8581, Val F1: 0.8615, Gap: 0.1191\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▁▆▆▆▇▆█▇▇▇█▇▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▇▁█▄▅▄▄▆▆▆▆██▅▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁█▃█▇▇▇▆▅▆▆▄▄▆▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▃▁▇▆▇▆▆▇▇▆▇█▇▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▂▁▃▆▆▅▅█▇▇▆▆▆▇▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▁█▃▅▅▅▄▅▄▅▇▆▄▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆███▆▇▅▆▆█▂▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▆█▇▇██▅▆▄▅▅▆▁▅▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▅▅▅▆▆▇▇▆▇█▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▇▆▇▇█▅▇██▆██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁█▇▇█▇▇▆▇▆▆▇█▇▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▁▅▆▄▆▆█▂▆▇▇▄▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▇▅▇▇█▃▆▇█▇▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▅▅▃▆█▇▁▄▇▆▅▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▅▇▅▅█▅▁▄█▆▂▅▆▅▁</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▆▇▆▇▆█▅▆▇█▆▇▇</td></tr><tr><td>Validation F1</td><td>▁▂▆▆▆▇▆█▅▆▇█▆▇▇</td></tr><tr><td>Validation Loss</td><td>▄▃▁▁▂▂▃▃▅▅▅▆█▆█</td></tr><tr><td>Validation Precision</td><td>▁▁▆▆▅▆▆█▄▆▇█▆▆█</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇▇█▆▇▇█▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86262</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86301</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86223</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83108</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81094</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.85224</td></tr><tr><td>Class_Negative_F1</td><td>0.88713</td></tr><tr><td>Class_Negative_Precision</td><td>0.90383</td></tr><tr><td>Class_Negative_Recall</td><td>0.87103</td></tr><tr><td>Class_Neutral_F1</td><td>0.85116</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83922</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86346</td></tr><tr><td>Class_Positive_F1</td><td>0.87559</td></tr><tr><td>Class_Positive_Precision</td><td>0.91523</td></tr><tr><td>Class_Positive_Recall</td><td>0.83925</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97725</td></tr><tr><td>Train Loss</td><td>0.08733</td></tr><tr><td>Validation Accuracy</td><td>0.85811</td></tr><tr><td>Validation F1</td><td>0.86152</td></tr><tr><td>Validation Loss</td><td>0.79034</td></tr><tr><td>Validation Precision</td><td>0.86645</td></tr><tr><td>Validation Recall</td><td>0.85764</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/onoj3or0' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/onoj3or0</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_123602-onoj3or0/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 13:20:12,340] Trial 12 finished with value: 0.8658892128279884 and parameters: {'learning_rate': 2.9485003747847762e-05, 'weight_decay': 2.77651553292106e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 12 with value: 0.8658892128279884.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_132013-1kjpww9y</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/1kjpww9y' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/1kjpww9y' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/1kjpww9y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6685, Val Acc: 0.7878, Val F1: 0.7941, Gap: -0.1192\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8219, Val Acc: 0.8208, Val F1: 0.8256, Gap: 0.0011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8703, Val Acc: 0.8271, Val F1: 0.8321, Gap: 0.0432\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.9014, Val Acc: 0.8554, Val F1: 0.8577, Gap: 0.0460\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9215, Val Acc: 0.8450, Val F1: 0.8488, Gap: 0.0765\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9355, Val Acc: 0.8364, Val F1: 0.8385, Gap: 0.0991\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9444, Val Acc: 0.8557, Val F1: 0.8588, Gap: 0.0887\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9499, Val Acc: 0.8558, Val F1: 0.8588, Gap: 0.0941\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9581, Val Acc: 0.8609, Val F1: 0.8644, Gap: 0.0972\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9614, Val Acc: 0.8444, Val F1: 0.8476, Gap: 0.1170\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9662, Val Acc: 0.8612, Val F1: 0.8638, Gap: 0.1050\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9687, Val Acc: 0.8664, Val F1: 0.8690, Gap: 0.1023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9726, Val Acc: 0.8614, Val F1: 0.8632, Gap: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9731, Val Acc: 0.8520, Val F1: 0.8549, Gap: 0.1211\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9789, Val Acc: 0.8654, Val F1: 0.8679, Gap: 0.1135\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▆▅▁▇▇▇▅▇█▇▆▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▂▄▇▄▁▇▅▅▃▇▇█▅█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▇▆▂▇█▃▅▆▇▃▃▁▆▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▇▅▂▇▇▇▅███▆█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▇▇▆▇▅▆▆▆▅▆█▅▇▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▁▂▆▄▁▇▆▆▄▇▆█▅█</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆▅▆▇▄▅▆▅▅▅▅▅█</td></tr><tr><td>Class_Negative_Precision</td><td>▂▇▆▅█▇▁▄▅▃▃▃▂▄█</td></tr><tr><td>Class_Negative_Recall</td><td>▄▁▅▅▃▅█▆▆▇███▆▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▄▇▆█▇█▇▇▇██▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▄▁▄▃▆██▅▇▆▇▅▇▄▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▄█▅▆▅▇▆▆▆█▇██</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▄▇▆█▇▆█▇▇█▇▆▇</td></tr><tr><td>Class_Positive_Precision</td><td>▂▃▁▇▃▅▆█▆█▅▆▆█▇</td></tr><tr><td>Class_Positive_Recall</td><td>▄▆█▄▇▆▅▂▅▂▅▅▅▁▃</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▇▆▅▇▇█▆███▇█</td></tr><tr><td>Validation F1</td><td>▁▄▅▇▆▅▇▇█▆██▇▇█</td></tr><tr><td>Validation Loss</td><td>▃▂▁▁▂▄▂▃▃▅▄▅▆▇█</td></tr><tr><td>Validation Precision</td><td>▁▄▄▇▅▅▆▇▇▆▇▇▇▆█</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▇▆▇▇█▆▇█▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85824</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.90323</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.81752</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84763</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81801</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.87948</td></tr><tr><td>Class_Negative_F1</td><td>0.90266</td></tr><tr><td>Class_Negative_Precision</td><td>0.93969</td></tr><tr><td>Class_Negative_Recall</td><td>0.86844</td></tr><tr><td>Class_Neutral_F1</td><td>0.8546</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82861</td></tr><tr><td>Class_Neutral_Recall</td><td>0.88228</td></tr><tr><td>Class_Positive_F1</td><td>0.87646</td></tr><tr><td>Class_Positive_Precision</td><td>0.90312</td></tr><tr><td>Class_Positive_Recall</td><td>0.85132</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97889</td></tr><tr><td>Train Loss</td><td>0.08462</td></tr><tr><td>Validation Accuracy</td><td>0.8654</td></tr><tr><td>Validation F1</td><td>0.86792</td></tr><tr><td>Validation Loss</td><td>0.85037</td></tr><tr><td>Validation Precision</td><td>0.87853</td></tr><tr><td>Validation Recall</td><td>0.85981</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/1kjpww9y' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/1kjpww9y</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_132013-1kjpww9y/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 14:04:25,186] Trial 13 finished with value: 0.8663751214771623 and parameters: {'learning_rate': 3.4119074223548975e-05, 'weight_decay': 2.5039473040004243e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 13 with value: 0.8663751214771623.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_140426-98cjfy2i</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/98cjfy2i' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/98cjfy2i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/98cjfy2i</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6785, Val Acc: 0.7970, Val F1: 0.8020, Gap: -0.1185\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8270, Val Acc: 0.8382, Val F1: 0.8436, Gap: -0.0112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8686, Val Acc: 0.8309, Val F1: 0.8338, Gap: 0.0377\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.9024, Val Acc: 0.8502, Val F1: 0.8525, Gap: 0.0522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9202, Val Acc: 0.8573, Val F1: 0.8614, Gap: 0.0630\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9326, Val Acc: 0.8491, Val F1: 0.8527, Gap: 0.0835\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9409, Val Acc: 0.8597, Val F1: 0.8619, Gap: 0.0812\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9482, Val Acc: 0.8516, Val F1: 0.8557, Gap: 0.0966\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9525, Val Acc: 0.8644, Val F1: 0.8672, Gap: 0.0881\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9574, Val Acc: 0.8404, Val F1: 0.8446, Gap: 0.1170\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9608, Val Acc: 0.8675, Val F1: 0.8702, Gap: 0.0933\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9636, Val Acc: 0.8631, Val F1: 0.8650, Gap: 0.1005\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9658, Val Acc: 0.8536, Val F1: 0.8567, Gap: 0.1122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9698, Val Acc: 0.8479, Val F1: 0.8517, Gap: 0.1219\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9732, Val Acc: 0.8523, Val F1: 0.8546, Gap: 0.1210\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▃▆▇▆▇█▇▆█▇▇█▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▇▆▁█▅▄▅▆▅▄▆█▅▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▅█▃▆▇▆▆▆▇▆▄▆▆▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▁█▇▅▇█▇▆▇▇▇▅▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▄▅▅▃▇▆▇▅▇▆▅█▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▇▁█▇▆▅▇▆▅▆▇▆▃▅</td></tr><tr><td>Class_Negative_F1</td><td>▃▆████▅██▂█▇▅▁▄</td></tr><tr><td>Class_Negative_Precision</td><td>▆▇█▆█▇▅▇▇▂▆▅▅▁▄</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▄▆▃▄▆▄▅▇▅▆▆█▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▅▆▇▇▅▇▅██▇▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃█▆▆▆▆▇▆█▅▆▆▇▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▆▆▂▃▅▅▆▃▇▁█▇▅▅▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▃▆▅▇▂▇▇██▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▆▇▂▁▄█▆▁▅▅▇▆▆▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂██▇▂▅▇▆▅▄▆▄▅▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▄▆▇▆▇▆█▅██▇▆▆</td></tr><tr><td>Validation F1</td><td>▁▅▄▆▇▆▇▇█▅█▇▇▆▆</td></tr><tr><td>Validation Loss</td><td>▄▂▁▂▁▄▂▄▃▅▅█▆▇▆</td></tr><tr><td>Validation Precision</td><td>▁▅▁▆▆▅▆▅▇▂██▅▄▅</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇█▇█▇█▇█▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85077</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84846</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8531</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81448</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84902</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78265</td></tr><tr><td>Class_Negative_F1</td><td>0.86278</td></tr><tr><td>Class_Negative_Precision</td><td>0.83505</td></tr><tr><td>Class_Negative_Recall</td><td>0.89242</td></tr><tr><td>Class_Neutral_F1</td><td>0.85647</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84374</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86958</td></tr><tr><td>Class_Positive_F1</td><td>0.8883</td></tr><tr><td>Class_Positive_Precision</td><td>0.89753</td></tr><tr><td>Class_Positive_Recall</td><td>0.87925</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97324</td></tr><tr><td>Train Loss</td><td>0.10128</td></tr><tr><td>Validation Accuracy</td><td>0.85228</td></tr><tr><td>Validation F1</td><td>0.85456</td></tr><tr><td>Validation Loss</td><td>0.65233</td></tr><tr><td>Validation Precision</td><td>0.85476</td></tr><tr><td>Validation Recall</td><td>0.8554</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_14</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/98cjfy2i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00/runs/98cjfy2i</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_00</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_140426-98cjfy2i/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 14:48:38,349] Trial 14 finished with value: 0.8674684159378037 and parameters: {'learning_rate': 4.9786903263194e-05, 'weight_decay': 2.269910677069254e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 14 with value: 0.8674684159378037.\n"]},{"name":"stdout","output_type":"stream","text":["\n"," Best Results:\n","Validation Accuracy: 0.8675\n","Best hyperparameters:\n","  learning_rate: 4.9786903263194e-05\n","  weight_decay: 2.269910677069254e-06\n","  patience: 7\n","  batch_size: 32\n","  num_layers: 0\n","  dropout_rate: 0.4\n","  gradient_clip_val: 0.5\n","  use_class_weights: True\n","\n","Best model saved: best_model_trial_14.pt\n"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 0:\")\n","study0 = optuna.create_study(direction=\"maximize\")\n","study0.optimize(objective, n_trials=15)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study0.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model0.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")"]},{"cell_type":"markdown","metadata":{"id":"nZFG9Hly2Owh"},"source":["# **FIRST STUDY:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"0mUcwpwrtwQz","outputId":"a25eb164-7f0a-4ff1-f335-a8557dce1a5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 12:35:49,843] A new study created in memory with name: no-name-5aad679b-fde0-4772-9e21-92fad52b5e0e\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 1:\n","Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Finishing previous runs because reinit is set to 'default'."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/new_cardiffnlp_1/runs/9quzuugz' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/new_cardiffnlp_1/runs/9quzuugz</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/new_cardiffnlp_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/new_cardiffnlp_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_123411-9quzuugz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_123550-hiq9zeir</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hiq9zeir' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hiq9zeir' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hiq9zeir</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5279, Val Acc: 0.5866, Val F1: 0.5944, Gap: -0.0587\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6225, Val Acc: 0.6418, Val F1: 0.6507, Gap: -0.0192\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6708, Val Acc: 0.6740, Val F1: 0.6846, Gap: -0.0032\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7007, Val Acc: 0.6504, Val F1: 0.6586, Gap: 0.0503\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7368, Val Acc: 0.6440, Val F1: 0.6497, Gap: 0.0929\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7608, Val Acc: 0.6991, Val F1: 0.7114, Gap: 0.0617\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7825, Val Acc: 0.7392, Val F1: 0.7476, Gap: 0.0433\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8001, Val Acc: 0.7185, Val F1: 0.7265, Gap: 0.0815\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8191, Val Acc: 0.7007, Val F1: 0.7057, Gap: 0.1184\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8355, Val Acc: 0.7541, Val F1: 0.7627, Gap: 0.0814\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8450, Val Acc: 0.7551, Val F1: 0.7629, Gap: 0.0899\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8522, Val Acc: 0.7394, Val F1: 0.7484, Gap: 0.1127\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8645, Val Acc: 0.7341, Val F1: 0.7425, Gap: 0.1304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8693, Val Acc: 0.7345, Val F1: 0.7454, Gap: 0.1348\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8811, Val Acc: 0.7524, Val F1: 0.7606, Gap: 0.1287\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▄▅▇▇▅▄▇▇█▇█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▅▃▄█▆▃▃▆▇█▆█▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▅▃▇▇▁▆██▆▄▃▆▂▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▄▄▇▆▅▄▇▇▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▆▃▇▅▆▄▆▅▇█▇▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▄▄▃▇▆▄▃▇▆▇▆█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆▅▆▇▇▇█████▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▂▅▁▆▂▇▄▅▅▄▇██</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▆▄▇▆█▆██▇█▇▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▃▅▄▃▁▄▇█▆██▆▆▆█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▃▆▅▅▇███▇▇█▆▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▄▆▅▂▁▄▇▇▅▇█▆▆▅▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▂▁▄▇█▆██▆▆▅▇</td></tr><tr><td>Class_Positive_Precision</td><td>▃▅▃▂▁▃█▇▄█▇▄▄▄▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▁▅▇█▇▂▄▆▂▄▇▇▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▆▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▄▃▆▇▆▆██▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▃▅▄▃▆▇▆▆██▇▇▇█</td></tr><tr><td>Validation Loss</td><td>█▅▄▄▅▃▁▃▄▁▃▃▄▃▄</td></tr><tr><td>Validation Precision</td><td>▁▃▄▄▃▆▇▇▆██▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▅▅▅▆▇▇▇████▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.76678</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.6951</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.85493</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.70166</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.70906</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.6944</td></tr><tr><td>Class_Negative_F1</td><td>0.83531</td></tr><tr><td>Class_Negative_Precision</td><td>0.90476</td></tr><tr><td>Class_Negative_Recall</td><td>0.77576</td></tr><tr><td>Class_Neutral_F1</td><td>0.71652</td></tr><tr><td>Class_Neutral_Precision</td><td>0.74295</td></tr><tr><td>Class_Neutral_Recall</td><td>0.6919</td></tr><tr><td>Class_Positive_F1</td><td>0.78267</td></tr><tr><td>Class_Positive_Precision</td><td>0.7391</td></tr><tr><td>Class_Positive_Recall</td><td>0.8317</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.88109</td></tr><tr><td>Train Loss</td><td>0.30137</td></tr><tr><td>Validation Accuracy</td><td>0.75243</td></tr><tr><td>Validation F1</td><td>0.76059</td></tr><tr><td>Validation Loss</td><td>0.7428</td></tr><tr><td>Validation Precision</td><td>0.7582</td></tr><tr><td>Validation Recall</td><td>0.76974</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hiq9zeir' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hiq9zeir</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_123550-hiq9zeir/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 12:59:44,915] Trial 0 finished with value: 0.7551020408163265 and parameters: {'learning_rate': 0.00020156473775253668, 'weight_decay': 4.9459167426846274e-05, 'batch_size': 64, 'num_layers': 3, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 0 with value: 0.7551020408163265.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_125945-8wmfge71</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8wmfge71' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8wmfge71' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8wmfge71</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5606, Val Acc: 0.6224, Val F1: 0.6287, Gap: -0.0619\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6872, Val Acc: 0.7159, Val F1: 0.7239, Gap: -0.0286\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7512, Val Acc: 0.7751, Val F1: 0.7833, Gap: -0.0240\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7943, Val Acc: 0.7716, Val F1: 0.7776, Gap: 0.0227\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8201, Val Acc: 0.8002, Val F1: 0.8066, Gap: 0.0200\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8426, Val Acc: 0.7830, Val F1: 0.7901, Gap: 0.0595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8600, Val Acc: 0.8126, Val F1: 0.8191, Gap: 0.0475\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8701, Val Acc: 0.8072, Val F1: 0.8130, Gap: 0.0629\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8825, Val Acc: 0.8256, Val F1: 0.8320, Gap: 0.0569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8912, Val Acc: 0.8077, Val F1: 0.8146, Gap: 0.0835\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8992, Val Acc: 0.8124, Val F1: 0.8189, Gap: 0.0868\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9039, Val Acc: 0.8305, Val F1: 0.8365, Gap: 0.0734\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9131, Val Acc: 0.8327, Val F1: 0.8377, Gap: 0.0804\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9178, Val Acc: 0.8301, Val F1: 0.8351, Gap: 0.0877\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9218, Val Acc: 0.8294, Val F1: 0.8351, Gap: 0.0923\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▇▅▇▆█▇███████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▆█▆▄▆▆▆▆▇▇█▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>██▆▁▆█▇▇▇▇▆▆▄▇▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▆▇▇▆▇▇▇██████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▅▅▇▅▇▇▆█▇▆▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▆▇▆▆▇▇█▇▇██▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▅▆▆▇▇█▇█▇██▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▇▄▆▅▇█▇▇▇▇▇▇▅█</td></tr><tr><td>Class_Negative_Recall</td><td>▅▁▇▆▇▅▅▆▆▇▅▇▇█▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▅▆▇▇▇█▆▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▅▃▅█▇▇▇▇▆▇▇█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▅▆▇▅▆▆█▅▆██▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▆▆▇▆▇█▅▆████</td></tr><tr><td>Class_Positive_Precision</td><td>▂▃▄▃▄▅▃▃█▁▂▇▅▆▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▆▇▇▇▇▇▅██▆▇▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆▇▆▇▇█▇▇████</td></tr><tr><td>Validation F1</td><td>▁▄▆▆▇▆▇▇█▇▇████</td></tr><tr><td>Validation Loss</td><td>█▅▃▃▂▂▁▁▂▁▂▂▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▄▆▆▇▆▇▇█▇▇██▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▆▅▇▇▇▇█▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84363</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81129</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.87865</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.79188</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.79714</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78669</td></tr><tr><td>Class_Negative_F1</td><td>0.87291</td></tr><tr><td>Class_Negative_Precision</td><td>0.94625</td></tr><tr><td>Class_Negative_Recall</td><td>0.81011</td></tr><tr><td>Class_Neutral_F1</td><td>0.81171</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81029</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81313</td></tr><tr><td>Class_Positive_F1</td><td>0.85531</td></tr><tr><td>Class_Positive_Precision</td><td>0.81208</td></tr><tr><td>Class_Positive_Recall</td><td>0.9034</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.92176</td></tr><tr><td>Train Loss</td><td>0.21122</td></tr><tr><td>Validation Accuracy</td><td>0.82945</td></tr><tr><td>Validation F1</td><td>0.83508</td></tr><tr><td>Validation Loss</td><td>0.53361</td></tr><tr><td>Validation Precision</td><td>0.83541</td></tr><tr><td>Validation Recall</td><td>0.83839</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8wmfge71' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8wmfge71</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_125945-8wmfge71/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 13:27:43,455] Trial 1 finished with value: 0.8327259475218659 and parameters: {'learning_rate': 0.00018471699333468756, 'weight_decay': 3.259906503890993e-05, 'batch_size': 64, 'num_layers': 5, 'dropout_rate': 0.25, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_132744-nm6kanzx</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/nm6kanzx' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/nm6kanzx' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/nm6kanzx</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5770, Val Acc: 0.6794, Val F1: 0.6917, Gap: -0.1024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7088, Val Acc: 0.6861, Val F1: 0.7006, Gap: 0.0227\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7827, Val Acc: 0.7641, Val F1: 0.7665, Gap: 0.0186\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8284, Val Acc: 0.7877, Val F1: 0.7957, Gap: 0.0407\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8617, Val Acc: 0.7915, Val F1: 0.7979, Gap: 0.0701\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8857, Val Acc: 0.7934, Val F1: 0.8001, Gap: 0.0924\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9029, Val Acc: 0.7994, Val F1: 0.8060, Gap: 0.1034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9151, Val Acc: 0.7957, Val F1: 0.8019, Gap: 0.1194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9248, Val Acc: 0.7784, Val F1: 0.7866, Gap: 0.1464\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9336, Val Acc: 0.7988, Val F1: 0.8039, Gap: 0.1348\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9410, Val Acc: 0.7823, Val F1: 0.7875, Gap: 0.1587\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9473, Val Acc: 0.8050, Val F1: 0.8106, Gap: 0.1423\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9479, Val Acc: 0.7919, Val F1: 0.7973, Gap: 0.1560\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9548, Val Acc: 0.8037, Val F1: 0.8079, Gap: 0.1511\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9585, Val Acc: 0.8028, Val F1: 0.8085, Gap: 0.1556\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▇▇▇▇▇▇▇▇▅█▆▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▄▇▇▄▄▅▅▃▃▁▅▂█▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▄▃▃▅▆▅▄▆▇█▆█▂▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▇▇▇▆▇█▇▇▅▇▆█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▄▆▇▆▆▅▅▅█▇▆▆▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▇▆▆▆▆█▇▇▄▆▅█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▇█▇▇▆▇▇▇▇▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▅▆▇▇▆▇█▅▇▄▆▄▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▅▅▆▅▅▂▇▅█▆▆▅</td></tr><tr><td>Class_Neutral_F1</td><td>▃▁▇▇▇▇█▇▆█▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▅▇▇▇█▇▇▇██▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▅▁██▆▆▇▆▅▇▇▇▆▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▃▁▂▇▇▇█▇▇▇▇███▇</td></tr><tr><td>Class_Positive_Precision</td><td>▄▁█▆▅▆▆▅▅█▆▆▆▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▅█▁▆▇▆▆▇▇▅▆▆▆▆▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁▆▇▇▇█▇▇█▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▂▅▇▇▇█▇▇█▇█▇██</td></tr><tr><td>Validation Loss</td><td>██▃▁▁▁▂▄▆▅▇▅▆▇▆</td></tr><tr><td>Validation Precision</td><td>▁▂▇▇▇▇▇▇▆█▆▇▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▃▄▇▇██▇▇▇▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.80958</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.76229</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86314</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.76027</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.76008</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.76046</td></tr><tr><td>Class_Negative_F1</td><td>0.861</td></tr><tr><td>Class_Negative_Precision</td><td>0.92291</td></tr><tr><td>Class_Negative_Recall</td><td>0.80687</td></tr><tr><td>Class_Neutral_F1</td><td>0.78631</td></tr><tr><td>Class_Neutral_Precision</td><td>0.78839</td></tr><tr><td>Class_Neutral_Recall</td><td>0.78425</td></tr><tr><td>Class_Positive_F1</td><td>0.82509</td></tr><tr><td>Class_Positive_Precision</td><td>0.80722</td></tr><tr><td>Class_Positive_Recall</td><td>0.84377</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95845</td></tr><tr><td>Train Loss</td><td>0.12234</td></tr><tr><td>Validation Accuracy</td><td>0.80284</td></tr><tr><td>Validation F1</td><td>0.80845</td></tr><tr><td>Validation Loss</td><td>0.76505</td></tr><tr><td>Validation Precision</td><td>0.80818</td></tr><tr><td>Validation Recall</td><td>0.8117</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/nm6kanzx' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/nm6kanzx</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_132744-nm6kanzx/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 13:54:35,276] Trial 2 finished with value: 0.8050291545189504 and parameters: {'learning_rate': 0.0001802532392084408, 'weight_decay': 4.4484809531201e-06, 'batch_size': 128, 'num_layers': 5, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_135436-9lr4ytje</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/9lr4ytje' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/9lr4ytje' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/9lr4ytje</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5160, Val Acc: 0.5610, Val F1: 0.5657, Gap: -0.0450\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6126, Val Acc: 0.6090, Val F1: 0.6169, Gap: 0.0037\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6566, Val Acc: 0.6256, Val F1: 0.6345, Gap: 0.0310\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.6857, Val Acc: 0.5974, Val F1: 0.6068, Gap: 0.0883\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7132, Val Acc: 0.6747, Val F1: 0.6848, Gap: 0.0385\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7400, Val Acc: 0.6720, Val F1: 0.6814, Gap: 0.0680\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7607, Val Acc: 0.7178, Val F1: 0.7266, Gap: 0.0429\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.7723, Val Acc: 0.6955, Val F1: 0.7059, Gap: 0.0768\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.7875, Val Acc: 0.7365, Val F1: 0.7463, Gap: 0.0509\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.7995, Val Acc: 0.6957, Val F1: 0.7041, Gap: 0.1038\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8137, Val Acc: 0.7161, Val F1: 0.7247, Gap: 0.0976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8262, Val Acc: 0.7332, Val F1: 0.7427, Gap: 0.0930\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8312, Val Acc: 0.7415, Val F1: 0.7497, Gap: 0.0897\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8361, Val Acc: 0.7425, Val F1: 0.7520, Gap: 0.0936\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8440, Val Acc: 0.7360, Val F1: 0.7449, Gap: 0.1080\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▄▄▄▆▇▇█▆▆▇▇█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▃▃▃▅▇▆█▅▅▇▇█▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▃▅██▇▂▄▁▆▆▃▅▃▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▁▂▄▄▅▇▆█▆▆▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▂▄▃▄▇▆▅█▆▆▆▇▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▁▃▃▄▅▆▆█▅▅▇▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▄▃▆▇▇▇▇█▇█▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▄█▆▅▄▇▆▆▇█▅██</td></tr><tr><td>Class_Negative_Recall</td><td>▂▂▅▁▄▇█▆▇▇▆▆█▆▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▄▁▇▅▇▆▇▆▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▁▄▁▅▇▆▅▇▆▇▇▇▆█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▄▁▇▄▇▅▇▅▇▇██▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▁▅▅▇▅▇▅▇███▇</td></tr><tr><td>Class_Positive_Precision</td><td>▂▃▃▁▇▄▆▄▆▄▅▆█▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▅▅▆█▁▆▄▆▄▇▇▆▃▆▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▃▂▅▅▇▆█▆▇████</td></tr><tr><td>Validation F1</td><td>▁▃▄▃▅▅▇▆█▆▇████</td></tr><tr><td>Validation Loss</td><td>█▆▅▆▄▄▁▂▁▃▂▁▂▁▂</td></tr><tr><td>Validation Precision</td><td>▁▃▃▃▆▅▇▆█▆▇████</td></tr><tr><td>Validation Recall</td><td>▁▃▄▃▅▆▇▆█▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.75793</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.65772</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89416</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.67583</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.68261</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.66919</td></tr><tr><td>Class_Negative_F1</td><td>0.82787</td></tr><tr><td>Class_Negative_Precision</td><td>0.88496</td></tr><tr><td>Class_Negative_Recall</td><td>0.77771</td></tr><tr><td>Class_Neutral_F1</td><td>0.69169</td></tr><tr><td>Class_Neutral_Precision</td><td>0.75636</td></tr><tr><td>Class_Neutral_Recall</td><td>0.6372</td></tr><tr><td>Class_Positive_F1</td><td>0.77129</td></tr><tr><td>Class_Positive_Precision</td><td>0.72248</td></tr><tr><td>Class_Positive_Recall</td><td>0.82717</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.84401</td></tr><tr><td>Train Loss</td><td>0.38985</td></tr><tr><td>Validation Accuracy</td><td>0.73603</td></tr><tr><td>Validation F1</td><td>0.74492</td></tr><tr><td>Validation Loss</td><td>0.71334</td></tr><tr><td>Validation Precision</td><td>0.74083</td></tr><tr><td>Validation Recall</td><td>0.76108</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/9lr4ytje' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/9lr4ytje</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_135436-9lr4ytje/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 14:17:34,931] Trial 3 finished with value: 0.7424684159378037 and parameters: {'learning_rate': 0.00017061320170819297, 'weight_decay': 8.173678243120216e-05, 'batch_size': 128, 'num_layers': 3, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_141736-rge8tc7v</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/rge8tc7v' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/rge8tc7v' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/rge8tc7v</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5126, Val Acc: 0.5684, Val F1: 0.5765, Gap: -0.0557\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6218, Val Acc: 0.6282, Val F1: 0.6433, Gap: -0.0064\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6783, Val Acc: 0.6170, Val F1: 0.6281, Gap: 0.0613\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7131, Val Acc: 0.6634, Val F1: 0.6751, Gap: 0.0497\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7502, Val Acc: 0.7100, Val F1: 0.7190, Gap: 0.0402\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7852, Val Acc: 0.6777, Val F1: 0.6882, Gap: 0.1075\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8168, Val Acc: 0.7178, Val F1: 0.7276, Gap: 0.0990\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8378, Val Acc: 0.7298, Val F1: 0.7387, Gap: 0.1079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8597, Val Acc: 0.7196, Val F1: 0.7288, Gap: 0.1401\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8709, Val Acc: 0.7314, Val F1: 0.7391, Gap: 0.1395\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8873, Val Acc: 0.7048, Val F1: 0.7123, Gap: 0.1825\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8972, Val Acc: 0.7393, Val F1: 0.7465, Gap: 0.1579\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9104, Val Acc: 0.7153, Val F1: 0.7243, Gap: 0.1951\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9192, Val Acc: 0.7256, Val F1: 0.7317, Gap: 0.1936\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9251, Val Acc: 0.7285, Val F1: 0.7384, Gap: 0.1966\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▂▆▇▆▇▇▆▇▆▇▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▁▅▇▅▇▇▅█▅▇▆▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▁█▅▃▆▃▃▅▁▅▃▅▃▃</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▂▅▇▆██▇█▆█▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▁█▆▇▆▆▆▇█▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▂▃▆▅█▇▆█▄▇▇▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▄▅▆▇███▇▆██▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▇▇▃█▇▇█▃▅▅█▁▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▁▂▇▄▅▆▅▇▅▆▅█▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▄▅▆▄▆▇▇▇▇█▆▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▃▁▇▃▇▆█▇██▆▇███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▃▅▆▃▅▇▆▇▇█▅▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▄▄▇▃▆▇▇▇▇█▆▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▄▂▆▁▄▆▆▆▆█▄▆▅</td></tr><tr><td>Class_Positive_Recall</td><td>▃▆▃▆▂█▆▃▃▂▃▁▆▃▄</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▃▅▇▅▇█▇█▇█▇▇█</td></tr><tr><td>Validation F1</td><td>▁▄▃▅▇▆▇█▇█▇█▇▇█</td></tr><tr><td>Validation Loss</td><td>▇▄▆▃▁▃▃▁▄▂▅▃███</td></tr><tr><td>Validation Precision</td><td>▁▄▄▅▇▆▇█▇█▇█▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▃▅▇▆████▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.77199</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.72552</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.82482</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.69274</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.70244</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.68331</td></tr><tr><td>Class_Negative_F1</td><td>0.81903</td></tr><tr><td>Class_Negative_Precision</td><td>0.84802</td></tr><tr><td>Class_Negative_Recall</td><td>0.79196</td></tr><tr><td>Class_Neutral_F1</td><td>0.66262</td></tr><tr><td>Class_Neutral_Precision</td><td>0.71078</td></tr><tr><td>Class_Neutral_Recall</td><td>0.62057</td></tr><tr><td>Class_Positive_F1</td><td>0.74542</td></tr><tr><td>Class_Positive_Precision</td><td>0.67736</td></tr><tr><td>Class_Positive_Recall</td><td>0.82868</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.92513</td></tr><tr><td>Train Loss</td><td>0.18673</td></tr><tr><td>Validation Accuracy</td><td>0.7285</td></tr><tr><td>Validation F1</td><td>0.73836</td></tr><tr><td>Validation Loss</td><td>0.96229</td></tr><tr><td>Validation Precision</td><td>0.73282</td></tr><tr><td>Validation Recall</td><td>0.74987</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/rge8tc7v' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/rge8tc7v</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_141736-rge8tc7v/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 14:40:36,862] Trial 4 finished with value: 0.739310009718173 and parameters: {'learning_rate': 0.00016405864496295668, 'weight_decay': 3.1500124812547343e-06, 'batch_size': 128, 'num_layers': 3, 'dropout_rate': 0.2, 'gradient_clip_val': 1.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_144037-ow4jg3cb</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/ow4jg3cb' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/ow4jg3cb' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/ow4jg3cb</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5491, Val Acc: 0.5538, Val F1: 0.5567, Gap: -0.0047\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6409, Val Acc: 0.6744, Val F1: 0.6820, Gap: -0.0336\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6894, Val Acc: 0.6981, Val F1: 0.7070, Gap: -0.0087\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7344, Val Acc: 0.6917, Val F1: 0.7000, Gap: 0.0427\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7671, Val Acc: 0.7038, Val F1: 0.7115, Gap: 0.0633\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7978, Val Acc: 0.7191, Val F1: 0.7276, Gap: 0.0787\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8225, Val Acc: 0.7385, Val F1: 0.7469, Gap: 0.0840\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8442, Val Acc: 0.7058, Val F1: 0.7153, Gap: 0.1384\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8589, Val Acc: 0.7423, Val F1: 0.7479, Gap: 0.1165\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8764, Val Acc: 0.7161, Val F1: 0.7251, Gap: 0.1602\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8890, Val Acc: 0.7291, Val F1: 0.7386, Gap: 0.1599\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8988, Val Acc: 0.7313, Val F1: 0.7404, Gap: 0.1675\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9078, Val Acc: 0.7422, Val F1: 0.7501, Gap: 0.1656\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9167, Val Acc: 0.7242, Val F1: 0.7331, Gap: 0.1924\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9227, Val Acc: 0.7451, Val F1: 0.7516, Gap: 0.1776\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▆▇▆▇█▇█▇███▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▆▅▅▅▇▄█▅▇▅▆▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▁▂▅▅▆▂▇▂▅▃▆▄▂▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▇▆▆▇█▆█▇█▇▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▅▅▆▇▆▆▆▇█▇▇▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▆▆▅▆█▅█▆▇▇▇▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▅▆▇▇▆█▇▇█▇▇▆</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▅▄▅▆▇█▇▇▆▆▆▆▇</td></tr><tr><td>Class_Negative_Recall</td><td>▄▂▅▇▇█▆▁▆▅▇█▇▆▃</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇▆▇▇█▇█▆▇▇█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▄▁▄▅▅▇▆▆▅█▆█▇▆▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁█▇▆▇▆▇▆█▅▆▆▇▆█</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▄▃▅▆▆▆▄▅▆▆█▆▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▆▇▅▄▆▄█▂▃▅▅▂▅</td></tr><tr><td>Class_Positive_Recall</td><td>▅▁▃▂▄▇▅▇▂██▆▇█▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▆▅▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▆▇█▇█▇▇▇█▇█</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇█▇█▇███▇█</td></tr><tr><td>Validation Loss</td><td>█▃▂▂▂▂▁▃▂▅▄▅▄▆▆</td></tr><tr><td>Validation Precision</td><td>▁▆▆▆▆▆▇▆█▆▇▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇▇▇▇▇██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.74646</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.80336</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.69708</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.7163</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.68186</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.75441</td></tr><tr><td>Class_Negative_F1</td><td>0.81043</td></tr><tr><td>Class_Negative_Precision</td><td>0.88803</td></tr><tr><td>Class_Negative_Recall</td><td>0.7453</td></tr><tr><td>Class_Neutral_F1</td><td>0.72022</td></tr><tr><td>Class_Neutral_Precision</td><td>0.6915</td></tr><tr><td>Class_Neutral_Recall</td><td>0.75142</td></tr><tr><td>Class_Positive_F1</td><td>0.76462</td></tr><tr><td>Class_Positive_Precision</td><td>0.76929</td></tr><tr><td>Class_Positive_Recall</td><td>0.76</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.9227</td></tr><tr><td>Train Loss</td><td>0.2121</td></tr><tr><td>Validation Accuracy</td><td>0.74514</td></tr><tr><td>Validation F1</td><td>0.75161</td></tr><tr><td>Validation Loss</td><td>0.95813</td></tr><tr><td>Validation Precision</td><td>0.76681</td></tr><tr><td>Validation Recall</td><td>0.74164</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/ow4jg3cb' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/ow4jg3cb</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_144037-ow4jg3cb/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 15:03:44,910] Trial 5 finished with value: 0.7451409135082604 and parameters: {'learning_rate': 0.00023580787644014077, 'weight_decay': 1.4243928606518173e-06, 'batch_size': 128, 'num_layers': 3, 'dropout_rate': 0.2, 'gradient_clip_val': 1.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_150345-8531izao</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8531izao' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8531izao' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8531izao</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5561, Val Acc: 0.6132, Val F1: 0.6264, Gap: -0.0571\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6752, Val Acc: 0.7042, Val F1: 0.7145, Gap: -0.0290\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7322, Val Acc: 0.7329, Val F1: 0.7426, Gap: -0.0007\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7838, Val Acc: 0.7278, Val F1: 0.7372, Gap: 0.0560\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8122, Val Acc: 0.7578, Val F1: 0.7660, Gap: 0.0545\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8420, Val Acc: 0.7547, Val F1: 0.7608, Gap: 0.0873\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8609, Val Acc: 0.7456, Val F1: 0.7545, Gap: 0.1153\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8796, Val Acc: 0.7170, Val F1: 0.7280, Gap: 0.1627\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8918, Val Acc: 0.7651, Val F1: 0.7732, Gap: 0.1268\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9024, Val Acc: 0.7694, Val F1: 0.7759, Gap: 0.1329\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9132, Val Acc: 0.7773, Val F1: 0.7843, Gap: 0.1359\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9165, Val Acc: 0.7762, Val F1: 0.7849, Gap: 0.1403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9245, Val Acc: 0.7890, Val F1: 0.7957, Gap: 0.1355\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9308, Val Acc: 0.7841, Val F1: 0.7895, Gap: 0.1467\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9359, Val Acc: 0.7551, Val F1: 0.7634, Gap: 0.1808\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▆▆▆▅▆▆▇▇████▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▅▃▇█▆▄▆▇▆▇▅▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▅▅▇▃▁▄█▅▃▅▅▇▄▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▄▆▇▆▆▇█▇▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▆▆▇▇██▆▇▇██▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▄▅▁▅▆▂▂██▆▆▆█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇█▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▂▁▄▆▆▅▇█▇▅▆▇▇▃▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▇▅▆▇▆▄▅▇▆▆▇█▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▅▆▇▆▆▄▇▇█▇██▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▁▄▄▁▃▂▄█▆▆▄▇█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▅▅█▆▇▃▅▆▇▇▇▇▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▆▆▇▇▇▄▇▇▇███▆</td></tr><tr><td>Class_Positive_Precision</td><td>▃▆▄▅█▄▄▁▅▅▆▆▇█▃</td></tr><tr><td>Class_Positive_Recall</td><td>▁▁▅▆▃▇▇█▇▇▆▆▅▅█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇▆▅▇▇█▇██▇</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇▆▅▇▇████▇</td></tr><tr><td>Validation Loss</td><td>█▄▂▃▁▃▄▆▃▄▅▄▄▃▇</td></tr><tr><td>Validation Precision</td><td>▁▅▅▅█▇▆▅▇█████▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▆▆▆▆▇▇▇▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.77672</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.814</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.7427</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.7364</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.72576</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.74735</td></tr><tr><td>Class_Negative_F1</td><td>0.83862</td></tr><tr><td>Class_Negative_Precision</td><td>0.90724</td></tr><tr><td>Class_Negative_Recall</td><td>0.77965</td></tr><tr><td>Class_Neutral_F1</td><td>0.69795</td></tr><tr><td>Class_Neutral_Precision</td><td>0.73569</td></tr><tr><td>Class_Neutral_Recall</td><td>0.66389</td></tr><tr><td>Class_Positive_F1</td><td>0.76751</td></tr><tr><td>Class_Positive_Precision</td><td>0.66593</td></tr><tr><td>Class_Positive_Recall</td><td>0.90566</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.93595</td></tr><tr><td>Train Loss</td><td>0.18251</td></tr><tr><td>Validation Accuracy</td><td>0.7551</td></tr><tr><td>Validation F1</td><td>0.76344</td></tr><tr><td>Validation Loss</td><td>0.93806</td></tr><tr><td>Validation Precision</td><td>0.76972</td></tr><tr><td>Validation Recall</td><td>0.76785</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8531izao' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/8531izao</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_150345-8531izao/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 15:29:45,915] Trial 6 finished with value: 0.7889941690962099 and parameters: {'learning_rate': 0.00020192408176135008, 'weight_decay': 2.6031661728637517e-06, 'batch_size': 64, 'num_layers': 4, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_152947-jheh0ss3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jheh0ss3' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jheh0ss3' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jheh0ss3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5767, Val Acc: 0.6182, Val F1: 0.6279, Gap: -0.0415\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7063, Val Acc: 0.7229, Val F1: 0.7319, Gap: -0.0166\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7714, Val Acc: 0.7189, Val F1: 0.7329, Gap: 0.0525\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8183, Val Acc: 0.7687, Val F1: 0.7758, Gap: 0.0496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8576, Val Acc: 0.7852, Val F1: 0.7933, Gap: 0.0723\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8793, Val Acc: 0.7851, Val F1: 0.7923, Gap: 0.0942\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8984, Val Acc: 0.7896, Val F1: 0.7959, Gap: 0.1088\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9145, Val Acc: 0.7846, Val F1: 0.7919, Gap: 0.1299\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9232, Val Acc: 0.7907, Val F1: 0.7936, Gap: 0.1326\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9317, Val Acc: 0.7775, Val F1: 0.7833, Gap: 0.1542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9364, Val Acc: 0.7764, Val F1: 0.7808, Gap: 0.1600\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9441, Val Acc: 0.7768, Val F1: 0.7818, Gap: 0.1672\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9457, Val Acc: 0.8061, Val F1: 0.8110, Gap: 0.1395\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9538, Val Acc: 0.8054, Val F1: 0.8097, Gap: 0.1484\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9582, Val Acc: 0.7930, Val F1: 0.7978, Gap: 0.1652\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▇▆█▇▇▇▆▇▅▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▆▅▇▆█▇█▅▃██▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▆▄▇▄▅▂▄▁▇█▂▃▃▃</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▆█▇███▇▆████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▇▆█▆▇▇▆█▆▆▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▅▅▆▆▇▆█▅▅▇▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇▇▇█▆▇▇▅██▅</td></tr><tr><td>Class_Negative_Precision</td><td>▆▆▇█▆███▄█▆▃▇▇▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▆▇▆▆▇█▆█▆▇██</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▃▇▇▇▇▆█▇█▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▂▅▄▅▅▅▆▆█▆▅▅▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▃▆▆▆▆▅▇▆▆▆██▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▂▇▆▇▇▆▇▇█▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▁▆▅▆▅▄█▅▆▅█▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▆▁█▄▆▅▆▇▂▇▅▆▃▄▄</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▅▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▅▅▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>Validation Loss</td><td>█▃▄▁▁▂▂▃▃▄▅▅▅▅▅</td></tr><tr><td>Validation Precision</td><td>▁▅▅▆▇▇▇▇▇▆▆▆██▇</td></tr><tr><td>Validation Recall</td><td>▁▅▅▇██▇█▇██▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.80703</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81878</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.79562</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.7556</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.75427</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.75693</td></tr><tr><td>Class_Negative_F1</td><td>0.81293</td></tr><tr><td>Class_Negative_Precision</td><td>0.7809</td></tr><tr><td>Class_Negative_Recall</td><td>0.8477</td></tr><tr><td>Class_Neutral_F1</td><td>0.78418</td></tr><tr><td>Class_Neutral_Precision</td><td>0.7917</td></tr><tr><td>Class_Neutral_Recall</td><td>0.77681</td></tr><tr><td>Class_Positive_F1</td><td>0.8294</td></tr><tr><td>Class_Positive_Precision</td><td>0.85079</td></tr><tr><td>Class_Positive_Recall</td><td>0.80906</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95824</td></tr><tr><td>Train Loss</td><td>0.12458</td></tr><tr><td>Validation Accuracy</td><td>0.793</td></tr><tr><td>Validation F1</td><td>0.79783</td></tr><tr><td>Validation Loss</td><td>0.80855</td></tr><tr><td>Validation Precision</td><td>0.79929</td></tr><tr><td>Validation Recall</td><td>0.79722</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jheh0ss3' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jheh0ss3</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_152947-jheh0ss3/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 15:56:38,178] Trial 7 finished with value: 0.8061224489795918 and parameters: {'learning_rate': 0.00014828854923606448, 'weight_decay': 7.795222076465135e-06, 'batch_size': 128, 'num_layers': 5, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_155639-hpnff0id</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hpnff0id' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hpnff0id' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hpnff0id</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5427, Val Acc: 0.6279, Val F1: 0.6404, Gap: -0.0852\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6335, Val Acc: 0.6622, Val F1: 0.6707, Gap: -0.0287\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6773, Val Acc: 0.6721, Val F1: 0.6832, Gap: 0.0051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7157, Val Acc: 0.6866, Val F1: 0.6965, Gap: 0.0291\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7466, Val Acc: 0.7042, Val F1: 0.7151, Gap: 0.0424\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7713, Val Acc: 0.7274, Val F1: 0.7287, Gap: 0.0439\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7886, Val Acc: 0.6998, Val F1: 0.7118, Gap: 0.0888\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8067, Val Acc: 0.7245, Val F1: 0.7354, Gap: 0.0822\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8212, Val Acc: 0.7433, Val F1: 0.7518, Gap: 0.0779\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8382, Val Acc: 0.7328, Val F1: 0.7425, Gap: 0.1054\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8484, Val Acc: 0.7456, Val F1: 0.7551, Gap: 0.1027\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8616, Val Acc: 0.7484, Val F1: 0.7579, Gap: 0.1132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8673, Val Acc: 0.7657, Val F1: 0.7714, Gap: 0.1017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8752, Val Acc: 0.7549, Val F1: 0.7643, Gap: 0.1203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8820, Val Acc: 0.7658, Val F1: 0.7737, Gap: 0.1162\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▃▄▁▅▇▅▆▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▁▂▁▇█▃▅▅▄▄▆▇▆▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▇▇█▃▁▇▇▅▇▇▆▆▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▄▂▆▆▅▇▇▆▇████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▃▅▄▄▇▆▆▅▆▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▁▄▁█▇▄▇▇▆▇████</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▅▆▆▇▇██▇▇▇█▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▄▁▂▄▆▅▇▆▆▅▇█▆█▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▇▇▇▆█▆▇▇█▆▆█▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▂▃▁▃▃▇▂▄▆▅▆▆█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▅▅▄▆▇▇█▇▆▆▆█</td></tr><tr><td>Class_Neutral_Recall</td><td>▅▄▁▃▃█▂▃▅▃▅▅█▆▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▃▅▄▄▄▅▇▆▇▇▆██</td></tr><tr><td>Class_Positive_Precision</td><td>▄▃▂▂▂█▁▂▄▃▄▄█▅▅</td></tr><tr><td>Class_Positive_Recall</td><td>▂▂▅▇▆▁█▆▇▇▆▆▂▅▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▃▄▅▆▅▆▇▆▇▇█▇█</td></tr><tr><td>Validation F1</td><td>▁▃▃▄▅▆▅▆▇▆▇▇███</td></tr><tr><td>Validation Loss</td><td>█▆▅▅▂▁▃▂▁▄▃▂▁▃▁</td></tr><tr><td>Validation Precision</td><td>▁▁▂▂▅▇▄▅▆▅▆▆█▇▇</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▅▅▆▆▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.77911</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.75666</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.80292</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.72035</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.69787</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.74433</td></tr><tr><td>Class_Negative_F1</td><td>0.84479</td></tr><tr><td>Class_Negative_Precision</td><td>0.88961</td></tr><tr><td>Class_Negative_Recall</td><td>0.80428</td></tr><tr><td>Class_Neutral_F1</td><td>0.73507</td></tr><tr><td>Class_Neutral_Precision</td><td>0.74617</td></tr><tr><td>Class_Neutral_Recall</td><td>0.72429</td></tr><tr><td>Class_Positive_F1</td><td>0.7892</td></tr><tr><td>Class_Positive_Precision</td><td>0.78449</td></tr><tr><td>Class_Positive_Recall</td><td>0.79396</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.88197</td></tr><tr><td>Train Loss</td><td>0.32752</td></tr><tr><td>Validation Accuracy</td><td>0.76579</td></tr><tr><td>Validation F1</td><td>0.7737</td></tr><tr><td>Validation Loss</td><td>0.72135</td></tr><tr><td>Validation Precision</td><td>0.77496</td></tr><tr><td>Validation Recall</td><td>0.77395</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hpnff0id' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/hpnff0id</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_155639-hpnff0id/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 16:20:38,495] Trial 8 finished with value: 0.7657920310981535 and parameters: {'learning_rate': 0.0002950629778338208, 'weight_decay': 4.134420220784157e-05, 'batch_size': 64, 'num_layers': 3, 'dropout_rate': 0.25, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_162039-bac780hv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/bac780hv' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/bac780hv' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/bac780hv</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5684, Val Acc: 0.6317, Val F1: 0.6443, Gap: -0.0633\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6772, Val Acc: 0.6639, Val F1: 0.6744, Gap: 0.0133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7281, Val Acc: 0.7109, Val F1: 0.7170, Gap: 0.0172\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7760, Val Acc: 0.7473, Val F1: 0.7566, Gap: 0.0287\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8127, Val Acc: 0.7490, Val F1: 0.7601, Gap: 0.0637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8403, Val Acc: 0.7318, Val F1: 0.7420, Gap: 0.1086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8627, Val Acc: 0.7765, Val F1: 0.7848, Gap: 0.0862\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8785, Val Acc: 0.7675, Val F1: 0.7766, Gap: 0.1110\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8903, Val Acc: 0.7741, Val F1: 0.7822, Gap: 0.1163\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9013, Val Acc: 0.7670, Val F1: 0.7744, Gap: 0.1343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9106, Val Acc: 0.7566, Val F1: 0.7647, Gap: 0.1541\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9160, Val Acc: 0.7852, Val F1: 0.7923, Gap: 0.1308\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9236, Val Acc: 0.7759, Val F1: 0.7835, Gap: 0.1478\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9284, Val Acc: 0.7692, Val F1: 0.7752, Gap: 0.1593\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9338, Val Acc: 0.7760, Val F1: 0.7834, Gap: 0.1578\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▆▇▆███▇▇██▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▂█▇▄█▇▆▆▅▇▇▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▆▇▁▄█▃▄▇▇█▄▆▄▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▃▇▇▆██▇▇▆█▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▆▅▇▆▆▇▇▇█▇█▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▁▁▇▆▅█▇▆▆▄▇▅▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▇▆▇▇██▇█▇▆█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▂▆▇█▄▇▇▄██▅▁▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▆▄▅▃█▅▇█▅▆▆█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▅▆▅▅▇▆▇▆▆█▇▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▃▃▄▅█▅▇█▆▇▅▆▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▅▇▅▄▆▆▆▅▆██▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▆▆▆▅█▇▇▇▆██▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▄▁▅▇▃▃█▅▅▄▃█▇▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▅▅▅█▇▆▇▇██▇▇▆▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▆▆▆█▇▇▇▇██▇█</td></tr><tr><td>Validation F1</td><td>▁▂▄▆▆▆█▇█▇▇██▇█</td></tr><tr><td>Validation Loss</td><td>█▆▃▁▁▄▁▂▃▄▆▁▄▅▅</td></tr><tr><td>Validation Precision</td><td>▁▂▄▇▆▅█▇▇▇▆█▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▇▆█▇██▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.79684</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.76754</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.82847</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.72904</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.78331</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.6818</td></tr><tr><td>Class_Negative_F1</td><td>0.84678</td></tr><tr><td>Class_Negative_Precision</td><td>0.8877</td></tr><tr><td>Class_Negative_Recall</td><td>0.80946</td></tr><tr><td>Class_Neutral_F1</td><td>0.7434</td></tr><tr><td>Class_Neutral_Precision</td><td>0.7234</td></tr><tr><td>Class_Neutral_Recall</td><td>0.76455</td></tr><tr><td>Class_Positive_F1</td><td>0.80113</td></tr><tr><td>Class_Positive_Precision</td><td>0.75416</td></tr><tr><td>Class_Positive_Recall</td><td>0.85434</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.93379</td></tr><tr><td>Train Loss</td><td>0.18764</td></tr><tr><td>Validation Accuracy</td><td>0.776</td></tr><tr><td>Validation F1</td><td>0.78344</td></tr><tr><td>Validation Loss</td><td>0.80964</td></tr><tr><td>Validation Precision</td><td>0.78322</td></tr><tr><td>Validation Recall</td><td>0.78772</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/bac780hv' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/bac780hv</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_162039-bac780hv/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 16:46:37,182] Trial 9 finished with value: 0.7852283770651117 and parameters: {'learning_rate': 0.00011650536508883602, 'weight_decay': 1.68452609498497e-05, 'batch_size': 64, 'num_layers': 4, 'dropout_rate': 0.25, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_164638-3aa8i9k2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/3aa8i9k2' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/3aa8i9k2' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/3aa8i9k2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5663, Val Acc: 0.6827, Val F1: 0.6945, Gap: -0.1164\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6949, Val Acc: 0.6985, Val F1: 0.7090, Gap: -0.0036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7615, Val Acc: 0.7519, Val F1: 0.7598, Gap: 0.0095\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8061, Val Acc: 0.7690, Val F1: 0.7752, Gap: 0.0371\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8393, Val Acc: 0.7358, Val F1: 0.7459, Gap: 0.1035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8644, Val Acc: 0.7946, Val F1: 0.7983, Gap: 0.0698\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8835, Val Acc: 0.7952, Val F1: 0.8024, Gap: 0.0883\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8988, Val Acc: 0.7987, Val F1: 0.8036, Gap: 0.1001\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9088, Val Acc: 0.7890, Val F1: 0.7962, Gap: 0.1198\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9182, Val Acc: 0.8056, Val F1: 0.8114, Gap: 0.1126\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9242, Val Acc: 0.8027, Val F1: 0.8069, Gap: 0.1215\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9291, Val Acc: 0.7888, Val F1: 0.7945, Gap: 0.1403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9345, Val Acc: 0.8011, Val F1: 0.8057, Gap: 0.1334\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9409, Val Acc: 0.8019, Val F1: 0.8060, Gap: 0.1391\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9459, Val Acc: 0.8073, Val F1: 0.8116, Gap: 0.1386\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▅▆▇▅█▇▇█▇▇▇▆▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁▂▂▃█▅▃▃▆▃▃▄▂▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▇▇▇▇▁▆██▅██▇█▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▃▄▅█▇▆▆█▆▇▆▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅█▆▅▇▇▅▆▇█▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▃▃▁▃█▅▄▅▇▄▄▄▄▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▅▇▆▆▆▇▅▆▇█▆▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▄▅▇▇█▆▂▃▇▇▄▆▄</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▆▆▄▄▄▇▇▇▅▇▇▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▂▁▆▆▂▇▇█▇██▆███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▄▄▄▅▅▅█▇▆▇▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▁▆▆▂▇▇█▅▇█▅▇▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▄▆▂▇▇▇███▅███</td></tr><tr><td>Class_Positive_Precision</td><td>▄▂▆▅▁▆▅█▇▇▆▄▆▆▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▁▅█▅▆▂▄▄▅▇▆▆▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▆▄▇▇█▇██▇███</td></tr><tr><td>Validation F1</td><td>▁▂▅▆▄▇▇█▇██▇███</td></tr><tr><td>Validation Loss</td><td>█▆▃▂▅▂▁▁▅▃▄▅▄▆▅</td></tr><tr><td>Validation Precision</td><td>▁▂▅▆▄█▇█▇█▇▆▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▅▆▇▇▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.80542</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.73209</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89507</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.75334</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80034</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.71155</td></tr><tr><td>Class_Negative_F1</td><td>0.86573</td></tr><tr><td>Class_Negative_Precision</td><td>0.87286</td></tr><tr><td>Class_Negative_Recall</td><td>0.85872</td></tr><tr><td>Class_Neutral_F1</td><td>0.79135</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82417</td></tr><tr><td>Class_Neutral_Recall</td><td>0.76105</td></tr><tr><td>Class_Positive_F1</td><td>0.84218</td></tr><tr><td>Class_Positive_Precision</td><td>0.7928</td></tr><tr><td>Class_Positive_Recall</td><td>0.89811</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94591</td></tr><tr><td>Train Loss</td><td>0.1432</td></tr><tr><td>Validation Accuracy</td><td>0.80734</td></tr><tr><td>Validation F1</td><td>0.8116</td></tr><tr><td>Validation Loss</td><td>0.66974</td></tr><tr><td>Validation Precision</td><td>0.80445</td></tr><tr><td>Validation Recall</td><td>0.8249</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/3aa8i9k2' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/3aa8i9k2</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_164638-3aa8i9k2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 17:14:55,037] Trial 10 finished with value: 0.8073372206025268 and parameters: {'learning_rate': 0.0001005126114088103, 'weight_decay': 1.9266389810995126e-05, 'batch_size': 64, 'num_layers': 5, 'dropout_rate': 0.25, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_171456-xvp5ppuy</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xvp5ppuy' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xvp5ppuy' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xvp5ppuy</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5699, Val Acc: 0.6775, Val F1: 0.6884, Gap: -0.1075\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6976, Val Acc: 0.6947, Val F1: 0.7025, Gap: 0.0028\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7702, Val Acc: 0.7541, Val F1: 0.7604, Gap: 0.0160\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8121, Val Acc: 0.7040, Val F1: 0.7158, Gap: 0.1081\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8418, Val Acc: 0.8009, Val F1: 0.8075, Gap: 0.0409\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8635, Val Acc: 0.8056, Val F1: 0.8116, Gap: 0.0578\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8832, Val Acc: 0.7973, Val F1: 0.8045, Gap: 0.0860\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8944, Val Acc: 0.8112, Val F1: 0.8188, Gap: 0.0832\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9044, Val Acc: 0.8151, Val F1: 0.8198, Gap: 0.0893\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9141, Val Acc: 0.8090, Val F1: 0.8145, Gap: 0.1050\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9237, Val Acc: 0.8172, Val F1: 0.8230, Gap: 0.1065\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9251, Val Acc: 0.8201, Val F1: 0.8258, Gap: 0.1050\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9316, Val Acc: 0.8143, Val F1: 0.8191, Gap: 0.1174\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9361, Val Acc: 0.8229, Val F1: 0.8273, Gap: 0.1132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9392, Val Acc: 0.8183, Val F1: 0.8246, Gap: 0.1210\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▃▁▄▅▇▇▇█▇▇█████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▄▁▄▄▇▆▅▇█▆█▇▆█▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁█▆▆▃▅▇▅▂▅▂▃▅▃▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▂▁▅▄▇▇▆██▇████▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▆█▆█▅▅▇█▅▅▇█▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▁▃▂▆▅▆▇▇▆██▇▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆▆▇█▇▇▇███▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▇▅▆▇▆██▆▇█▆▆▄█</td></tr><tr><td>Class_Negative_Recall</td><td>▃▁▅▅▅▇▅▄▇▆▅▇▅█▅</td></tr><tr><td>Class_Neutral_F1</td><td>▂▄▅▁▇▇▇▇█▇█████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▁▅▆▇▆▆▇▇█▆▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▃▅▁█▇▆▇█▆▇▇█▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▁▆▇▇▇▇▇▇█▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▂▄▄▁█▆▆▇█▆███▇█</td></tr><tr><td>Class_Positive_Recall</td><td>▃▃▅█▁▄▅▃▂▆▁▃▁▄▃</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▂▇▇▇▇█▇█████</td></tr><tr><td>Validation F1</td><td>▁▂▅▂▇▇▇██▇█████</td></tr><tr><td>Validation Loss</td><td>█▆▃▄▂▁▁▃▂▂▃▃▄▄▂</td></tr><tr><td>Validation Precision</td><td>▁▂▄▃▇▇▆▇█▇██▇██</td></tr><tr><td>Validation Recall</td><td>▁▂▅▄▇█▇▇▇█▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.82992</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.76561</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90602</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.765</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.75232</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77811</td></tr><tr><td>Class_Negative_F1</td><td>0.86764</td></tr><tr><td>Class_Negative_Precision</td><td>0.93224</td></tr><tr><td>Class_Negative_Recall</td><td>0.81141</td></tr><tr><td>Class_Neutral_F1</td><td>0.81027</td></tr><tr><td>Class_Neutral_Precision</td><td>0.80571</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81488</td></tr><tr><td>Class_Positive_F1</td><td>0.8501</td></tr><tr><td>Class_Positive_Precision</td><td>0.88293</td></tr><tr><td>Class_Positive_Recall</td><td>0.81962</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.93923</td></tr><tr><td>Train Loss</td><td>0.1594</td></tr><tr><td>Validation Accuracy</td><td>0.81827</td></tr><tr><td>Validation F1</td><td>0.82458</td></tr><tr><td>Validation Loss</td><td>0.57947</td></tr><tr><td>Validation Precision</td><td>0.82776</td></tr><tr><td>Validation Recall</td><td>0.82601</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xvp5ppuy' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xvp5ppuy</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_171456-xvp5ppuy/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 17:42:55,023] Trial 11 finished with value: 0.8228862973760933 and parameters: {'learning_rate': 0.0001133434816080723, 'weight_decay': 2.017099896608987e-05, 'batch_size': 64, 'num_layers': 5, 'dropout_rate': 0.25, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8327259475218659.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_174256-jb95zmje</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jb95zmje' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jb95zmje' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jb95zmje</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5625, Val Acc: 0.6379, Val F1: 0.6469, Gap: -0.0754\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7008, Val Acc: 0.7263, Val F1: 0.7354, Gap: -0.0255\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7654, Val Acc: 0.7423, Val F1: 0.7503, Gap: 0.0230\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8096, Val Acc: 0.7325, Val F1: 0.7443, Gap: 0.0771\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8317, Val Acc: 0.7943, Val F1: 0.8006, Gap: 0.0374\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8597, Val Acc: 0.7806, Val F1: 0.7887, Gap: 0.0791\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8765, Val Acc: 0.8147, Val F1: 0.8206, Gap: 0.0618\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8896, Val Acc: 0.8166, Val F1: 0.8231, Gap: 0.0731\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8998, Val Acc: 0.8045, Val F1: 0.8094, Gap: 0.0953\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9102, Val Acc: 0.8152, Val F1: 0.8198, Gap: 0.0949\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9148, Val Acc: 0.8152, Val F1: 0.8203, Gap: 0.0996\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9234, Val Acc: 0.8180, Val F1: 0.8229, Gap: 0.1053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9239, Val Acc: 0.8054, Val F1: 0.8100, Gap: 0.1185\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9293, Val Acc: 0.8336, Val F1: 0.8392, Gap: 0.0957\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9341, Val Acc: 0.8269, Val F1: 0.8315, Gap: 0.1072\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▅▆▆▇▇▇▆▇▇▇▇█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▄▆▅▇█▇▅▆▆█▇█▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▁▇▅▇▄▂▅█▇▆▃▃▄▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▅▅▆▇▇▇▆▇▇█▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅█▆▇▇▆▇▇▇▇███</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▅▄▆▇▇█▆▇▇█▇█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▇▆▇▇▇▇▇▆▆▄█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▄▄▆▇██▇▇▇▇▅▄▁█▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▅▄▅▆▆▆▆▇▇█▆▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▄▃▇▅▇▇▇█▇▇▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▅▃▆▆▆██████▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▄▃▇▅█▇▇▇▇▇▇██</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▃▇▅▇▇▇██▇▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▃▁▇▃▇▇▆▇▇▇▆▇█</td></tr><tr><td>Class_Positive_Recall</td><td>▃▂▆█▁▇▄▄▅▅▄▄▅▅▃</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▄▇▆▇▇▇▇▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▄▅▅▇▆▇▇▇▇▇▇▇██</td></tr><tr><td>Validation Loss</td><td>█▄▃▃▂▃▁▂▂▃▂▃▃▁▂</td></tr><tr><td>Validation Precision</td><td>▁▄▅▅▇▆▇▇▇▇▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▄▅▅▆▆▇▇▇██▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83305</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.77096</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90602</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.78069</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81356</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.75038</td></tr><tr><td>Class_Negative_F1</td><td>0.86518</td></tr><tr><td>Class_Negative_Precision</td><td>0.86323</td></tr><tr><td>Class_Negative_Recall</td><td>0.86714</td></tr><tr><td>Class_Neutral_F1</td><td>0.81702</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81051</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82363</td></tr><tr><td>Class_Positive_F1</td><td>0.86137</td></tr><tr><td>Class_Positive_Precision</td><td>0.88978</td></tr><tr><td>Class_Positive_Recall</td><td>0.83472</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.93409</td></tr><tr><td>Train Loss</td><td>0.17614</td></tr><tr><td>Validation Accuracy</td><td>0.8269</td></tr><tr><td>Validation F1</td><td>0.83146</td></tr><tr><td>Validation Loss</td><td>0.57491</td></tr><tr><td>Validation Precision</td><td>0.82961</td></tr><tr><td>Validation Recall</td><td>0.83638</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jb95zmje' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/jb95zmje</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_174256-jb95zmje/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 18:10:55,862] Trial 12 finished with value: 0.8335762876579204 and parameters: {'learning_rate': 0.0001328976971752646, 'weight_decay': 2.2429207118419066e-05, 'batch_size': 64, 'num_layers': 5, 'dropout_rate': 0.25, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 12 with value: 0.8335762876579204.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_181056-a4ou67a3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/a4ou67a3' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/a4ou67a3' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/a4ou67a3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5642, Val Acc: 0.5871, Val F1: 0.5887, Gap: -0.0229\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6927, Val Acc: 0.7218, Val F1: 0.7338, Gap: -0.0291\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7609, Val Acc: 0.7632, Val F1: 0.7693, Gap: -0.0023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7976, Val Acc: 0.7566, Val F1: 0.7627, Gap: 0.0410\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8262, Val Acc: 0.7809, Val F1: 0.7862, Gap: 0.0453\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8441, Val Acc: 0.8053, Val F1: 0.8109, Gap: 0.0389\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8605, Val Acc: 0.8109, Val F1: 0.8167, Gap: 0.0496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8727, Val Acc: 0.8005, Val F1: 0.8067, Gap: 0.0722\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8863, Val Acc: 0.7986, Val F1: 0.8060, Gap: 0.0878\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8983, Val Acc: 0.8161, Val F1: 0.8204, Gap: 0.0822\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9021, Val Acc: 0.8127, Val F1: 0.8198, Gap: 0.0894\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9082, Val Acc: 0.8138, Val F1: 0.8176, Gap: 0.0944\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9136, Val Acc: 0.8089, Val F1: 0.8146, Gap: 0.1047\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9172, Val Acc: 0.8184, Val F1: 0.8246, Gap: 0.0988\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9245, Val Acc: 0.8342, Val F1: 0.8380, Gap: 0.0903\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▅▅▆▇▇▆█▇█▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▄▃▄▅▆▅▆▅▇█▆▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▆▇█▇▆▆▇▆▇▄▁▆▅▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▅▅▆▇▇▆▇▇██▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▂▁▅▄▆▇▇▅▆▇▇▆▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▅▅▅▆▇▇█▇██▇▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▅▇▆▇▇▇▇▇█▅▇█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▂▆▆▅▆██▅▇▂▆▇▄</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▆▅▄▆▆▅▄▇▅▇▆▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇▇▇█▇█▇█▇█▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▆█▇▇▇▇█▇▇██▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▇▆▇█▇▇▆█▇▇▇██</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▇▇█▇█▆█▇█▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▇▆▇█▇█▅█▆▇▆▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▇▁▂▅▅▄▅▄█▃▆▇▇▆▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇▇▇▇█▇▇▇██</td></tr><tr><td>Validation Loss</td><td>█▄▃▂▂▁▁▁▁▁▁▂▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▅▆▆▆▇▇▇▇▇▇█▇██</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▇▇▇▇▇█▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84497</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83964</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.85036</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80568</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82618</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78618</td></tr><tr><td>Class_Negative_F1</td><td>0.86542</td></tr><tr><td>Class_Negative_Precision</td><td>0.85</td></tr><tr><td>Class_Negative_Recall</td><td>0.8814</td></tr><tr><td>Class_Neutral_F1</td><td>0.81889</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82974</td></tr><tr><td>Class_Neutral_Recall</td><td>0.80832</td></tr><tr><td>Class_Positive_F1</td><td>0.85516</td></tr><tr><td>Class_Positive_Precision</td><td>0.82967</td></tr><tr><td>Class_Positive_Recall</td><td>0.88226</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.92446</td></tr><tr><td>Train Loss</td><td>0.20309</td></tr><tr><td>Validation Accuracy</td><td>0.83418</td></tr><tr><td>Validation F1</td><td>0.83802</td></tr><tr><td>Validation Loss</td><td>0.53278</td></tr><tr><td>Validation Precision</td><td>0.83504</td></tr><tr><td>Validation Recall</td><td>0.84171</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/a4ou67a3' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/a4ou67a3</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_181056-a4ou67a3/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 18:38:54,571] Trial 13 finished with value: 0.8341836734693877 and parameters: {'learning_rate': 0.00012917707921813353, 'weight_decay': 3.546931466671693e-05, 'batch_size': 64, 'num_layers': 5, 'dropout_rate': 0.25, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 13 with value: 0.8341836734693877.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250730_183855-xpkzj0i4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xpkzj0i4' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xpkzj0i4' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xpkzj0i4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5614, Val Acc: 0.6403, Val F1: 0.6463, Gap: -0.0789\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6956, Val Acc: 0.7171, Val F1: 0.7270, Gap: -0.0214\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7657, Val Acc: 0.7524, Val F1: 0.7574, Gap: 0.0133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8100, Val Acc: 0.7812, Val F1: 0.7883, Gap: 0.0288\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8397, Val Acc: 0.7957, Val F1: 0.8014, Gap: 0.0441\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8673, Val Acc: 0.7963, Val F1: 0.8035, Gap: 0.0710\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8845, Val Acc: 0.7895, Val F1: 0.7945, Gap: 0.0950\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8973, Val Acc: 0.7953, Val F1: 0.8008, Gap: 0.1020\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9082, Val Acc: 0.8208, Val F1: 0.8262, Gap: 0.0874\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9158, Val Acc: 0.8078, Val F1: 0.8143, Gap: 0.1080\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9232, Val Acc: 0.7903, Val F1: 0.7953, Gap: 0.1329\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9316, Val Acc: 0.8133, Val F1: 0.8191, Gap: 0.1183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9314, Val Acc: 0.8030, Val F1: 0.8068, Gap: 0.1284\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9407, Val Acc: 0.8228, Val F1: 0.8278, Gap: 0.1179\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9427, Val Acc: 0.8203, Val F1: 0.8261, Gap: 0.1224\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▄▇▇▇▆▇██▇█▆██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▃▅▆▅▅▆█▇▅█▄█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▃▇▇▄▆▇▅▁▄▇▂█▁▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▅▇▇▇▆▇██▇█▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▆▆▃▆▆▅▅█▆▆▆▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▄▆▆▇▆▆██▅█▆█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆▆▇▇▇▆██▇▇▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▆▄▆▇█▅▆▇█▆▅▆▆▇</td></tr><tr><td>Class_Negative_Recall</td><td>▃▁▇▆▆▅█▆█▇██▇▇▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▆▆▇█▇▇█▇▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▆▇▇▇▆▇█▆▇█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▆▆▆▇▆▇▇▅▆▆▇█▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▆▆▇█▇▇█▇▆▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▅▅▄█▅▅▆▄▃▅▆▆▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▅▅▇▃▆▇▆▇▇▇▆▆█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▇▇▇▇█▇▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▇▇▇▇█▇▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▄▃▂▁▃▃▃▂▃▄▃▂▄▂</td></tr><tr><td>Validation Precision</td><td>▁▄▅▆▇▇▆▇█▇▆▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇▇▇█▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8329</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.8</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86861</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.78544</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.79291</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77811</td></tr><tr><td>Class_Negative_F1</td><td>0.87212</td></tr><tr><td>Class_Negative_Precision</td><td>0.91224</td></tr><tr><td>Class_Negative_Recall</td><td>0.83539</td></tr><tr><td>Class_Neutral_F1</td><td>0.79296</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81805</td></tr><tr><td>Class_Neutral_Recall</td><td>0.76937</td></tr><tr><td>Class_Positive_F1</td><td>0.84715</td></tr><tr><td>Class_Positive_Precision</td><td>0.78944</td></tr><tr><td>Class_Positive_Recall</td><td>0.91396</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94275</td></tr><tr><td>Train Loss</td><td>0.1523</td></tr><tr><td>Validation Accuracy</td><td>0.82034</td></tr><tr><td>Validation F1</td><td>0.82611</td></tr><tr><td>Validation Loss</td><td>0.56873</td></tr><tr><td>Validation Precision</td><td>0.82253</td></tr><tr><td>Validation Recall</td><td>0.83309</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_14</strong> at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xpkzj0i4' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1/runs/xpkzj0i4</a><br> View project at: <a href='https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1' target=\"_blank\">https://wandb.ai/yardenshalom-tel-aviv-university/cardiffnlp_new5_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250730_183855-xpkzj0i4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-07-30 19:06:55,436] Trial 14 finished with value: 0.8227648202137998 and parameters: {'learning_rate': 0.00013871923622405644, 'weight_decay': 1.106774053285717e-05, 'batch_size': 64, 'num_layers': 5, 'dropout_rate': 0.25, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 13 with value: 0.8341836734693877.\n"]},{"ename":"NameError","evalue":"name 'study' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-44-3727589817.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ============ RUN THE STUDY ============\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"best_model_trial_{best_trial.number}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Best Results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 1:\")\n","study1 = optuna.create_study(direction=\"maximize\")\n","study1.optimize(objective, n_trials=15)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study1.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model1.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")"]},{"cell_type":"markdown","metadata":{"id":"lT4rwMjQuzER"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"UWwmcnKog8Db"},"source":["### **Summary of Results:**\n","\n","| Metric                          | Experiment 0 | Experiment 1 |\n","| ------------------------------- | ------------ | ------------ |\n","| **Validation Accuracy** (mean)  | 76.95%       | **78.61%**   |\n","| **Validation F1** (mean)        | 77.53%       | **79.26%**   |\n","| **Train Accuracy** (mean)       | 84.41%       | **92.33%**   |\n","| **Validation Recall** (mean)    | 78.08%       | **79.74%**   |\n","| **Validation Precision** (mean) | 77.51%       | **79.26%**   |\n","\n","Experiment 1 clearly outperforms across all metrics, especially in terms of overfitting reduction and generalization."]},{"cell_type":"markdown","metadata":{"id":"FS8Kvy2dvDCa"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"O4iAyCkevERm"},"source":["# **SECONED STUDY:**"]},{"cell_type":"markdown","metadata":{"id":"LMjWMsCsl5LO"},"source":["\n","Following the results of Experiment 0, we observed that shallow classifier heads (0–1 layers) achieved strong F1 scores across sentiment classes, while maintaining minimal overfitting. Given this, we chose to focus the next hyperparameter search exclusively on shallow architectures, and to refine only the best-performing settings.\n","\n","The goal of this **targeted run is to isolate the most impactful tuning knobs within the low-complexity regime** — such as dropout regularization, batch size, learning rate, and weight decay — while keeping model depth and clipping values fixed. This allows us to extract maximum performance from the shallow setting before moving on to more complex solutions such as data augmentation or architectural changes."]},{"cell_type":"markdown","metadata":{"id":"9jHMntZH3q_r"},"source":["Run:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1dIWEPzO3eQX","outputId":"4a1dce2f-9d1e-4dc7-f534-4f754a1c7655"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 16:03:14,209] A new study created in memory with name: no-name-6d0daf2d-fccd-4db1-baea-d966e442d1ee\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 2:\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_160317-nugorp7q</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nugorp7q' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nugorp7q' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nugorp7q</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5682, Val Acc: 0.6770, Val F1: 0.6878, Gap: -0.1088\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7303, Val Acc: 0.7714, Val F1: 0.7801, Gap: -0.0411\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7913, Val Acc: 0.7699, Val F1: 0.7773, Gap: 0.0213\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8286, Val Acc: 0.8066, Val F1: 0.8117, Gap: 0.0220\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8546, Val Acc: 0.8087, Val F1: 0.8133, Gap: 0.0459\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8728, Val Acc: 0.8276, Val F1: 0.8331, Gap: 0.0452\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8884, Val Acc: 0.8478, Val F1: 0.8521, Gap: 0.0406\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9013, Val Acc: 0.8325, Val F1: 0.8363, Gap: 0.0688\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9133, Val Acc: 0.8311, Val F1: 0.8358, Gap: 0.0821\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9211, Val Acc: 0.8347, Val F1: 0.8380, Gap: 0.0864\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9314, Val Acc: 0.8560, Val F1: 0.8598, Gap: 0.0753\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9372, Val Acc: 0.8624, Val F1: 0.8653, Gap: 0.0748\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9426, Val Acc: 0.8618, Val F1: 0.8651, Gap: 0.0809\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9472, Val Acc: 0.8455, Val F1: 0.8489, Gap: 0.1017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9506, Val Acc: 0.8474, Val F1: 0.8508, Gap: 0.1031\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▄▅▅▇▇▆▇▆███▇▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▃▄▄▆▆▄▅▅▇█▇▆▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▁▇▆█▇▆█▇▇▅▄▅▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▄▆▆▇▇▆▇▇███▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▄▆▆▆▇▆▇▇▇█▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▄▅▅▇▇▅▆▆█▇█▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▇▇▇█▇███████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆▅▇█▇▇█▇▇▃▅▅█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▄▅▅▃▆▅▄▅▅█▆▇▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▄▆▆▇▇▇▇▇███▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▆▆▇▆▆▇▇▇▇▇▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▃▆▆▇▇▇▆▇███▆█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▄▆▆▇▇█▆▇███▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▂▄▄▅▆▇▄▅▇▇█▄█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▇▆▇▆▆▆██▆▇▅█▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▅▆▆▇▇▇▇▇███▇▇</td></tr><tr><td>Validation F1</td><td>▁▅▅▆▆▇▇▇▇▇███▇▇</td></tr><tr><td>Validation Loss</td><td>█▅▄▂▂▁▁▂▂▂▁▂▁▂▃</td></tr><tr><td>Validation Precision</td><td>▁▅▄▆▆▇▇▇▇▇███▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83529</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.75055</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.94161</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.7964</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81335</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78013</td></tr><tr><td>Class_Negative_F1</td><td>0.88063</td></tr><tr><td>Class_Negative_Precision</td><td>0.93842</td></tr><tr><td>Class_Negative_Recall</td><td>0.82955</td></tr><tr><td>Class_Neutral_F1</td><td>0.8515</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85356</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84945</td></tr><tr><td>Class_Positive_F1</td><td>0.89023</td></tr><tr><td>Class_Positive_Precision</td><td>0.89294</td></tr><tr><td>Class_Positive_Recall</td><td>0.88755</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95055</td></tr><tr><td>Train Loss</td><td>0.1425</td></tr><tr><td>Validation Accuracy</td><td>0.84742</td></tr><tr><td>Validation F1</td><td>0.85081</td></tr><tr><td>Validation Loss</td><td>0.52212</td></tr><tr><td>Validation Precision</td><td>0.84976</td></tr><tr><td>Validation Recall</td><td>0.85766</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nugorp7q' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nugorp7q</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_160317-nugorp7q/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 16:45:00,920] Trial 0 finished with value: 0.8623663751214772 and parameters: {'learning_rate': 1.0259396288251191e-05, 'weight_decay': 3.811818485664568e-05, 'patience': 5, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 0 with value: 0.8623663751214772.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_164502-6p1vvkvg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/6p1vvkvg' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/6p1vvkvg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/6p1vvkvg</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6177, Val Acc: 0.7309, Val F1: 0.7408, Gap: -0.1133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7840, Val Acc: 0.8110, Val F1: 0.8173, Gap: -0.0270\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8409, Val Acc: 0.8336, Val F1: 0.8386, Gap: 0.0074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8757, Val Acc: 0.8322, Val F1: 0.8374, Gap: 0.0435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9000, Val Acc: 0.8569, Val F1: 0.8609, Gap: 0.0431\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9160, Val Acc: 0.8529, Val F1: 0.8566, Gap: 0.0631\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9291, Val Acc: 0.8534, Val F1: 0.8566, Gap: 0.0758\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9392, Val Acc: 0.8619, Val F1: 0.8645, Gap: 0.0773\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9495, Val Acc: 0.8534, Val F1: 0.8563, Gap: 0.0961\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9556, Val Acc: 0.8550, Val F1: 0.8584, Gap: 0.1007\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9622, Val Acc: 0.8508, Val F1: 0.8542, Gap: 0.1114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9646, Val Acc: 0.8639, Val F1: 0.8671, Gap: 0.1006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9700, Val Acc: 0.8497, Val F1: 0.8527, Gap: 0.1203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9728, Val Acc: 0.8590, Val F1: 0.8626, Gap: 0.1139\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9757, Val Acc: 0.8350, Val F1: 0.8397, Gap: 0.1407\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▆▇▇▇▇▇▇▇█▇█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▄▄▅▄▅█▄▅▄▆▄▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▂▇▆▇▇▆▁▇▆▇▆█▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▆▆▇▇▇█▇▇▇█▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▅▃▄▄█▄▆▅▆▆█▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▆▆▇▇▆█▆▇▆▇▆▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆█▇▆▇▇▇▇█▅▆▂</td></tr><tr><td>Class_Negative_Precision</td><td>▄▆▇█▇▆▅▇▆▆▇▆▄▆▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▃▁▄▄▅▄▅▄▄▅▆▄█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▆██████████▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▆▆██▆▇██▇▇█▆█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▆▆▇▇██▇▆▇█▇█▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▆██████▇█▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▆▆▇███▇▇▇█▇▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▆▇▇▇█▁▁▃▇▆▅▂▃▇▂</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆█▇▇█▇█▇█▇█▆</td></tr><tr><td>Validation F1</td><td>▁▅▆▆█▇▇█▇█▇█▇█▆</td></tr><tr><td>Validation Loss</td><td>▇▃▁▂▁▁▂▃▃▃▆▄▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▆▇▇▇█▇▇▇█▇▇▆</td></tr><tr><td>Validation Recall</td><td>▁▅▇▆██▇▇██▇███▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86221</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85947</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86496</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81491</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86343</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77156</td></tr><tr><td>Class_Negative_F1</td><td>0.82545</td></tr><tr><td>Class_Negative_Precision</td><td>0.73998</td></tr><tr><td>Class_Negative_Recall</td><td>0.93325</td></tr><tr><td>Class_Neutral_F1</td><td>0.8223</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87236</td></tr><tr><td>Class_Neutral_Recall</td><td>0.77768</td></tr><tr><td>Class_Positive_F1</td><td>0.87366</td></tr><tr><td>Class_Positive_Precision</td><td>0.85808</td></tr><tr><td>Class_Positive_Recall</td><td>0.88981</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97573</td></tr><tr><td>Train Loss</td><td>0.07392</td></tr><tr><td>Validation Accuracy</td><td>0.83503</td></tr><tr><td>Validation F1</td><td>0.83971</td></tr><tr><td>Validation Loss</td><td>0.68491</td></tr><tr><td>Validation Precision</td><td>0.83866</td></tr><tr><td>Validation Recall</td><td>0.84745</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/6p1vvkvg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/6p1vvkvg</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_164502-6p1vvkvg/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 17:26:50,581] Trial 1 finished with value: 0.8639455782312925 and parameters: {'learning_rate': 2.032264887513841e-05, 'weight_decay': 3.7232431785234417e-06, 'patience': 5, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_172651-klncq89x</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/klncq89x' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/klncq89x' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/klncq89x</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6328, Val Acc: 0.7632, Val F1: 0.7719, Gap: -0.1304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7984, Val Acc: 0.7761, Val F1: 0.7844, Gap: 0.0222\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8525, Val Acc: 0.8216, Val F1: 0.8252, Gap: 0.0310\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8875, Val Acc: 0.8417, Val F1: 0.8448, Gap: 0.0458\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9099, Val Acc: 0.8438, Val F1: 0.8479, Gap: 0.0662\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9263, Val Acc: 0.8547, Val F1: 0.8580, Gap: 0.0715\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9391, Val Acc: 0.8414, Val F1: 0.8451, Gap: 0.0977\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9468, Val Acc: 0.8428, Val F1: 0.8460, Gap: 0.1040\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9534, Val Acc: 0.8412, Val F1: 0.8455, Gap: 0.1122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9598, Val Acc: 0.8449, Val F1: 0.8484, Gap: 0.1150\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9638, Val Acc: 0.8431, Val F1: 0.8467, Gap: 0.1208\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9686, Val Acc: 0.8530, Val F1: 0.8561, Gap: 0.1156\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9720, Val Acc: 0.8601, Val F1: 0.8631, Gap: 0.1119\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9727, Val Acc: 0.8575, Val F1: 0.8618, Gap: 0.1152\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9769, Val Acc: 0.8537, Val F1: 0.8566, Gap: 0.1232\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▃▅▇▇▇▇▇▇▆▇██▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▂▄▆█▆▅▆▆▅▆▇▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▆██▇▁▇▇▆▅▇▆▅▆▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▄▆▇█▇▇▇▇▆▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▇▅▇█▆▇▇█▆▆██▆█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▃▅▆█▆▅▆▇▆▅▇█▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▅▇█▅▅▅▇▄▆▆▇▇▆</td></tr><tr><td>Class_Negative_Precision</td><td>▁█▆▇█▂▂▃█▅▆▄▅▆▄</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▃▅▅▇▇▆▄▃▄▆▇▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▃▁▇█▇█▇▇▆██████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▅▄▆▇█▇▅▆▅▆▇▆▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▁▇█▆▇▅▆▆▇█▇▇▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▄▁▇▇▆█▇▇▆▇▇█▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▇▁▇█▅▇▆▅▄▇█▆▆▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁█▄▃▇▆▇▇█▅▃▆▇▅▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▇▇█▇▇▇▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▂▅▇▇█▇▇▇▇▇▇██▇</td></tr><tr><td>Validation Loss</td><td>▇▅▂▂▁▁▂▄▄▇▆▆▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▂▅▇▇█▆▆▇▇▇▇██▇</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▇▇▇▇▇▇▆████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85814</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.82259</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8969</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82633</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85699</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79778</td></tr><tr><td>Class_Negative_F1</td><td>0.87936</td></tr><tr><td>Class_Negative_Precision</td><td>0.86852</td></tr><tr><td>Class_Negative_Recall</td><td>0.89047</td></tr><tr><td>Class_Neutral_F1</td><td>0.84313</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8719</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81619</td></tr><tr><td>Class_Positive_F1</td><td>0.87585</td></tr><tr><td>Class_Positive_Precision</td><td>0.83265</td></tr><tr><td>Class_Positive_Recall</td><td>0.92377</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97695</td></tr><tr><td>Train Loss</td><td>0.07245</td></tr><tr><td>Validation Accuracy</td><td>0.85374</td></tr><tr><td>Validation F1</td><td>0.85656</td></tr><tr><td>Validation Loss</td><td>0.62364</td></tr><tr><td>Validation Precision</td><td>0.85053</td></tr><tr><td>Validation Recall</td><td>0.86502</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/klncq89x' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/klncq89x</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_172651-klncq89x/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 18:08:46,188] Trial 2 finished with value: 0.8600583090379009 and parameters: {'learning_rate': 2.609775993813414e-05, 'weight_decay': 2.6086187134551772e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_180847-rqojacrk</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/rqojacrk' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/rqojacrk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/rqojacrk</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6122, Val Acc: 0.6928, Val F1: 0.7043, Gap: -0.0806\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7691, Val Acc: 0.7939, Val F1: 0.8008, Gap: -0.0248\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8259, Val Acc: 0.8016, Val F1: 0.8066, Gap: 0.0243\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8617, Val Acc: 0.8440, Val F1: 0.8486, Gap: 0.0177\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8887, Val Acc: 0.8285, Val F1: 0.8324, Gap: 0.0602\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9059, Val Acc: 0.8519, Val F1: 0.8557, Gap: 0.0540\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9215, Val Acc: 0.8490, Val F1: 0.8520, Gap: 0.0725\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9327, Val Acc: 0.8304, Val F1: 0.8341, Gap: 0.1023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9416, Val Acc: 0.8465, Val F1: 0.8495, Gap: 0.0952\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9481, Val Acc: 0.8512, Val F1: 0.8550, Gap: 0.0969\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9551, Val Acc: 0.8382, Val F1: 0.8427, Gap: 0.1169\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9601, Val Acc: 0.8482, Val F1: 0.8519, Gap: 0.1119\n","Early stopping at epoch 12\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▅▇▆█▇▆▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▄▇▅▇▇▅▇█▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▂█▁▇▃▂▇▄▁▃▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▅█▇██▇██▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▇▆▆█▇▇▇████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▄█▅██▆▇▇▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▇█▇▇▇▆▇▆▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄▄▇▇█▅▄▄▃▅▅▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▅▆▆▇▇▇▇▆▅█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▇██▇██▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▄▅▆▆▇█▅▅▄▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▆▇▆▇▇▅███▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▇▆██▇████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▄▆▃▆▆▄█▇▅▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▅▆▅█▅▅▇▃▅▇▅</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆█▇██▇██▇█</td></tr><tr><td>Validation F1</td><td>▁▅▆█▇██▇██▇█</td></tr><tr><td>Validation Loss</td><td>█▄▃▁▂▁▂▄▃▄▅▅</td></tr><tr><td>Validation Precision</td><td>▁▅▆█▇██▇██▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▇██▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86136</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.82241</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.9042</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82305</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8399</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80686</td></tr><tr><td>Class_Negative_F1</td><td>0.86034</td></tr><tr><td>Class_Negative_Precision</td><td>0.82715</td></tr><tr><td>Class_Negative_Recall</td><td>0.89631</td></tr><tr><td>Class_Neutral_F1</td><td>0.83525</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87795</td></tr><tr><td>Class_Neutral_Recall</td><td>0.7965</td></tr><tr><td>Class_Positive_F1</td><td>0.87935</td></tr><tr><td>Class_Positive_Precision</td><td>0.86275</td></tr><tr><td>Class_Positive_Recall</td><td>0.8966</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96009</td></tr><tr><td>Train Loss</td><td>0.12401</td></tr><tr><td>Validation Accuracy</td><td>0.84815</td></tr><tr><td>Validation F1</td><td>0.85187</td></tr><tr><td>Validation Loss</td><td>0.57616</td></tr><tr><td>Validation Precision</td><td>0.84603</td></tr><tr><td>Validation Recall</td><td>0.86009</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/rqojacrk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/rqojacrk</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_180847-rqojacrk/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 18:44:11,827] Trial 3 finished with value: 0.8519193391642371 and parameters: {'learning_rate': 1.1600696216596856e-05, 'weight_decay': 1.0980564129931186e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_184416-09wto8xa</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/09wto8xa' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/09wto8xa' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/09wto8xa</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6330, Val Acc: 0.7439, Val F1: 0.7537, Gap: -0.1109\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7836, Val Acc: 0.8086, Val F1: 0.8157, Gap: -0.0249\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8387, Val Acc: 0.8316, Val F1: 0.8368, Gap: 0.0071\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8692, Val Acc: 0.8241, Val F1: 0.8287, Gap: 0.0451\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8940, Val Acc: 0.8525, Val F1: 0.8570, Gap: 0.0415\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9152, Val Acc: 0.8462, Val F1: 0.8504, Gap: 0.0690\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9259, Val Acc: 0.8219, Val F1: 0.8262, Gap: 0.1040\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9399, Val Acc: 0.8565, Val F1: 0.8597, Gap: 0.0833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9477, Val Acc: 0.8539, Val F1: 0.8575, Gap: 0.0938\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9529, Val Acc: 0.8562, Val F1: 0.8597, Gap: 0.0967\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9573, Val Acc: 0.8505, Val F1: 0.8539, Gap: 0.1068\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9617, Val Acc: 0.8601, Val F1: 0.8624, Gap: 0.1016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9660, Val Acc: 0.8403, Val F1: 0.8445, Gap: 0.1257\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9676, Val Acc: 0.8427, Val F1: 0.8469, Gap: 0.1249\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9733, Val Acc: 0.8556, Val F1: 0.8594, Gap: 0.1177\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▆▅▇▆▅█▇▇█▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▃▁▄▂▁▅▃▃▅█▆▄▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▃▅▇▆█▇▅▇▇▆▁▄▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▆▅▇▆▅█▇▇▇█▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▅▅▅▅█▇▇▆█▆█▆▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▅▄▆▅▁▆▅▅▅█▃▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▇█▇▆▇▇█▅▇▂▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▅▆▆▇█▇▇▆▇▇▄▆▁▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▄▄▄▄▄▆▅▅▆▅█▄▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▆▆▇▇▆███▇█▇▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▆█▇▇▆█▇██▆█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▆▄▆▆▅▇▇▇▆█▆▅▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▆██▅▇██▇█▇▆▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▆▄▆▇▃▆▇▇▆█▆▅▆</td></tr><tr><td>Class_Positive_Recall</td><td>▅▁▄▇▆▄█▆▅▅▇▃▅▇▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆█▇▆███▇█▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▆▆█▇▆███▇█▇▇█</td></tr><tr><td>Validation Loss</td><td>▇▃▂▃▁▃▅▃▃▅▆▅█▇█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▅▇▆▅▇▇▇▆█▆▆▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆█▇▆████▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87124</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85702</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88595</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83669</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84552</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82804</td></tr><tr><td>Class_Negative_F1</td><td>0.87643</td></tr><tr><td>Class_Negative_Precision</td><td>0.8866</td></tr><tr><td>Class_Negative_Recall</td><td>0.86649</td></tr><tr><td>Class_Neutral_F1</td><td>0.8393</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85276</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82626</td></tr><tr><td>Class_Positive_F1</td><td>0.87319</td></tr><tr><td>Class_Positive_Precision</td><td>0.83972</td></tr><tr><td>Class_Positive_Recall</td><td>0.90943</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.9733</td></tr><tr><td>Train Loss</td><td>0.09556</td></tr><tr><td>Validation Accuracy</td><td>0.85556</td></tr><tr><td>Validation F1</td><td>0.85937</td></tr><tr><td>Validation Loss</td><td>0.74035</td></tr><tr><td>Validation Precision</td><td>0.85632</td></tr><tr><td>Validation Recall</td><td>0.86323</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/09wto8xa' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/09wto8xa</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_184416-09wto8xa/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 19:28:32,542] Trial 4 finished with value: 0.8600583090379009 and parameters: {'learning_rate': 1.2239465359151734e-05, 'weight_decay': 1.6583847420583589e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_192833-nemrgl6n</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nemrgl6n' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nemrgl6n' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nemrgl6n</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5529, Val Acc: 0.6709, Val F1: 0.6832, Gap: -0.1180\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6898, Val Acc: 0.7324, Val F1: 0.7431, Gap: -0.0426\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7518, Val Acc: 0.7710, Val F1: 0.7798, Gap: -0.0192\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7876, Val Acc: 0.7906, Val F1: 0.7976, Gap: -0.0030\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8177, Val Acc: 0.7929, Val F1: 0.7996, Gap: 0.0249\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8392, Val Acc: 0.8189, Val F1: 0.8249, Gap: 0.0203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8565, Val Acc: 0.8293, Val F1: 0.8351, Gap: 0.0272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8715, Val Acc: 0.8231, Val F1: 0.8286, Gap: 0.0484\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8812, Val Acc: 0.8194, Val F1: 0.8247, Gap: 0.0619\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8935, Val Acc: 0.8328, Val F1: 0.8377, Gap: 0.0607\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9026, Val Acc: 0.8477, Val F1: 0.8518, Gap: 0.0550\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9103, Val Acc: 0.8440, Val F1: 0.8487, Gap: 0.0663\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9209, Val Acc: 0.8330, Val F1: 0.8379, Gap: 0.0879\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9249, Val Acc: 0.8535, Val F1: 0.8577, Gap: 0.0714\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9299, Val Acc: 0.8404, Val F1: 0.8456, Gap: 0.0895\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▅▅▅▇▇▇▇▇█████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁▃▁▁▆▆▅▃▄▆▆▆█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▆▆▇█▆▆▇██▇▇▇▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▅▅▇▇▇▇▇██▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▃▄▅▆▆▇▇▆█████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▆▅▅▇█▇▆▇██▇█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▆▆▇▇▇▇██▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆▆▇▇▇███▇█▇▇▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▃▄▅▄▆▆▄▅█▆▆█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▅▆▆▇▇▇▇███▇█▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▆▇▆▇▇███▇█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▆▅▆▇▅▅▇▇▇▆█▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▆▆▇▇▆▇▇██▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▅▇▄▅█▃▃▆▅▅▃▆▄</td></tr><tr><td>Class_Positive_Recall</td><td>▁▃▄▄▆▆▅▇▇▆▇▇█▇█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▆▇▇▇▇▇██▇█▇</td></tr><tr><td>Validation F1</td><td>▁▃▅▆▆▇▇▇▇▇██▇██</td></tr><tr><td>Validation Loss</td><td>█▅▄▃▃▂▁▂▂▁▁▁▂▁▃</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▅▇▇▇▇▇██▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85929</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83419</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88595</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81787</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84352</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79375</td></tr><tr><td>Class_Negative_F1</td><td>0.87509</td></tr><tr><td>Class_Negative_Precision</td><td>0.9243</td></tr><tr><td>Class_Negative_Recall</td><td>0.83085</td></tr><tr><td>Class_Neutral_F1</td><td>0.81465</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81662</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81269</td></tr><tr><td>Class_Positive_F1</td><td>0.86113</td></tr><tr><td>Class_Positive_Precision</td><td>0.80078</td></tr><tr><td>Class_Positive_Recall</td><td>0.93132</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.92987</td></tr><tr><td>Train Loss</td><td>0.21245</td></tr><tr><td>Validation Accuracy</td><td>0.84038</td></tr><tr><td>Validation F1</td><td>0.84561</td></tr><tr><td>Validation Loss</td><td>0.55757</td></tr><tr><td>Validation Precision</td><td>0.84388</td></tr><tr><td>Validation Recall</td><td>0.85091</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nemrgl6n' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/nemrgl6n</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_192833-nemrgl6n/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 20:10:28,585] Trial 5 finished with value: 0.8534985422740525 and parameters: {'learning_rate': 6.1813049870482055e-06, 'weight_decay': 8.989816808231036e-06, 'patience': 7, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_201029-wbibb7p9</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/wbibb7p9' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/wbibb7p9' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/wbibb7p9</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5537, Val Acc: 0.6713, Val F1: 0.6848, Gap: -0.1176\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7013, Val Acc: 0.7471, Val F1: 0.7574, Gap: -0.0458\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7641, Val Acc: 0.7466, Val F1: 0.7577, Gap: 0.0175\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8009, Val Acc: 0.7997, Val F1: 0.8064, Gap: 0.0012\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8296, Val Acc: 0.8002, Val F1: 0.8068, Gap: 0.0294\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8479, Val Acc: 0.8240, Val F1: 0.8301, Gap: 0.0239\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8655, Val Acc: 0.8325, Val F1: 0.8382, Gap: 0.0331\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8793, Val Acc: 0.8162, Val F1: 0.8207, Gap: 0.0631\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8903, Val Acc: 0.8268, Val F1: 0.8319, Gap: 0.0635\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9016, Val Acc: 0.8441, Val F1: 0.8493, Gap: 0.0575\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9109, Val Acc: 0.8591, Val F1: 0.8627, Gap: 0.0518\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9193, Val Acc: 0.8458, Val F1: 0.8513, Gap: 0.0734\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9274, Val Acc: 0.8494, Val F1: 0.8523, Gap: 0.0780\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9327, Val Acc: 0.8548, Val F1: 0.8592, Gap: 0.0779\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9393, Val Acc: 0.8512, Val F1: 0.8549, Gap: 0.0882\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▅▆▆▇▇▅▇███▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▄▄▄▇▆▁▅▆██▅▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▃▄▅▆▃▅█▆▆▄▄▆▆▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▅▆▇▇▅▇▇██▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▅▆▇▇▆█▇▇██▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▂▅▅▆▆▄▅▇█▆▆▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▄▆▆▇▇▇▇███▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▆▆▇▇▇█████▆▇▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▅▅▅▆▆▆▇▇▇█▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▃▆▆▆▇▇▆▇█▇██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▃▆▆▅▆▇▆█▇▆▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▃▅▅▇▆▆▆▆███▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▃▆▆▇▇▇▆▇████▇</td></tr><tr><td>Class_Positive_Precision</td><td>▂▄▁▅▄▆▆▆▄▅█▆▇█▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▃▇▅▇▅▆▆█▇▆▇▆▆█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▄▆▆▇▇▆▇▇█████</td></tr><tr><td>Validation F1</td><td>▁▄▄▆▆▇▇▆▇▇█████</td></tr><tr><td>Validation Loss</td><td>█▅▅▃▃▂▂▃▂▂▁▂▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▄▄▆▅▇▇▆▆▇██▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▄▄▆▆▇▇▇▇██▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86321</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83835</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8896</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83489</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83722</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.83258</td></tr><tr><td>Class_Negative_F1</td><td>0.88149</td></tr><tr><td>Class_Negative_Precision</td><td>0.90623</td></tr><tr><td>Class_Negative_Recall</td><td>0.85807</td></tr><tr><td>Class_Neutral_F1</td><td>0.82968</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8673</td></tr><tr><td>Class_Neutral_Recall</td><td>0.79519</td></tr><tr><td>Class_Positive_F1</td><td>0.86532</td></tr><tr><td>Class_Positive_Precision</td><td>0.80467</td></tr><tr><td>Class_Positive_Recall</td><td>0.93585</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.93935</td></tr><tr><td>Train Loss</td><td>0.18512</td></tr><tr><td>Validation Accuracy</td><td>0.85119</td></tr><tr><td>Validation F1</td><td>0.85492</td></tr><tr><td>Validation Loss</td><td>0.51587</td></tr><tr><td>Validation Precision</td><td>0.85075</td></tr><tr><td>Validation Recall</td><td>0.86226</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/wbibb7p9' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/wbibb7p9</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_201029-wbibb7p9/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 20:52:25,031] Trial 6 finished with value: 0.859086491739553 and parameters: {'learning_rate': 7.193205334514547e-06, 'weight_decay': 3.551224503300356e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_205226-dqwhbtk6</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/dqwhbtk6' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/dqwhbtk6' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/dqwhbtk6</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5532, Val Acc: 0.6416, Val F1: 0.6533, Gap: -0.0885\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6982, Val Acc: 0.7043, Val F1: 0.7124, Gap: -0.0061\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7661, Val Acc: 0.7681, Val F1: 0.7769, Gap: -0.0020\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8037, Val Acc: 0.7880, Val F1: 0.7941, Gap: 0.0157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8337, Val Acc: 0.8098, Val F1: 0.8158, Gap: 0.0239\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8520, Val Acc: 0.8066, Val F1: 0.8115, Gap: 0.0454\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8681, Val Acc: 0.8274, Val F1: 0.8331, Gap: 0.0407\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8833, Val Acc: 0.8203, Val F1: 0.8263, Gap: 0.0630\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8931, Val Acc: 0.8432, Val F1: 0.8472, Gap: 0.0499\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9042, Val Acc: 0.8468, Val F1: 0.8513, Gap: 0.0574\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9103, Val Acc: 0.8552, Val F1: 0.8584, Gap: 0.0551\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9164, Val Acc: 0.8528, Val F1: 0.8561, Gap: 0.0636\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9254, Val Acc: 0.8513, Val F1: 0.8546, Gap: 0.0741\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9280, Val Acc: 0.8422, Val F1: 0.8461, Gap: 0.0858\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9334, Val Acc: 0.8311, Val F1: 0.8354, Gap: 0.1022\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▆▅▇▆█▆██████▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▇▅▆▅█▅▇▇▇█▇█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▆▁▆▆█▅█▆▇▆▅█▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▆▆▇▆█▆███████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅▆▆▆▇▅▇▇████▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▇▅▇▆▇▇████▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▇▇▇▇▇██▇█▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▆▇▇▇▇█▆█▇▆▇▆▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▄▄▆▆▆▆█▆██▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▁▄▆▆▆▇▇▇████▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▅▇▆▆█▇▇▇▇▇▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▁▄▆▆▆▆▆▇████▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▃▆▆▆▆▇▇████▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>▄▁▃▆▆▆▅▇▇████▆▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇▇▆▇▇█▆▇▆▆▇▇██</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▇▆▇▇██████▇</td></tr><tr><td>Validation F1</td><td>▁▃▅▆▇▆▇▇██████▇</td></tr><tr><td>Validation Loss</td><td>█▆▄▃▂▂▂▂▁▁▁▁▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▆▆▇▇█████▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▇▇▇▇██████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84715</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.77931</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92792</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80734</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84061</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.7766</td></tr><tr><td>Class_Negative_F1</td><td>0.87412</td></tr><tr><td>Class_Negative_Precision</td><td>0.90669</td></tr><tr><td>Class_Negative_Recall</td><td>0.84381</td></tr><tr><td>Class_Neutral_F1</td><td>0.80559</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86185</td></tr><tr><td>Class_Neutral_Recall</td><td>0.75624</td></tr><tr><td>Class_Positive_F1</td><td>0.84256</td></tr><tr><td>Class_Positive_Precision</td><td>0.75877</td></tr><tr><td>Class_Positive_Recall</td><td>0.94717</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.93339</td></tr><tr><td>Train Loss</td><td>0.18847</td></tr><tr><td>Validation Accuracy</td><td>0.83115</td></tr><tr><td>Validation F1</td><td>0.83535</td></tr><tr><td>Validation Loss</td><td>0.5032</td></tr><tr><td>Validation Precision</td><td>0.82944</td></tr><tr><td>Validation Recall</td><td>0.85035</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/dqwhbtk6' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/dqwhbtk6</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_205226-dqwhbtk6/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 21:36:41,728] Trial 7 finished with value: 0.8551992225461613 and parameters: {'learning_rate': 5.5211209136471394e-06, 'weight_decay': 4.466548288856994e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_213642-n3ritf19</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/n3ritf19' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/n3ritf19' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/n3ritf19</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6279, Val Acc: 0.7545, Val F1: 0.7609, Gap: -0.1266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7983, Val Acc: 0.7982, Val F1: 0.8051, Gap: 0.0000\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8545, Val Acc: 0.8445, Val F1: 0.8489, Gap: 0.0100\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8857, Val Acc: 0.8466, Val F1: 0.8513, Gap: 0.0391\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9091, Val Acc: 0.8530, Val F1: 0.8570, Gap: 0.0561\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9275, Val Acc: 0.8540, Val F1: 0.8578, Gap: 0.0735\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9396, Val Acc: 0.8609, Val F1: 0.8643, Gap: 0.0787\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9485, Val Acc: 0.8482, Val F1: 0.8514, Gap: 0.1004\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9569, Val Acc: 0.8552, Val F1: 0.8581, Gap: 0.1017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9629, Val Acc: 0.8393, Val F1: 0.8419, Gap: 0.1236\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9678, Val Acc: 0.8448, Val F1: 0.8483, Gap: 0.1231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9708, Val Acc: 0.8627, Val F1: 0.8668, Gap: 0.1080\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9732, Val Acc: 0.8633, Val F1: 0.8670, Gap: 0.1099\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9766, Val Acc: 0.8624, Val F1: 0.8640, Gap: 0.1142\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9790, Val Acc: 0.8422, Val F1: 0.8447, Gap: 0.1368\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▇▇▇█▇▇▅▇██▇▅</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄█▅▆▆▆▅▆▄▆▇▇█▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▆▁▇▆▇▆▇▇█▇▅▅▁█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▇▇▇▇█▇█▆▇███▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅▆▆▅▆▆█▇█▆▇▆▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅█▇▇▇█▇▆▅▅███▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇██▆▇▅▆▅▃█▇▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▃▆▇█▇▆▅▃▃▄▁▇▅▄▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▃▃▄▅▅▆█▆█▃▆▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▆▆▇▇█▇▇▇▇███▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▃▆▅█▇▇▅▇█▄▆▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▁▆▅▆▆▆▅▇▆▅█▇▇▅</td></tr><tr><td>Class_Positive_F1</td><td>▂▁▆▆▇██▇▇▇▇███▇</td></tr><tr><td>Class_Positive_Precision</td><td>▃▁▅▄▅▇▇▇█▇▆█▇▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▃█▇█▇▅▅▃▁▄▆▃▅▆▄</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▇▇▇█▇▇▆▇███▇</td></tr><tr><td>Validation F1</td><td>▁▄▇▇▇▇█▇▇▆▇███▇</td></tr><tr><td>Validation Loss</td><td>▅▃▂▁▁▂▂▃▃▅▄▅▅▆█</td></tr><tr><td>Validation Precision</td><td>▁▄▇▇▇▇▇▇▇▆▆███▆</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇███▇█▇▇██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83367</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.75202</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.93522</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.79746</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83824</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.76046</td></tr><tr><td>Class_Negative_F1</td><td>0.87846</td></tr><tr><td>Class_Negative_Precision</td><td>0.87173</td></tr><tr><td>Class_Negative_Recall</td><td>0.88529</td></tr><tr><td>Class_Neutral_F1</td><td>0.8417</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86688</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81794</td></tr><tr><td>Class_Positive_F1</td><td>0.87201</td></tr><tr><td>Class_Positive_Precision</td><td>0.86488</td></tr><tr><td>Class_Positive_Recall</td><td>0.87925</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97898</td></tr><tr><td>Train Loss</td><td>0.06558</td></tr><tr><td>Validation Accuracy</td><td>0.8422</td></tr><tr><td>Validation F1</td><td>0.84466</td></tr><tr><td>Validation Loss</td><td>0.70326</td></tr><tr><td>Validation Precision</td><td>0.83875</td></tr><tr><td>Validation Recall</td><td>0.85563</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/n3ritf19' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/n3ritf19</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_213642-n3ritf19/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 22:18:40,273] Trial 8 finished with value: 0.8633381924198251 and parameters: {'learning_rate': 2.4829699507688917e-05, 'weight_decay': 5.324539105513838e-06, 'patience': 7, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_221841-doghte7c</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/doghte7c' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/doghte7c' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/doghte7c</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5782, Val Acc: 0.6594, Val F1: 0.6698, Gap: -0.0812\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7376, Val Acc: 0.7785, Val F1: 0.7864, Gap: -0.0409\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7998, Val Acc: 0.7991, Val F1: 0.8049, Gap: 0.0007\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8393, Val Acc: 0.8015, Val F1: 0.8072, Gap: 0.0378\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8649, Val Acc: 0.8364, Val F1: 0.8414, Gap: 0.0286\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8842, Val Acc: 0.8200, Val F1: 0.8249, Gap: 0.0643\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9003, Val Acc: 0.8376, Val F1: 0.8410, Gap: 0.0627\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9144, Val Acc: 0.8301, Val F1: 0.8337, Gap: 0.0844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9275, Val Acc: 0.8565, Val F1: 0.8595, Gap: 0.0709\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9373, Val Acc: 0.8401, Val F1: 0.8435, Gap: 0.0972\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9434, Val Acc: 0.8495, Val F1: 0.8522, Gap: 0.0940\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9518, Val Acc: 0.8449, Val F1: 0.8473, Gap: 0.1069\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9546, Val Acc: 0.8341, Val F1: 0.8372, Gap: 0.1206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9595, Val Acc: 0.8429, Val F1: 0.8464, Gap: 0.1165\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9631, Val Acc: 0.8479, Val F1: 0.8509, Gap: 0.1152\n","Early stopping at epoch 15\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▅▅▇▇▇▆█▆▇▇▆██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▅▄▇▆▅▄█▅▆▆▄█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▁▄▆▂▅▇█▂▇▅▆█▂▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▆▇▇▇▆█▇█▇▆██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▆▅▆▆█▇▇▆██▆██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▅▆█▇▆▆█▆▇▆▆▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇█████▇▇█▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▂▁▄▇▄▇▇▇▃█▁▃▆▂▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▆▅▇▆▇▆█▆█▇▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▆▆▇▇▇▇█████▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▅▇▆▇▇▇▇▇█▇█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▆▆▇▆▇▇████▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▆▆▇▆▇▇█████▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▆▅█▅▆▆████▇▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▆▁▅▇▃██▇▅▆▅▄▇▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇▇▇█▇██▇██</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇▇▇█▇██▇██</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▂▂▁▂▁▂▂▃▄▄▅</td></tr><tr><td>Validation Precision</td><td>▁▅▆▆▇▇▇▇█▇█▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆▇▇█▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85237</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.80258</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90876</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81341</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85327</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77711</td></tr><tr><td>Class_Negative_F1</td><td>0.86688</td></tr><tr><td>Class_Negative_Precision</td><td>0.85222</td></tr><tr><td>Class_Negative_Recall</td><td>0.88205</td></tr><tr><td>Class_Neutral_F1</td><td>0.84089</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86813</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81532</td></tr><tr><td>Class_Positive_F1</td><td>0.8811</td></tr><tr><td>Class_Positive_Precision</td><td>0.84535</td></tr><tr><td>Class_Positive_Recall</td><td>0.92</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96313</td></tr><tr><td>Train Loss</td><td>0.10737</td></tr><tr><td>Validation Accuracy</td><td>0.84791</td></tr><tr><td>Validation F1</td><td>0.85093</td></tr><tr><td>Validation Loss</td><td>0.60189</td></tr><tr><td>Validation Precision</td><td>0.84431</td></tr><tr><td>Validation Recall</td><td>0.86065</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/doghte7c' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/doghte7c</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_221841-doghte7c/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 23:00:38,604] Trial 9 finished with value: 0.8565354713313897 and parameters: {'learning_rate': 1.198801758016798e-05, 'weight_decay': 2.0976965871882046e-06, 'patience': 5, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8639455782312925.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_230039-k0xuu1fp</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/k0xuu1fp' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/k0xuu1fp' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/k0xuu1fp</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6676, Val Acc: 0.7349, Val F1: 0.7460, Gap: -0.0673\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8114, Val Acc: 0.7917, Val F1: 0.7966, Gap: 0.0197\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8622, Val Acc: 0.8369, Val F1: 0.8423, Gap: 0.0253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8930, Val Acc: 0.8409, Val F1: 0.8455, Gap: 0.0521\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9154, Val Acc: 0.8546, Val F1: 0.8578, Gap: 0.0608\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9291, Val Acc: 0.8409, Val F1: 0.8443, Gap: 0.0882\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9406, Val Acc: 0.8641, Val F1: 0.8681, Gap: 0.0765\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9480, Val Acc: 0.8607, Val F1: 0.8656, Gap: 0.0873\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9562, Val Acc: 0.8517, Val F1: 0.8559, Gap: 0.1045\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9596, Val Acc: 0.8567, Val F1: 0.8598, Gap: 0.1029\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9646, Val Acc: 0.8671, Val F1: 0.8706, Gap: 0.0975\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9682, Val Acc: 0.8511, Val F1: 0.8547, Gap: 0.1171\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9712, Val Acc: 0.8660, Val F1: 0.8692, Gap: 0.1052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9740, Val Acc: 0.8579, Val F1: 0.8608, Gap: 0.1162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9768, Val Acc: 0.8639, Val F1: 0.8672, Gap: 0.1128\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▆▇▇▅███▇█▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▇▆▆▄▇▇█▇▇▆██▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▇▂▆▆█▅▅▃▃▄▄▂▁▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▇▇▇▆█▇█▇█▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▇▆█▆█▇▇█▇█▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▆▇▆▅▇█▇▇█▆█▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆▇▇██▇▆▆▇▇█▇▆</td></tr><tr><td>Class_Negative_Precision</td><td>▃▇█▅▆▇▅█▆▁▄▂▆▄▃</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▆▆▆▇▅▆▇▇█▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▅▇██▇▇▆██▇▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▄▂▁▃▁█▆▇▆▇▇▇▇▆▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▆▆█▆▇▆▆▆▇▆▆▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▃▆▇▇█▅▇▇▆▇▆▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▁█▇▅▄▄▁▄▅▂▃▃▆</td></tr><tr><td>Class_Positive_Recall</td><td>▅▆█▁▃▅▇▇█▇▅█▇▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▇▇▇██▇▇█▇███</td></tr><tr><td>Validation F1</td><td>▁▄▆▇▇▇██▇▇█▇█▇█</td></tr><tr><td>Validation Loss</td><td>▆▃▂▂▁▃▂▃▅▅▄▇▇██</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇█▆██▇▇█▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▇▇██▇▇█▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87297</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84224</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90602</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83948</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84702</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.83207</td></tr><tr><td>Class_Negative_F1</td><td>0.88113</td></tr><tr><td>Class_Negative_Precision</td><td>0.89558</td></tr><tr><td>Class_Negative_Recall</td><td>0.86714</td></tr><tr><td>Class_Neutral_F1</td><td>0.85751</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84371</td></tr><tr><td>Class_Neutral_Recall</td><td>0.87177</td></tr><tr><td>Class_Positive_F1</td><td>0.88466</td></tr><tr><td>Class_Positive_Precision</td><td>0.9112</td></tr><tr><td>Class_Positive_Recall</td><td>0.85962</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97677</td></tr><tr><td>Train Loss</td><td>0.08955</td></tr><tr><td>Validation Accuracy</td><td>0.86395</td></tr><tr><td>Validation F1</td><td>0.86715</td></tr><tr><td>Validation Loss</td><td>0.74398</td></tr><tr><td>Validation Precision</td><td>0.86795</td></tr><tr><td>Validation Recall</td><td>0.86733</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/k0xuu1fp' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/k0xuu1fp</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_230039-k0xuu1fp/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-03 23:44:58,038] Trial 10 finished with value: 0.8671039844509232 and parameters: {'learning_rate': 1.924356648556222e-05, 'weight_decay': 4.998886173840331e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 10 with value: 0.8671039844509232.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250803_234459-lqn72enf</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/lqn72enf' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/lqn72enf' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/lqn72enf</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6686, Val Acc: 0.7597, Val F1: 0.7666, Gap: -0.0911\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8131, Val Acc: 0.8100, Val F1: 0.8161, Gap: 0.0031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8629, Val Acc: 0.8336, Val F1: 0.8396, Gap: 0.0293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8941, Val Acc: 0.8622, Val F1: 0.8655, Gap: 0.0319\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9154, Val Acc: 0.8552, Val F1: 0.8591, Gap: 0.0602\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9311, Val Acc: 0.8463, Val F1: 0.8483, Gap: 0.0847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9410, Val Acc: 0.8575, Val F1: 0.8609, Gap: 0.0835\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9506, Val Acc: 0.8454, Val F1: 0.8483, Gap: 0.1053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9562, Val Acc: 0.8620, Val F1: 0.8655, Gap: 0.0942\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9601, Val Acc: 0.8565, Val F1: 0.8596, Gap: 0.1035\n","Early stopping at epoch 10\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▇▇█▇█▆█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▇▅█▆▆▃▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▄▂▆▁▆▅█▅▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▇▇█▇█▆█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅█▇▆▇▅▆█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▇▇▇▇▇▅█▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆█▇▆▆▆▇▅</td></tr><tr><td>Class_Negative_Precision</td><td>▃▇██▆▃▆▄▇▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▂▄▅▇▄▅▄█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▅█▇▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▄▆▆▄▆▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▅█▇█▇▇▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▅█▆▄▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▃▅▄█▅▇▅▆</td></tr><tr><td>Class_Positive_Recall</td><td>▆██▇█▁▆▄▆▆</td></tr><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆██▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▅▆██▇█▇██</td></tr><tr><td>Validation Loss</td><td>▆▄▂▁▂▃▃▅▅█</td></tr><tr><td>Validation Precision</td><td>▁▅▆████▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▅▆█▇▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86071</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81382</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91332</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82402</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85847</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79223</td></tr><tr><td>Class_Negative_F1</td><td>0.87254</td></tr><tr><td>Class_Negative_Precision</td><td>0.83109</td></tr><tr><td>Class_Negative_Recall</td><td>0.91834</td></tr><tr><td>Class_Neutral_F1</td><td>0.85085</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87402</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82888</td></tr><tr><td>Class_Positive_F1</td><td>0.8899</td></tr><tr><td>Class_Positive_Precision</td><td>0.89846</td></tr><tr><td>Class_Positive_Recall</td><td>0.88151</td></tr><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.96006</td></tr><tr><td>Train Loss</td><td>0.13401</td></tr><tr><td>Validation Accuracy</td><td>0.85654</td></tr><tr><td>Validation F1</td><td>0.8596</td></tr><tr><td>Validation Loss</td><td>0.69924</td></tr><tr><td>Validation Precision</td><td>0.85517</td></tr><tr><td>Validation Recall</td><td>0.86686</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/lqn72enf' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/lqn72enf</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250803_234459-lqn72enf/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 00:14:43,662] Trial 11 finished with value: 0.8622448979591837 and parameters: {'learning_rate': 1.9449437161009815e-05, 'weight_decay': 4.972695958022485e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 10 with value: 0.8671039844509232.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_001444-ka6zs85t</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/ka6zs85t' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/ka6zs85t' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/ka6zs85t</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6613, Val Acc: 0.7850, Val F1: 0.7894, Gap: -0.1237\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8078, Val Acc: 0.8195, Val F1: 0.8267, Gap: -0.0116\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8622, Val Acc: 0.8228, Val F1: 0.8278, Gap: 0.0395\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8901, Val Acc: 0.8541, Val F1: 0.8593, Gap: 0.0360\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9134, Val Acc: 0.8605, Val F1: 0.8636, Gap: 0.0529\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9280, Val Acc: 0.8437, Val F1: 0.8494, Gap: 0.0844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9374, Val Acc: 0.8511, Val F1: 0.8545, Gap: 0.0863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9467, Val Acc: 0.8180, Val F1: 0.8220, Gap: 0.1287\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9530, Val Acc: 0.8508, Val F1: 0.8542, Gap: 0.1022\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9571, Val Acc: 0.8588, Val F1: 0.8614, Gap: 0.0982\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9603, Val Acc: 0.8519, Val F1: 0.8564, Gap: 0.1084\n","Early stopping at epoch 11\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▆█▇█▇▅▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>█▂▁▆▆▅▄▁▄▅▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▇█▇▆▇▇█▇▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▇█▇▇▃▆▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▇▇▆▇▆█▆▇▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▆▃▅█▆▇▁▆▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▇▇█▇▂▆▅▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▄▆▇▇▆█▁▄▄▄▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▅▅▇▄█▇▇▇▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▃▆▇▄▇▃▇█▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▆▅▇▆▇▆█▅█</td></tr><tr><td>Class_Neutral_Recall</td><td>▅▃▁▅▅▂▅▁▄█▃</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▂▇▇▄█▂█▆▇</td></tr><tr><td>Class_Positive_Precision</td><td>▆▆▁▄▄▂█▁▅█▄</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▇▇▆█▃█▆▂▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▇█▆▇▄▇█▇</td></tr><tr><td>Validation F1</td><td>▁▅▅██▇▇▄▇█▇</td></tr><tr><td>Validation Loss</td><td>▅▃▃▁▁▄▂█▅▄▆</td></tr><tr><td>Validation Precision</td><td>▁▃▂▆▇▅▆▁▅█▆</td></tr><tr><td>Validation Recall</td><td>▁▅▆███▇▆█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86801</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85162</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88504</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82996</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80388</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.85779</td></tr><tr><td>Class_Negative_F1</td><td>0.88198</td></tr><tr><td>Class_Negative_Precision</td><td>0.91091</td></tr><tr><td>Class_Negative_Recall</td><td>0.85483</td></tr><tr><td>Class_Neutral_F1</td><td>0.83183</td></tr><tr><td>Class_Neutral_Precision</td><td>0.88224</td></tr><tr><td>Class_Neutral_Recall</td><td>0.78687</td></tr><tr><td>Class_Positive_F1</td><td>0.87003</td></tr><tr><td>Class_Positive_Precision</td><td>0.8216</td></tr><tr><td>Class_Positive_Recall</td><td>0.92453</td></tr><tr><td>Epoch</td><td>11</td></tr><tr><td>Train Accuracy</td><td>0.96033</td></tr><tr><td>Train Loss</td><td>0.13323</td></tr><tr><td>Validation Accuracy</td><td>0.85192</td></tr><tr><td>Validation F1</td><td>0.85636</td></tr><tr><td>Validation Loss</td><td>0.65853</td></tr><tr><td>Validation Precision</td><td>0.85405</td></tr><tr><td>Validation Recall</td><td>0.86181</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/ka6zs85t' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/ka6zs85t</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_001444-ka6zs85t/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 00:47:16,814] Trial 12 finished with value: 0.8605442176870748 and parameters: {'learning_rate': 1.8484645200702897e-05, 'weight_decay': 1.0924173028126777e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 10 with value: 0.8671039844509232.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_004717-q3q7xqe4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/q3q7xqe4' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/q3q7xqe4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/q3q7xqe4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6642, Val Acc: 0.7856, Val F1: 0.7928, Gap: -0.1214\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8094, Val Acc: 0.8333, Val F1: 0.8389, Gap: -0.0239\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8595, Val Acc: 0.8343, Val F1: 0.8394, Gap: 0.0252\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8908, Val Acc: 0.8482, Val F1: 0.8522, Gap: 0.0427\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9137, Val Acc: 0.8291, Val F1: 0.8332, Gap: 0.0846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9269, Val Acc: 0.8518, Val F1: 0.8555, Gap: 0.0751\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9400, Val Acc: 0.8587, Val F1: 0.8619, Gap: 0.0813\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9488, Val Acc: 0.8403, Val F1: 0.8440, Gap: 0.1085\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9545, Val Acc: 0.8471, Val F1: 0.8495, Gap: 0.1074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9598, Val Acc: 0.8523, Val F1: 0.8558, Gap: 0.1076\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9654, Val Acc: 0.8562, Val F1: 0.8600, Gap: 0.1092\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9677, Val Acc: 0.8593, Val F1: 0.8626, Gap: 0.1084\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9720, Val Acc: 0.8530, Val F1: 0.8563, Gap: 0.1190\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9737, Val Acc: 0.8541, Val F1: 0.8581, Gap: 0.1196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9769, Val Acc: 0.8570, Val F1: 0.8603, Gap: 0.1199\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▅▇▂▆█▅▅▇▇██▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▆▇▄▇▁▅▅▄▄▆▆█▇▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▃▆▄█▆▆▇▇▆▆▄▅▄▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▄▇▁▆█▄▅▇▇█▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▅▅▄▆█▆█▇▆▅▇▆█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▄▄▇▁▅▅▃▃▅▅█▄▆▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▅▆▇▇▆▅▆▅▇▆▆█▅</td></tr><tr><td>Class_Negative_Precision</td><td>▄▆█▇█▆▃▇▄▃▆▄▃▇▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▄▃▆▇▄▆▅▅▆▇▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▇██▇████▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▆▇▇▆█▇▆▇▆█▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇▅▅▇█▇▅█▇█▇▆▅▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▆▆▇▇█▇▇█▇█▆▆█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▃▂██▆▃▇▆▆▇▃▂▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▅▆▇▂▁▅█▃▄▄▄▇█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▇▅▇█▆▇▇██▇██</td></tr><tr><td>Validation F1</td><td>▁▆▆▇▅▇█▆▇▇██▇██</td></tr><tr><td>Validation Loss</td><td>▄▁▁▁▃▂▂▅▄▅▆▆▇█▇</td></tr><tr><td>Validation Precision</td><td>▁▅▅▇▅▇▇▅▆▇▇█▆▇▇</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▆▇█▇▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86824</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85039</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88686</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82959</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8611</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.8003</td></tr><tr><td>Class_Negative_F1</td><td>0.86755</td></tr><tr><td>Class_Negative_Precision</td><td>0.82842</td></tr><tr><td>Class_Negative_Recall</td><td>0.91056</td></tr><tr><td>Class_Neutral_F1</td><td>0.84938</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87189</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82801</td></tr><tr><td>Class_Positive_F1</td><td>0.88651</td></tr><tr><td>Class_Positive_Precision</td><td>0.86884</td></tr><tr><td>Class_Positive_Recall</td><td>0.90491</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97692</td></tr><tr><td>Train Loss</td><td>0.09062</td></tr><tr><td>Validation Accuracy</td><td>0.85702</td></tr><tr><td>Validation F1</td><td>0.86025</td></tr><tr><td>Validation Loss</td><td>0.76947</td></tr><tr><td>Validation Precision</td><td>0.85613</td></tr><tr><td>Validation Recall</td><td>0.86613</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/q3q7xqe4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/q3q7xqe4</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_004717-q3q7xqe4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 01:31:38,218] Trial 13 finished with value: 0.85932944606414 and parameters: {'learning_rate': 1.800099466606305e-05, 'weight_decay': 3.1339466165132913e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 10 with value: 0.8671039844509232.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_013139-837nin8e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/837nin8e' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/837nin8e' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/837nin8e</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6016, Val Acc: 0.6591, Val F1: 0.6697, Gap: -0.0575\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7694, Val Acc: 0.7980, Val F1: 0.8032, Gap: -0.0286\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8266, Val Acc: 0.8252, Val F1: 0.8314, Gap: 0.0014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8626, Val Acc: 0.8248, Val F1: 0.8296, Gap: 0.0378\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8866, Val Acc: 0.8387, Val F1: 0.8417, Gap: 0.0479\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9059, Val Acc: 0.8307, Val F1: 0.8360, Gap: 0.0752\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9216, Val Acc: 0.8534, Val F1: 0.8574, Gap: 0.0682\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9314, Val Acc: 0.8251, Val F1: 0.8277, Gap: 0.1063\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9398, Val Acc: 0.8437, Val F1: 0.8471, Gap: 0.0961\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9496, Val Acc: 0.8509, Val F1: 0.8540, Gap: 0.0986\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9544, Val Acc: 0.8522, Val F1: 0.8549, Gap: 0.1023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9602, Val Acc: 0.8535, Val F1: 0.8572, Gap: 0.1067\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9645, Val Acc: 0.8465, Val F1: 0.8500, Gap: 0.1181\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9692, Val Acc: 0.8492, Val F1: 0.8519, Gap: 0.1200\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9711, Val Acc: 0.8467, Val F1: 0.8501, Gap: 0.1244\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▇▆▆▇█▅▇█▇█▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▇▆▆▇█▄▇███▇█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▃▂▅▇▄▃█▆▃▃▅▅▁▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▇▇▇▇█▆▇███▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▆▆▇▇▇▇▇█▇█▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▇▇▆▇█▅▆▇█▇▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇▇▇████▇▇▇▇▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▂▃▄▇▁█▇▆▅▁▃▄▄▂▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▆▆▇▆▆▇▇▇▇▆▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇▇█▇█▇███████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▅▇▆▅▆▇▇▇█▅█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▇▆▇▆█▇▇▇▇█▇█▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▇█▆▇▇▇█████▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▇▅█▅▆▆▆▆▆▇▇▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▂▂▁▆▁█▆▅▆▆▆▆▅▄▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇▇▇█▇███████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇▇█▇███████</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▁▂▁▃▂▂▂▃▄▄▅</td></tr><tr><td>Validation Precision</td><td>▁▆▇▇▇▇█▇▇██████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇▇█▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86126</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.80492</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92609</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81972</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.87429</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77156</td></tr><tr><td>Class_Negative_F1</td><td>0.87304</td></tr><tr><td>Class_Negative_Precision</td><td>0.84747</td></tr><tr><td>Class_Negative_Recall</td><td>0.90019</td></tr><tr><td>Class_Neutral_F1</td><td>0.82993</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87259</td></tr><tr><td>Class_Neutral_Recall</td><td>0.79125</td></tr><tr><td>Class_Positive_F1</td><td>0.86631</td></tr><tr><td>Class_Positive_Precision</td><td>0.81325</td></tr><tr><td>Class_Positive_Recall</td><td>0.92679</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97106</td></tr><tr><td>Train Loss</td><td>0.08516</td></tr><tr><td>Validation Accuracy</td><td>0.8467</td></tr><tr><td>Validation F1</td><td>0.85005</td></tr><tr><td>Validation Loss</td><td>0.61283</td></tr><tr><td>Validation Precision</td><td>0.8425</td></tr><tr><td>Validation Recall</td><td>0.86318</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_14</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/837nin8e' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2/runs/837nin8e</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_013139-837nin8e/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 02:13:41,934] Trial 14 finished with value: 0.8534985422740525 and parameters: {'learning_rate': 1.6368369237343168e-05, 'weight_decay': 3.422900026320533e-06, 'patience': 5, 'batch_size': 64, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.5, 'use_class_weights': True}. Best is trial 10 with value: 0.8671039844509232.\n"]},{"name":"stdout","output_type":"stream","text":["\n"," Best Results:\n","Validation Accuracy: 0.8671\n","Best hyperparameters:\n","  learning_rate: 1.924356648556222e-05\n","  weight_decay: 4.998886173840331e-06\n","  patience: 5\n","  batch_size: 32\n","  num_layers: 0\n","  dropout_rate: 0.1\n","  gradient_clip_val: 0.5\n","  use_class_weights: False\n","\n","Best model saved: best_model_trial_10.pt\n"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 2:\")\n","study2 = optuna.create_study(direction=\"maximize\")\n","study2.optimize(objective, n_trials=15)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study2.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model2.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kPUtoa6G3yaI"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3eD0TKgEUJ-K"},"source":["## **Study Results Summary – Stability vs. Peak Performance**\n","\n","To evaluate the effect of narrowing the hyperparameter space, we compared two experiments:\n","\n","* **Study 0** – Broad hyperparameter search on shallow models\n","* **Study 2** – Focused search based on insights from Study 0\n","\n","The table below presents the results for:\n","\n","* The **best single run** in Study 0\n","* The **average performance** of all trials in Study 0 and Study 2\n","\n","|                          | **Best in Study 0** | **Average Study 0** | **Average Study 2** |\n","| ------------------------ | ------------------- | ------------------- | ------------------- |\n","| **Validation Accuracy**  | **86.54%**          | 76.95%              | **84.86%**          |\n","| **Validation F1**        | **86.79%**          | 77.53%              | **85.22%**          |\n","| **Validation Precision** | 87.85%              | 77.51%              | **84.83%**          |\n","| **Validation Recall**    | 85.98%              | 78.08%              | **85.99%**          |\n","| **Validation Loss**      | 0.8504              | 0.7545              | **0.6342**          |\n","| **Train Accuracy**       | 97.89%              | 84.41%              | **96.18%**          |\n","| **Train Loss**           | 0.0846              | 0.3909              | **0.1200**          |\n","| **Overfitting Gap**      | 11.35%              | **7.46%**           | 11.32%              |\n","\n","---\n","\n","##  **Interpretation**\n","\n","* The **best score overall** was achieved in **Study 0**, with an F1 of **86.79%**.\n","* However, **Study 2** produced **more consistent and stable results**, with less variance across trials.\n","* The **Validation Loss dropped significantly** in Study 2 (from 0.75 → 0.63), which reflects improved learning dynamics.\n","* The **Overfitting Gap** slightly increased, but this is expected when pushing for higher accuracy.\n","\n"," In summary:\n","**Study 2 did not exceed the top score of Study 0, but it successfully converged near the optimum in a stable and reliable manner.**\n","We now take it as our new starting point for further enhancements.\n","\n","---\n","\n","## **Segment-Level Analysis: Average F1 per Class**\n","\n","|                          | **Best in Study 0** | **Best in Study 2** | **Average Study 0** | **Average Study 2** |\n","| ------------------------ | ------------------- | ------------------- | ------------------- | ------------------- |\n","| **Validation Accuracy**  | **86.54%**          | 86.39%              | 76.95%              | **84.86%**          |\n","| **Validation F1**        | **86.79%**          | 86.72%              | 77.53%              | **85.22%**          |\n","| **Validation Precision** | **87.85%**          | 86.80%              | 77.51%              | **84.83%**          |\n","| **Validation Recall**    | 85.98%              | **86.73%**          | 78.08%              | **85.99%**          |\n","| **Validation Loss**      | 0.8504              | **0.7440**          | 0.7545              | **0.6342**          |\n","| **Train Accuracy**       | **97.89%**          | 97.68%              | 84.41%              | **96.18%**          |\n","| **Train Loss**           | 0.0846              | 0.0895              | 0.3909              | **0.1200**          |\n","| **Overfitting Gap**      | 11.35%              | **11.28%**          | **7.46%**           | 11.32%              |\n","\n","---\n","\n","Although the **best single validation score** was achieved in **Study 0** (with a Validation F1 of **86.79%**), the results across trials were inconsistent and highly variable. In contrast, **Study 2** produced **consistently strong results**, with most trials converging around **85% F1** and demonstrating improved loss values and training stability.\n","\n","In this context, we emphasize the use of **F1 Score** as the main evaluation metric, since it captures both **precision and recall** and is especially informative for **imbalanced datasets** like ours. While accuracy alone may be dominated by the majority classes, the F1 score reflects the model’s true ability to correctly identify all sentiment categories, including the rare or ambiguous ones.\n","\n","With a reliable baseline now established through Study 2, we turn our attention to **class-level analysis** to identify whether specific segments are underperforming. This will help us target future improvements — such as data augmentation or weighting — more effectively.\n","\n","---\n","\n","### **Per-Class Performance Summary**\n","\n","| **Class**          | **F1 Score** | **Precision** | **Recall**  |\n","| ------------------ | ------------ | ------------- | ----------- |\n","| Extremely Positive | **0.82**     | 0.85          | **0.80** 🔽 |\n","| Neutral            | **0.84**     | 0.86          | **0.81** 🔽 |\n","| Extremely Negative | 0.86         | **0.82** 🔽   | 0.90        |\n","| Negative           | 0.87         | 0.87          | 0.88        |\n","| Positive           | 0.87         | 0.84          | 0.91        |\n","\n","---\n","\n","###  **Interpretation:**\n","\n","* The **weakest classes** based on F1 are:\n","\n","  * **Extremely Positive (F1 = 0.82)**\n","  * **Neutral (F1 = 0.84)**\n","\n","* These classes also have the **lowest Recall** (below 82%), indicating the model **often misses true examples** from these classes.\n","\n","* For **Extremely Negative**, recall is high (0.90), but **precision is slightly lower** – indicating some false positives.\n","\n","* **Positive** and **Negative** classes are well-balanced and perform strongly across all metrics.\n","\n","**Conclusion**:\n","To improve the model, we should **focus on boosting recall for the Extremely Positive and Neutral classes**, likely through data augmentation, reweighting, or improved representation learning for those categories."]},{"cell_type":"markdown","metadata":{"id":"dplEKiu4qBIT"},"source":["# Augmentations:"]},{"cell_type":"markdown","metadata":{"id":"4CKMajHgR_Fw"},"source":["#### GUIDED AUGMENTATION PLAN (Based on Study 0 F1 scores):\n","| Class              | Recommendation            |\n","|--------------------|---------------------------|\n","| Negative           | No augmentation           |\n","| Positive           | No augmentation           |\n","| Extremely Negative | No augmentation         |\n","| Neutral            | Add ~2000 samples         |\n","| Extremely Positive | Add ~2200 samples         |\n","➤ Focus augmentation only on weaker classes — skip Negative & Positive.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SKcXfoLTPzSu"},"source":["# **STUDY 3:**"]},{"cell_type":"markdown","metadata":{"id":"lzx8JIxzUNE5"},"source":["**Data Augmentation**:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":606,"status":"ok","timestamp":1754375542859,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"QoDLp13xURi7","outputId":"807a442c-aa77-433a-d170-7687e9f91418"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label counts BEFORE augmentation:\n","Sentiment\n","Positive              9137\n","Negative              7934\n","Neutral               6170\n","Extremely Positive    5299\n","Extremely Negative    4385\n","Name: count, dtype: int64\n","\n","Removed 0 duplicate rows from augmented data.\n","\n","Number of augmented samples added per class:\n","Sentiment\n","Extremely Positive    2200\n","Neutral               2000\n","Name: count, dtype: int64\n","\n","Label counts AFTER augmentation:\n","Sentiment\n","Positive              9137\n","Neutral               8170\n","Negative              7934\n","Extremely Positive    7499\n","Extremely Negative    4385\n","Name: count, dtype: int64\n"]}],"source":["# Count and print label distribution before augmentation\n","print(\"Label counts BEFORE augmentation:\")\n","original_counts = train_df[\"Sentiment\"].value_counts()\n","print(original_counts)\n","\n","# Load full augmented data\n","augmented_df = pd.read_csv('/content/drive/MyDrive/deep_learning/augmented_1.csv', encoding='latin1')\n","\n","# Filter only the weak classes\n","target_classes = ['Extremely Positive', 'Neutral']\n","augmented_df = augmented_df[augmented_df['Sentiment'].isin(target_classes)]\n","\n","# Map labels to numeric (assuming label2id is defined)\n","augmented_df[\"label\"] = augmented_df[\"Sentiment\"].map(label2id)\n","\n","# Optional: Drop duplicates (based on ProcessedTweet) before merge\n","before_merge_aug_size = len(augmented_df)\n","augmented_df = augmented_df.drop_duplicates(subset='ProcessedTweet')\n","after_merge_aug_size = len(augmented_df)\n","\n","print(f\"\\nRemoved {before_merge_aug_size - after_merge_aug_size} duplicate rows from augmented data.\")\n","\n","# Track how many samples were added per class\n","added_counts = augmented_df[\"Sentiment\"].value_counts()\n","print(\"\\nNumber of augmented samples added per class:\")\n","print(added_counts)\n","\n","# Combine datasets\n","train_df = pd.concat([train_df, augmented_df], ignore_index=True)\n","\n","# Shuffle the dataset\n","train_df = train_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n","\n","# Final label counts after augmentation\n","print(\"\\nLabel counts AFTER augmentation:\")\n","final_counts = train_df[\"Sentiment\"].value_counts()\n","print(final_counts)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["fd00d5b11db54d22a8265393d9d83ac1","8da0fe58ec0d4cdda1bf373a753a7d79","b550033498e345199086a7f83df35a2a","dcaa88787cef443292e482a4c6591833","9934cabfa2e14d4f9ad3f424db3e3357","159452003ca0492083c1599f8d6ea10c","9ecb50add3bf4e538086000798a53cc1","6b2a5d9790834621a33c6c72fe47970b","bd5a57fd06b74c97a9085bde0aa5e36e","a460d6d3df2649cbbfffcb82949d4989","9bded0129477418ba560056b71c15ff1","4e67156223544a108af30d99aef4a4d0","e321fefb3f8143548c9aeb437f053ed1","f222ef630b874b909aa68ab5b0be5515","baf943f525714289aa4fd6a6830c2d2f","9beebd8546aa419eb7c4a3e1a5d37bd0","df0c9da553cf4c6390ba791c38e0911b","bc410b8865104ebca5ec34a77f4dea96","ba78ab20dc9946bf915e7f9fcfd8fb7f","d950f50f528a4dc39dbfe79224ac5d22","c485c30b4d2745048eb93adb3465a0e8","9647881014394c2f984bb5c6195c6575","b3d1c6de9d3644a8aa45ad6a75abb4de","bc6dc64feb834315bb54f82a6d941c9f","efc8a7925fa8401ebeace69b0681934b","7b59fd6bff20474cbd9dc47687dcf772","fe14ed43bb084dc9bcd180bc873fbc6b","b71bb3888cb14577888645bd81047c55","e517ea0cd925457b9c1fb57607887b2a","1ba01c503ebe49c0bc127d75b55f2e40","9e5974812c3d495a972d5b2c14a6fa2a","f0875cb432ae46f2a35be6fb71f13660","9e3f513097244e028d97e86b1db0afd7","1c5928899c104666a5f0eb4bc78a6807","c76d54a59c294ffeaf8c1072a27fbbe8","80d9885b0047485cba2065e991df80a9","f2e290021d434cc6971431a14c1d92d7","150b56419f80417ba9b7b51c26f50f5e","c1d4188d4215420c9027fa081c42426c","66a49f64e258489099edeb3ce00d1501","7b8412b7b9b74791a3b31de5cd19167a","86afc1a9c2f146e8a97b30c8642c375e","6c43a9b19d9048cbbc29c4ce53fa9bfb","18e60b0b0da4417889aef85cf05e6945","5d525f6bcae14db6844e01c709487fc2","6b6e54b1acd94d799e3ce29cf02a6dcf","3da7ad155db043239b0f4e487b7d920e","377cacad40e64e2e8e035f852665b0ba","b24ae0dd31da4f178791e480890409a0","8e53df7c354a4ac99d129e68dbcb2343","780023a8cf244c5aac0e23f5feaece4e","987de168da8842bdacb7a9d1e5411dc8","20b9f65792794bfd8ff110f132df34cc","33af6287da9e49df82e4bf305c046cca","b1b67821d153465580c3c20868bca55b","42c218c1d4bf4ed29bc1ea52c9e62cd6","5c9f18bb6c6140a3a5345b8dd1c1c045","51a90984dcc54c2d97337deda5acb726","fd016b073bbf494e88bba6145a83feb6","01739522664242e49f6c561d18b600d9","12efb49319e44b8393eb69e2132bc03e","bc1884ca4bce4bc0bad7efdd8f3d761e","fc441f5da03c47349616063f802409b4","c6a9ef42d68f41b5bb8c3d843faffaf1","be3f32a3b0494412aa904f3abfe1104a","ae53fbd8bee349fe9827d81e35570937"]},"id":"XpyNhoembQiu","outputId":"83e76cdc-f7d5-476e-b0b1-62f8dd5b5dd3"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 06:23:24,396] A new study created in memory with name: no-name-19def74d-fa48-4ffd-9578-2a272bd3ed62\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 3:\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd00d5b11db54d22a8265393d9d83ac1","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e67156223544a108af30d99aef4a4d0","version_major":2,"version_minor":0},"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3d1c6de9d3644a8aa45ad6a75abb4de","version_major":2,"version_minor":0},"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c5928899c104666a5f0eb4bc78a6807","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d525f6bcae14db6844e01c709487fc2","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42c218c1d4bf4ed29bc1ea52c9e62cd6","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_062334-fwy32w40</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/fwy32w40' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/fwy32w40' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/fwy32w40</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6179, Val Acc: 0.6699, Val F1: 0.6793, Gap: -0.0521\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7688, Val Acc: 0.7530, Val F1: 0.7626, Gap: 0.0157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8228, Val Acc: 0.8161, Val F1: 0.8217, Gap: 0.0067\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8577, Val Acc: 0.8304, Val F1: 0.8356, Gap: 0.0273\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8788, Val Acc: 0.8140, Val F1: 0.8197, Gap: 0.0647\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8974, Val Acc: 0.8393, Val F1: 0.8438, Gap: 0.0581\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9109, Val Acc: 0.8514, Val F1: 0.8552, Gap: 0.0595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9240, Val Acc: 0.8444, Val F1: 0.8481, Gap: 0.0796\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9349, Val Acc: 0.8473, Val F1: 0.8505, Gap: 0.0876\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9414, Val Acc: 0.8463, Val F1: 0.8498, Gap: 0.0951\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9504, Val Acc: 0.8571, Val F1: 0.8601, Gap: 0.0932\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9538, Val Acc: 0.8502, Val F1: 0.8525, Gap: 0.1036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9609, Val Acc: 0.8579, Val F1: 0.8609, Gap: 0.1030\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9635, Val Acc: 0.8460, Val F1: 0.8494, Gap: 0.1175\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9695, Val Acc: 0.8446, Val F1: 0.8483, Gap: 0.1249\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▆▆▆▇▇▇▇██▇██▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▆▅▄▅▇▅▅▆▆█▆▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▅▄▇██▃█▇▇▆▁▇▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▇▆▇▇█▇▇████▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▅▅▆▇▆▇██▇▇██▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▇▇▆▇█▆▆▇██▇▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▇▇█▇██▆█▇▇▆▆</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆██▇▅█▅▃▅▃▄▂▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▃▃▄▅▆▄▆▆▇▇▇█▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▇▇▆▇█████████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▆▆▇▇▇▆█▇▇▇▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▇█▆▇▇█▇▇███▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▇▇▆▇████▇████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▅█▄▅▆▇▆▇█▇█▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▆▇▅▂█▇▆▄▇▄▁▅▃▅▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▇▆▇█▇███████</td></tr><tr><td>Validation F1</td><td>▁▄▆▇▆▇█████████</td></tr><tr><td>Validation Loss</td><td>█▅▂▂▃▂▁▂▃▂▄▄▄▅▆</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇▆▇█▇▇▇███▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇█▇███▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8558</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.80369</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91515</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81564</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83821</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79425</td></tr><tr><td>Class_Negative_F1</td><td>0.86252</td></tr><tr><td>Class_Negative_Precision</td><td>0.89595</td></tr><tr><td>Class_Negative_Recall</td><td>0.8315</td></tr><tr><td>Class_Neutral_F1</td><td>0.83616</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83038</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84201</td></tr><tr><td>Class_Positive_F1</td><td>0.87132</td></tr><tr><td>Class_Positive_Precision</td><td>0.86136</td></tr><tr><td>Class_Positive_Recall</td><td>0.88151</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96948</td></tr><tr><td>Train Loss</td><td>0.11106</td></tr><tr><td>Validation Accuracy</td><td>0.84463</td></tr><tr><td>Validation F1</td><td>0.84829</td></tr><tr><td>Validation Loss</td><td>0.74504</td></tr><tr><td>Validation Precision</td><td>0.84592</td></tr><tr><td>Validation Recall</td><td>0.85288</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/fwy32w40' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/fwy32w40</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_062334-fwy32w40/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 07:13:17,965] Trial 0 finished with value: 0.857871720116618 and parameters: {'learning_rate': 8.746796060879495e-06, 'weight_decay': 2.4181128207255105e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 0 with value: 0.857871720116618.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_071320-uusswx5g</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/uusswx5g' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/uusswx5g' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/uusswx5g</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6964, Val Acc: 0.7982, Val F1: 0.8058, Gap: -0.1018\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8316, Val Acc: 0.8033, Val F1: 0.8102, Gap: 0.0283\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8712, Val Acc: 0.8480, Val F1: 0.8524, Gap: 0.0231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8942, Val Acc: 0.8654, Val F1: 0.8694, Gap: 0.0288\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9096, Val Acc: 0.8665, Val F1: 0.8702, Gap: 0.0431\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9226, Val Acc: 0.8607, Val F1: 0.8665, Gap: 0.0619\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9265, Val Acc: 0.8622, Val F1: 0.8662, Gap: 0.0642\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9342, Val Acc: 0.8580, Val F1: 0.8609, Gap: 0.0762\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9397, Val Acc: 0.8684, Val F1: 0.8719, Gap: 0.0713\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9420, Val Acc: 0.8530, Val F1: 0.8557, Gap: 0.0890\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9466, Val Acc: 0.8627, Val F1: 0.8647, Gap: 0.0839\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9480, Val Acc: 0.8683, Val F1: 0.8714, Gap: 0.0797\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9507, Val Acc: 0.8626, Val F1: 0.8663, Gap: 0.0881\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9531, Val Acc: 0.8646, Val F1: 0.8680, Gap: 0.0885\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9551, Val Acc: 0.8682, Val F1: 0.8710, Gap: 0.0869\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▇▇▇▆▆█▄▅▇▇▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▁█▆██▇▄█▇▃▅▇▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄█▁▅▃▃▄█▄▂▇▆▄▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▁▆▇▇▇▇▆█▆▆▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▂▁▅▅▄█▆▇▆▄█▆▇▆▄</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▆▇█▄▅▂▇▅▂▆▅▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▁▇▆▇▇▇▆▆▆▇▆█▅█</td></tr><tr><td>Class_Negative_Precision</td><td>▅█▇▇▇▇▇▄▄▄▃▇▅▁▇</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▆▅▅▆▅▆▇▇█▅▇█▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▅▇▇▆▇▇▇▇██▆▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▄▅▅▂▄▅▆▄▆▇▆█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▁▅█▇███▇██▇▆▆█</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▅███▇▆▇▆▇█▆█▆</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▄▇▇▆▆▇█▇▇▆▄▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▆▇█▄▃▆▅▂▃▂▃▆█▅▁</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▆██▇▇▇█▆▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▁▆██▇▇▇█▆▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▇▃▂▁▄▃▄▂▆▇▄▆▇▆</td></tr><tr><td>Validation Precision</td><td>▁▁▆███▇▆█▇▇▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▂▅▇▇▇▇▇▇▅██▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86933</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86462</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.87409</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84131</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81191</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.87292</td></tr><tr><td>Class_Negative_F1</td><td>0.89848</td></tr><tr><td>Class_Negative_Precision</td><td>0.93671</td></tr><tr><td>Class_Negative_Recall</td><td>0.86325</td></tr><tr><td>Class_Neutral_F1</td><td>0.86595</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8478</td></tr><tr><td>Class_Neutral_Recall</td><td>0.8849</td></tr><tr><td>Class_Positive_F1</td><td>0.87968</td></tr><tr><td>Class_Positive_Precision</td><td>0.93165</td></tr><tr><td>Class_Positive_Recall</td><td>0.83321</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.9551</td></tr><tr><td>Train Loss</td><td>0.15135</td></tr><tr><td>Validation Accuracy</td><td>0.8682</td></tr><tr><td>Validation F1</td><td>0.87095</td></tr><tr><td>Validation Loss</td><td>0.51568</td></tr><tr><td>Validation Precision</td><td>0.87854</td></tr><tr><td>Validation Recall</td><td>0.86567</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/uusswx5g' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/uusswx5g</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_071320-uusswx5g/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 08:03:06,613] Trial 1 finished with value: 0.8684402332361516 and parameters: {'learning_rate': 2.7809818047512282e-05, 'weight_decay': 3.608152198069414e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8684402332361516.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_080311-psxpkijh</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/psxpkijh' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/psxpkijh' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/psxpkijh</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6258, Val Acc: 0.7123, Val F1: 0.7194, Gap: -0.0865\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7697, Val Acc: 0.7800, Val F1: 0.7880, Gap: -0.0103\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8236, Val Acc: 0.8100, Val F1: 0.8171, Gap: 0.0136\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8541, Val Acc: 0.8237, Val F1: 0.8287, Gap: 0.0304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8777, Val Acc: 0.8356, Val F1: 0.8405, Gap: 0.0421\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8959, Val Acc: 0.8451, Val F1: 0.8492, Gap: 0.0508\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9091, Val Acc: 0.8489, Val F1: 0.8532, Gap: 0.0602\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9222, Val Acc: 0.8462, Val F1: 0.8506, Gap: 0.0760\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9312, Val Acc: 0.8554, Val F1: 0.8587, Gap: 0.0758\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9413, Val Acc: 0.8260, Val F1: 0.8295, Gap: 0.1152\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9487, Val Acc: 0.8452, Val F1: 0.8490, Gap: 0.1034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9551, Val Acc: 0.8499, Val F1: 0.8539, Gap: 0.1053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9587, Val Acc: 0.8480, Val F1: 0.8520, Gap: 0.1107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9658, Val Acc: 0.8505, Val F1: 0.8541, Gap: 0.1153\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9677, Val Acc: 0.8468, Val F1: 0.8510, Gap: 0.1209\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▆▇▇█▇█▆▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▆▅▇▇█▆█▅▆▇██▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▄▃▆▁▄▂▆▄█▇▄▂▂▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▆▇▇█▇█▆▇███▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▅▆▇▇▇▇▇▇▇█▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▇▆█▇▇▇█▆▇▇▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▇▆██▇▇██▇▆█</td></tr><tr><td>Class_Negative_Precision</td><td>▂▂▆█▅▃▆█▃▄▅▇▂▁▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▄▃▆▆▆▆▇▇▇▆▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▇▆█▇▇█▆▇█▇█▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▆▅▇▆▆▆▇██▆█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▃▇▄▇▇▇█▄▅█▅▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▇▇█▇▇▇▆█▇▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▂▆▂▅▂▅▄▄█▁▄▅▂▇▃</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▆▅▇▇▆▇▄█▇▆█▆█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆▇▇███▇█████</td></tr><tr><td>Validation F1</td><td>▁▄▆▆▇████▇█████</td></tr><tr><td>Validation Loss</td><td>▇▄▂▁▁▁▁▂▁▅▄▄▄▆█</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇▇▇█▇█▆▇█▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▇████▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86091</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.80637</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92336</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8162</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86505</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77257</td></tr><tr><td>Class_Negative_F1</td><td>0.87698</td></tr><tr><td>Class_Negative_Precision</td><td>0.89534</td></tr><tr><td>Class_Negative_Recall</td><td>0.85936</td></tr><tr><td>Class_Neutral_F1</td><td>0.8302</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8302</td></tr><tr><td>Class_Neutral_Recall</td><td>0.8302</td></tr><tr><td>Class_Positive_F1</td><td>0.87089</td></tr><tr><td>Class_Positive_Precision</td><td>0.83611</td></tr><tr><td>Class_Positive_Recall</td><td>0.90868</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96768</td></tr><tr><td>Train Loss</td><td>0.11173</td></tr><tr><td>Validation Accuracy</td><td>0.84682</td></tr><tr><td>Validation F1</td><td>0.85103</td></tr><tr><td>Validation Loss</td><td>0.76912</td></tr><tr><td>Validation Precision</td><td>0.84661</td></tr><tr><td>Validation Recall</td><td>0.85883</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/psxpkijh' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/psxpkijh</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_080311-psxpkijh/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 08:53:02,178] Trial 2 finished with value: 0.8554421768707483 and parameters: {'learning_rate': 8.571481594781606e-06, 'weight_decay': 1.3038406674211534e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8684402332361516.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 37125 samples\n","Label distribution: [4385 7934 8170 9137 7499]\n","Class weights computed:\n","Extremely Negative (0): 1.693\n","Extremely Positive (1): 0.936\n","Negative (2): 0.909\n","Neutral (3): 0.813\n","Positive (4): 0.990\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_085304-ig8j6h9v</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/ig8j6h9v' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/ig8j6h9v' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/ig8j6h9v</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5711, Val Acc: 0.6571, Val F1: 0.6674, Gap: -0.0860\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7197, Val Acc: 0.6761, Val F1: 0.6843, Gap: 0.0435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7779, Val Acc: 0.7731, Val F1: 0.7812, Gap: 0.0049\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8129, Val Acc: 0.7992, Val F1: 0.8057, Gap: 0.0137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8412, Val Acc: 0.8009, Val F1: 0.8069, Gap: 0.0403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8545, Val Acc: 0.8194, Val F1: 0.8248, Gap: 0.0351\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8719, Val Acc: 0.8146, Val F1: 0.8198, Gap: 0.0573\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8868, Val Acc: 0.8376, Val F1: 0.8417, Gap: 0.0492\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8999, Val Acc: 0.8304, Val F1: 0.8337, Gap: 0.0695\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9095, Val Acc: 0.8407, Val F1: 0.8454, Gap: 0.0688\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9192, Val Acc: 0.8245, Val F1: 0.8283, Gap: 0.0947\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9284, Val Acc: 0.8366, Val F1: 0.8410, Gap: 0.0918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9317, Val Acc: 0.8463, Val F1: 0.8501, Gap: 0.0854\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9398, Val Acc: 0.8495, Val F1: 0.8524, Gap: 0.0903\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9451, Val Acc: 0.8455, Val F1: 0.8489, Gap: 0.0996\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▁▅▆▆▆▆█▆█▇███▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁▅▆▅▆▆█▆▇▆███▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁█▅▅▆▆▇▄▇▆▆▄▅▄▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▅▆▆▇▇█▇█▇████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▆▅▆▇▇▇▆█████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▁▆▆▆▇▆█▆█▇▇██▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▇▇▇▇██▇█▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆▆▇▇▇▇▆█▅▇▆▆█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▃▅▅▅▅▆█▅█▇██▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▁▅▆▆▇▆▇██▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▆▆▇▇▇▆▇▇█▇█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▁▅▆▅▇▆█▇▇▆▆▇██</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▆▆▇▇▆▇██▇▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▂▁▅▆▅▇▅█▇▇▅▅▇█▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▄▄▆▅█▂▅▅██▆▃▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▆▆▇▇█▇█▇████</td></tr><tr><td>Validation F1</td><td>▁▂▅▆▆▇▇█▇█▇████</td></tr><tr><td>Validation Loss</td><td>█▇▃▂▂▁▂▁▂▂▃▂▂▃▄</td></tr><tr><td>Validation Precision</td><td>▁▂▅▆▆▇▇█▇█▇▇███</td></tr><tr><td>Validation Recall</td><td>▁▂▅▆▇▇▇▇██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84128</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.77069</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92609</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80267</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81823</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.7877</td></tr><tr><td>Class_Negative_F1</td><td>0.87722</td></tr><tr><td>Class_Negative_Precision</td><td>0.9467</td></tr><tr><td>Class_Negative_Recall</td><td>0.81724</td></tr><tr><td>Class_Neutral_F1</td><td>0.84642</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82563</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86827</td></tr><tr><td>Class_Positive_F1</td><td>0.87673</td></tr><tr><td>Class_Positive_Precision</td><td>0.89536</td></tr><tr><td>Class_Positive_Recall</td><td>0.85887</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94505</td></tr><tr><td>Train Loss</td><td>0.16372</td></tr><tr><td>Validation Accuracy</td><td>0.84548</td></tr><tr><td>Validation F1</td><td>0.84886</td></tr><tr><td>Validation Loss</td><td>0.60491</td></tr><tr><td>Validation Precision</td><td>0.85132</td></tr><tr><td>Validation Recall</td><td>0.85163</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/ig8j6h9v' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/ig8j6h9v</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_085304-ig8j6h9v/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 09:42:55,278] Trial 3 finished with value: 0.8494897959183674 and parameters: {'learning_rate': 5.186383923541179e-06, 'weight_decay': 1.0722402127985306e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8684402332361516.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 37125 samples\n","Label distribution: [4385 7934 8170 9137 7499]\n","Class weights computed:\n","Extremely Negative (0): 1.693\n","Extremely Positive (1): 0.936\n","Negative (2): 0.909\n","Neutral (3): 0.813\n","Positive (4): 0.990\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_094257-m2gx498n</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/m2gx498n' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/m2gx498n' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/m2gx498n</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5113, Val Acc: 0.5743, Val F1: 0.5882, Gap: -0.0631\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6391, Val Acc: 0.6543, Val F1: 0.6669, Gap: -0.0152\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6987, Val Acc: 0.6686, Val F1: 0.6799, Gap: 0.0301\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7361, Val Acc: 0.7345, Val F1: 0.7438, Gap: 0.0016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7623, Val Acc: 0.7445, Val F1: 0.7534, Gap: 0.0178\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7836, Val Acc: 0.7645, Val F1: 0.7727, Gap: 0.0191\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7999, Val Acc: 0.7833, Val F1: 0.7906, Gap: 0.0166\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8153, Val Acc: 0.7885, Val F1: 0.7951, Gap: 0.0268\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8288, Val Acc: 0.7960, Val F1: 0.8021, Gap: 0.0328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8406, Val Acc: 0.7809, Val F1: 0.7880, Gap: 0.0598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8521, Val Acc: 0.8044, Val F1: 0.8101, Gap: 0.0477\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8578, Val Acc: 0.7975, Val F1: 0.8026, Gap: 0.0603\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8653, Val Acc: 0.8196, Val F1: 0.8252, Gap: 0.0457\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8748, Val Acc: 0.8056, Val F1: 0.8112, Gap: 0.0692\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8823, Val Acc: 0.8236, Val F1: 0.8290, Gap: 0.0587\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▂▅▆▆▇▇▇▇▇▆█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▁▆▆▆▇▆▆▇▇▅█▆█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▁█▄▄▅▅▆▆▇▆█▆█▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▂▆▆▆▇▇▇▇▇▇█▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▃▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▂▅▆▆▇▇▇▇▇▆█▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▅▅▆▆▆▇▇█▇████</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▅▇▆▆█▇▇▅█▇███</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▅▅▅▆▇▇▇▇███▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▄▅▅▆▆▆▆▇▇▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▅▅▆▇▇▇▆▇▇█▆█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▅▆▇▇▇▇███▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▅▅▃▅▅▇▇▄▆▆█▄▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▂▄▆▅▅▄▅█▆▇▅█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▆▆▇▇▇▇▇▇█▇█</td></tr><tr><td>Validation F1</td><td>▁▃▄▆▆▆▇▇▇▇▇▇█▇█</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▆▆▇▇▇▇▇▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83123</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.76983</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90328</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.78404</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80074</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.76803</td></tr><tr><td>Class_Negative_F1</td><td>0.85884</td></tr><tr><td>Class_Negative_Precision</td><td>0.92911</td></tr><tr><td>Class_Negative_Recall</td><td>0.79844</td></tr><tr><td>Class_Neutral_F1</td><td>0.8079</td></tr><tr><td>Class_Neutral_Precision</td><td>0.80146</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81444</td></tr><tr><td>Class_Positive_F1</td><td>0.86292</td></tr><tr><td>Class_Positive_Precision</td><td>0.84097</td></tr><tr><td>Class_Positive_Recall</td><td>0.88604</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.88232</td></tr><tr><td>Train Loss</td><td>0.329</td></tr><tr><td>Validation Accuracy</td><td>0.82362</td></tr><tr><td>Validation F1</td><td>0.82899</td></tr><tr><td>Validation Loss</td><td>0.50911</td></tr><tr><td>Validation Precision</td><td>0.82842</td></tr><tr><td>Validation Recall</td><td>0.83405</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/m2gx498n' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/m2gx498n</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_094257-m2gx498n/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 10:32:49,211] Trial 4 finished with value: 0.8236151603498543 and parameters: {'learning_rate': 2.235201059378888e-06, 'weight_decay': 1.0428706983912493e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8684402332361516.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_103251-3d9ysj1z</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3d9ysj1z' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3d9ysj1z' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3d9ysj1z</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6447, Val Acc: 0.7251, Val F1: 0.7342, Gap: -0.0804\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7884, Val Acc: 0.7736, Val F1: 0.7792, Gap: 0.0149\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8401, Val Acc: 0.8305, Val F1: 0.8332, Gap: 0.0096\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8673, Val Acc: 0.8423, Val F1: 0.8471, Gap: 0.0250\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8919, Val Acc: 0.8552, Val F1: 0.8587, Gap: 0.0367\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9088, Val Acc: 0.8371, Val F1: 0.8421, Gap: 0.0717\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9220, Val Acc: 0.8465, Val F1: 0.8505, Gap: 0.0755\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9347, Val Acc: 0.8519, Val F1: 0.8544, Gap: 0.0828\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9420, Val Acc: 0.8503, Val F1: 0.8540, Gap: 0.0917\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9497, Val Acc: 0.8462, Val F1: 0.8507, Gap: 0.1035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9560, Val Acc: 0.8514, Val F1: 0.8552, Gap: 0.1046\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9609, Val Acc: 0.8296, Val F1: 0.8329, Gap: 0.1313\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9659, Val Acc: 0.8506, Val F1: 0.8545, Gap: 0.1153\n","Early stopping at epoch 13\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▁▄▇▇▇▇▆▇█▇▅█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁█▆█▅▅█▆▆▆▃▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅█▁▅▃▇▇▂▆▇▆█▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▇▇█▆▇████▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▆▇▅▇▆██▆▆█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▁█▇▇▆▆█▆▇▇▄▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▇▇█▆▇▇▇█▇▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▅▇▆█▇▅▄▃▆▂▄</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▆▅▇▄▆▇▇█▅██</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▇▇█████▇█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▄▅▄▅▆▆▆▇▆█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▇▇█▇▇▇▇▅▇▅▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▇█▇███▆█▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄█▇█▇▇▇▆▄▇▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▄▆▁▅▄▄▅▅▆█▄▅▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▇█▇█████▇█</td></tr><tr><td>Validation F1</td><td>▁▄▇▇█▇█████▇█</td></tr><tr><td>Validation Loss</td><td>▇▅▂▁▁▂▂▂▃▅▅█▆</td></tr><tr><td>Validation Precision</td><td>▁▃▇▇█▇▇█▇▇▇▆▇</td></tr><tr><td>Validation Recall</td><td>▁▄▅▇▇▇█▇███▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86305</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81729</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91423</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82021</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83455</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80635</td></tr><tr><td>Class_Negative_F1</td><td>0.87879</td></tr><tr><td>Class_Negative_Precision</td><td>0.8935</td></tr><tr><td>Class_Negative_Recall</td><td>0.86455</td></tr><tr><td>Class_Neutral_F1</td><td>0.839</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85167</td></tr><tr><td>Class_Neutral_Recall</td><td>0.8267</td></tr><tr><td>Class_Positive_F1</td><td>0.8713</td></tr><tr><td>Class_Positive_Precision</td><td>0.85424</td></tr><tr><td>Class_Positive_Recall</td><td>0.88906</td></tr><tr><td>Epoch</td><td>13</td></tr><tr><td>Train Accuracy</td><td>0.96593</td></tr><tr><td>Train Loss</td><td>0.11639</td></tr><tr><td>Validation Accuracy</td><td>0.85058</td></tr><tr><td>Validation F1</td><td>0.85447</td></tr><tr><td>Validation Loss</td><td>0.64939</td></tr><tr><td>Validation Precision</td><td>0.85025</td></tr><tr><td>Validation Recall</td><td>0.86018</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3d9ysj1z' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3d9ysj1z</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_103251-3d9ysj1z/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 11:16:03,352] Trial 5 finished with value: 0.8551992225461613 and parameters: {'learning_rate': 1.0704120379533749e-05, 'weight_decay': 6.2809976905608506e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8684402332361516.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_111605-2yyzu8kr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/2yyzu8kr' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/2yyzu8kr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/2yyzu8kr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5730, Val Acc: 0.6512, Val F1: 0.6643, Gap: -0.0783\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7214, Val Acc: 0.7437, Val F1: 0.7535, Gap: -0.0223\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7722, Val Acc: 0.7538, Val F1: 0.7625, Gap: 0.0184\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8058, Val Acc: 0.7973, Val F1: 0.8048, Gap: 0.0086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8344, Val Acc: 0.8161, Val F1: 0.8228, Gap: 0.0183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8514, Val Acc: 0.8167, Val F1: 0.8224, Gap: 0.0348\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8659, Val Acc: 0.8078, Val F1: 0.8123, Gap: 0.0581\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8829, Val Acc: 0.8304, Val F1: 0.8356, Gap: 0.0525\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8921, Val Acc: 0.8387, Val F1: 0.8428, Gap: 0.0534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9044, Val Acc: 0.8282, Val F1: 0.8322, Gap: 0.0761\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9117, Val Acc: 0.8345, Val F1: 0.8390, Gap: 0.0771\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9192, Val Acc: 0.8511, Val F1: 0.8554, Gap: 0.0681\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9286, Val Acc: 0.8485, Val F1: 0.8531, Gap: 0.0800\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9339, Val Acc: 0.8401, Val F1: 0.8438, Gap: 0.0937\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9411, Val Acc: 0.8360, Val F1: 0.8400, Gap: 0.1051\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▆▆▆▄▇▇▆▇██▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▃▆█▅▂▆▅▄▅█▇▅▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▁▆▅▃▇█▆▇█▇▅▆▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▄▆▇▆▅▇▇▆▇██▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▅▅▇▆▇▇▇▇▇▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▃▆█▅▃▆▆▅▆██▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆▇▇█▇██████▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▄▆▆▇▆▇▇██▇▆▅▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▆▅▆▆▇▇▇▇▇▇██▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▄▆▇▇▇▇███████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▅▆▆▇▇▇▇▇▇██▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▃▇▇█▇▇████▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▄▆▇▇█▇███████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▃▇█▇▇▆▇██▇█▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▇▁▃▅▆█▆▅▅▆▆█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▅▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▇▇▆▇█▇▇███▇</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▇▇▆▇█▇▇███▇</td></tr><tr><td>Validation Loss</td><td>█▅▄▂▂▂▂▁▁▂▂▁▁▃▃</td></tr><tr><td>Validation Precision</td><td>▁▄▄▆▇▇▆▇▇▇▇██▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇▇█▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84501</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.79031</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90785</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.79905</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83748</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.76399</td></tr><tr><td>Class_Negative_F1</td><td>0.85131</td></tr><tr><td>Class_Negative_Precision</td><td>0.89613</td></tr><tr><td>Class_Negative_Recall</td><td>0.81076</td></tr><tr><td>Class_Neutral_F1</td><td>0.82917</td></tr><tr><td>Class_Neutral_Precision</td><td>0.80865</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85077</td></tr><tr><td>Class_Positive_F1</td><td>0.87542</td></tr><tr><td>Class_Positive_Precision</td><td>0.8629</td></tr><tr><td>Class_Positive_Recall</td><td>0.8883</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94106</td></tr><tr><td>Train Loss</td><td>0.18405</td></tr><tr><td>Validation Accuracy</td><td>0.83601</td></tr><tr><td>Validation F1</td><td>0.83999</td></tr><tr><td>Validation Loss</td><td>0.58989</td></tr><tr><td>Validation Precision</td><td>0.8391</td></tr><tr><td>Validation Recall</td><td>0.84433</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/2yyzu8kr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/2yyzu8kr</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_111605-2yyzu8kr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 12:05:55,325] Trial 6 finished with value: 0.8510689990281827 and parameters: {'learning_rate': 4.696054040301132e-06, 'weight_decay': 1.2027113244924052e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8684402332361516.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_120557-pkphhd7f</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pkphhd7f' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pkphhd7f' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pkphhd7f</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6988, Val Acc: 0.8101, Val F1: 0.8164, Gap: -0.1114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8394, Val Acc: 0.8276, Val F1: 0.8303, Gap: 0.0118\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8777, Val Acc: 0.8220, Val F1: 0.8276, Gap: 0.0556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.9016, Val Acc: 0.8462, Val F1: 0.8498, Gap: 0.0554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9162, Val Acc: 0.8336, Val F1: 0.8386, Gap: 0.0827\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9285, Val Acc: 0.8579, Val F1: 0.8625, Gap: 0.0706\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9343, Val Acc: 0.8552, Val F1: 0.8563, Gap: 0.0791\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9428, Val Acc: 0.8697, Val F1: 0.8729, Gap: 0.0732\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9473, Val Acc: 0.8631, Val F1: 0.8661, Gap: 0.0842\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9508, Val Acc: 0.8488, Val F1: 0.8492, Gap: 0.1021\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9539, Val Acc: 0.8524, Val F1: 0.8554, Gap: 0.1015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9587, Val Acc: 0.8614, Val F1: 0.8643, Gap: 0.0973\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9615, Val Acc: 0.8641, Val F1: 0.8682, Gap: 0.0974\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9640, Val Acc: 0.8693, Val F1: 0.8723, Gap: 0.0947\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9641, Val Acc: 0.8689, Val F1: 0.8722, Gap: 0.0952\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▄▄▄▅▇▆▇▆▁▄▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▅▄▂▁▄▅▇▇▃█▁▅▅▅▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▅▇▇▅▆▄▄▇▁█▅▆▆▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▂▁▄▆▇█▅▅▁▆▆▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄█▆▇▄▆▇▆▂▆▇▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▆▄▁▁▃▇▆▆▄█▂▄▅▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆▆▄▆▅█▆▄▇▆▄█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▂▅█▇▇▄▁▇▆▇█▃▃▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▅▂▃▂▆█▆▅▁▃█▅▆▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▂▇▃▇▇▇█▇█▇▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▅▁▅█▅█▄▇█▆█▅██▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇▂▆▃▅█▇▇▇▇█▆▇█</td></tr><tr><td>Class_Positive_F1</td><td>▄▁▃█▄▇▅█▇▇█▆██▇</td></tr><tr><td>Class_Positive_Precision</td><td>▃█▁▅▂▆█▅▆▇▆▇▆▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▆▁█▇█▅▃▇▆▅▆▅▆▆▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▂▅▄▇▆█▇▆▆▇▇██</td></tr><tr><td>Validation F1</td><td>▁▃▂▅▄▇▆█▇▅▆▇▇██</td></tr><tr><td>Validation Loss</td><td>▃▂▂▁▇▁▄▃▄▅█▅▅▆▅</td></tr><tr><td>Validation Precision</td><td>▁▄▁▄▃▆▇█▆█▅▇▆▇█</td></tr><tr><td>Validation Recall</td><td>▁▂▄▆▅▆▅▇▇▃▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87814</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86268</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89416</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84489</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84511</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84468</td></tr><tr><td>Class_Negative_F1</td><td>0.89304</td></tr><tr><td>Class_Negative_Precision</td><td>0.91907</td></tr><tr><td>Class_Negative_Recall</td><td>0.86844</td></tr><tr><td>Class_Neutral_F1</td><td>0.86185</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83299</td></tr><tr><td>Class_Neutral_Recall</td><td>0.89278</td></tr><tr><td>Class_Positive_F1</td><td>0.8831</td></tr><tr><td>Class_Positive_Precision</td><td>0.92626</td></tr><tr><td>Class_Positive_Recall</td><td>0.84377</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96412</td></tr><tr><td>Train Loss</td><td>0.12376</td></tr><tr><td>Validation Accuracy</td><td>0.86893</td></tr><tr><td>Validation F1</td><td>0.8722</td></tr><tr><td>Validation Loss</td><td>0.56067</td></tr><tr><td>Validation Precision</td><td>0.87722</td></tr><tr><td>Validation Recall</td><td>0.86877</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pkphhd7f' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pkphhd7f</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_120557-pkphhd7f/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 12:56:09,143] Trial 7 finished with value: 0.8696550048590865 and parameters: {'learning_rate': 4.07450839010673e-05, 'weight_decay': 1.722376488935651e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 7 with value: 0.8696550048590865.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_125611-pivn12vq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pivn12vq' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pivn12vq' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pivn12vq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5054, Val Acc: 0.5962, Val F1: 0.6117, Gap: -0.0908\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6325, Val Acc: 0.6640, Val F1: 0.6764, Gap: -0.0315\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6949, Val Acc: 0.6955, Val F1: 0.7072, Gap: -0.0006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7323, Val Acc: 0.7258, Val F1: 0.7358, Gap: 0.0064\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7584, Val Acc: 0.7479, Val F1: 0.7567, Gap: 0.0105\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7780, Val Acc: 0.7609, Val F1: 0.7698, Gap: 0.0171\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7922, Val Acc: 0.7707, Val F1: 0.7787, Gap: 0.0215\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8109, Val Acc: 0.7941, Val F1: 0.8013, Gap: 0.0168\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8252, Val Acc: 0.7975, Val F1: 0.8039, Gap: 0.0277\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8348, Val Acc: 0.7911, Val F1: 0.7982, Gap: 0.0437\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8436, Val Acc: 0.7926, Val F1: 0.7986, Gap: 0.0509\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8554, Val Acc: 0.7963, Val F1: 0.8028, Gap: 0.0591\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8597, Val Acc: 0.8189, Val F1: 0.8251, Gap: 0.0408\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8666, Val Acc: 0.8155, Val F1: 0.8213, Gap: 0.0512\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8740, Val Acc: 0.8268, Val F1: 0.8322, Gap: 0.0472\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▅▅▆▆▇▇▇▆▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▂▄▄█▄█▆▅▃▅█▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▄▅▅▆▄▇▅▇▇█▇▆▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▅▅▆▆▇▇▇▆▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▃▅▅▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▄▄▅▆▅▇▇▆▅▆█▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▄▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▁▄▅▆▆▇▆▇▇▆▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▅▆▆▇▇▇▇▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▅▅▆▇▇▇██████</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▅▅▆▅▆▆█▆▇▆█▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▆▆▇▇▇▇█▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▅▃▇▄▆▆█▅▇▆█▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▂▁▄▆▄▇▇▇▅█▇█▇█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▃▄▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83781</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.79835</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88139</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.78783</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.79205</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78366</td></tr><tr><td>Class_Negative_F1</td><td>0.86293</td></tr><tr><td>Class_Negative_Precision</td><td>0.91813</td></tr><tr><td>Class_Negative_Recall</td><td>0.814</td></tr><tr><td>Class_Neutral_F1</td><td>0.81385</td></tr><tr><td>Class_Neutral_Precision</td><td>0.79532</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83326</td></tr><tr><td>Class_Positive_F1</td><td>0.85856</td></tr><tr><td>Class_Positive_Precision</td><td>0.86749</td></tr><tr><td>Class_Positive_Recall</td><td>0.84981</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.87397</td></tr><tr><td>Train Loss</td><td>0.36766</td></tr><tr><td>Validation Accuracy</td><td>0.82677</td></tr><tr><td>Validation F1</td><td>0.8322</td></tr><tr><td>Validation Loss</td><td>0.51927</td></tr><tr><td>Validation Precision</td><td>0.83427</td></tr><tr><td>Validation Recall</td><td>0.83242</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pivn12vq' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/pivn12vq</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_125611-pivn12vq/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 13:46:18,334] Trial 8 finished with value: 0.826773566569485 and parameters: {'learning_rate': 2.0587999410350136e-06, 'weight_decay': 1.16696661952905e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 7 with value: 0.8696550048590865.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_134620-qxqjth61</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/qxqjth61' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/qxqjth61' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/qxqjth61</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.7070, Val Acc: 0.7782, Val F1: 0.7824, Gap: -0.0711\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8297, Val Acc: 0.7988, Val F1: 0.8039, Gap: 0.0308\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8611, Val Acc: 0.8534, Val F1: 0.8585, Gap: 0.0077\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8772, Val Acc: 0.8503, Val F1: 0.8558, Gap: 0.0269\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8872, Val Acc: 0.8384, Val F1: 0.8428, Gap: 0.0487\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8916, Val Acc: 0.8431, Val F1: 0.8492, Gap: 0.0486\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8968, Val Acc: 0.8347, Val F1: 0.8412, Gap: 0.0621\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9003, Val Acc: 0.8700, Val F1: 0.8755, Gap: 0.0302\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9044, Val Acc: 0.8567, Val F1: 0.8601, Gap: 0.0477\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9072, Val Acc: 0.8621, Val F1: 0.8657, Gap: 0.0451\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9082, Val Acc: 0.8553, Val F1: 0.8583, Gap: 0.0529\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9101, Val Acc: 0.8465, Val F1: 0.8500, Gap: 0.0637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9149, Val Acc: 0.8500, Val F1: 0.8527, Gap: 0.0649\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9182, Val Acc: 0.8619, Val F1: 0.8653, Gap: 0.0564\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9151, Val Acc: 0.8614, Val F1: 0.8632, Gap: 0.0537\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▁▆▇▄▇▇█▇▇▇▅▄▇▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁█▇▇▂▄▆▇▆▄▅▃▂▅▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▁▄▅█▇▅▆▆▇▆██▇▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▇█▄▇▆█▇▇▇▆▅▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▆▆▃█▇█▅▅▅▇▆▆▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▇▇▄▄▄▆█▇█▄▃▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▇▃▆▃█▆▆▇▇█▅█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▇▆█▇▃▆▄▅▆▆▆▃▅</td></tr><tr><td>Class_Negative_Recall</td><td>▅▆▅▆▁▅▅▇▇▆▆▆███</td></tr><tr><td>Class_Neutral_F1</td><td>▃▁▇▅▇▅▅▇▇█▇▆█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▂▅▇▅▄▅▅▇▄▇▇█▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▁█▄▅▃▄▇▇▆▇▄▅▅█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▇▆▇▆▆█▆▇▅▆▇▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>█▁▇▄▅▃▃▅█▇█▃▆▅▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁█▅▇▇██▇▄▅▄█▆▇▄</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▇▆▆▆▅█▇▇▇▆▆▇▇</td></tr><tr><td>Validation F1</td><td>▁▃▇▇▆▆▅█▇▇▇▆▆▇▇</td></tr><tr><td>Validation Loss</td><td>█▇▁▂▂▃▄▁▂▁▁▄▄▂▁</td></tr><tr><td>Validation Precision</td><td>▁▃█▆▅▅▅█▇▇▇▅▅▆█</td></tr><tr><td>Validation Recall</td><td>▁▂▆▇▆▇▆█▆▇▆▇▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8626</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.904</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.82482</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84627</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84038</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.85224</td></tr><tr><td>Class_Negative_F1</td><td>0.89315</td></tr><tr><td>Class_Negative_Precision</td><td>0.91216</td></tr><tr><td>Class_Negative_Recall</td><td>0.87492</td></tr><tr><td>Class_Neutral_F1</td><td>0.8547</td></tr><tr><td>Class_Neutral_Precision</td><td>0.79977</td></tr><tr><td>Class_Neutral_Recall</td><td>0.91772</td></tr><tr><td>Class_Positive_F1</td><td>0.85925</td></tr><tr><td>Class_Positive_Precision</td><td>0.93834</td></tr><tr><td>Class_Positive_Recall</td><td>0.79245</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.91512</td></tr><tr><td>Train Loss</td><td>0.25316</td></tr><tr><td>Validation Accuracy</td><td>0.86139</td></tr><tr><td>Validation F1</td><td>0.86319</td></tr><tr><td>Validation Loss</td><td>0.41191</td></tr><tr><td>Validation Precision</td><td>0.87893</td></tr><tr><td>Validation Recall</td><td>0.85243</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/qxqjth61' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/qxqjth61</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_134620-qxqjth61/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 14:36:24,881] Trial 9 finished with value: 0.870019436345967 and parameters: {'learning_rate': 3.0224288296306628e-05, 'weight_decay': 8.664492208148433e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 9 with value: 0.870019436345967.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 37125 samples\n","Label distribution: [4385 7934 8170 9137 7499]\n","Class weights computed:\n","Extremely Negative (0): 1.693\n","Extremely Positive (1): 0.936\n","Negative (2): 0.909\n","Neutral (3): 0.813\n","Positive (4): 0.990\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_143627-yse40mjo</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/yse40mjo' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/yse40mjo' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/yse40mjo</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6783, Val Acc: 0.7875, Val F1: 0.7940, Gap: -0.1093\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8228, Val Acc: 0.8387, Val F1: 0.8439, Gap: -0.0159\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8689, Val Acc: 0.8520, Val F1: 0.8583, Gap: 0.0168\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8914, Val Acc: 0.8284, Val F1: 0.8295, Gap: 0.0630\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9048, Val Acc: 0.8399, Val F1: 0.8432, Gap: 0.0649\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9160, Val Acc: 0.8407, Val F1: 0.8450, Gap: 0.0752\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9246, Val Acc: 0.8654, Val F1: 0.8691, Gap: 0.0592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9316, Val Acc: 0.8677, Val F1: 0.8711, Gap: 0.0639\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9379, Val Acc: 0.8530, Val F1: 0.8554, Gap: 0.0849\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9398, Val Acc: 0.8658, Val F1: 0.8691, Gap: 0.0740\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9455, Val Acc: 0.8590, Val F1: 0.8624, Gap: 0.0865\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9469, Val Acc: 0.8616, Val F1: 0.8650, Gap: 0.0853\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9490, Val Acc: 0.8530, Val F1: 0.8569, Gap: 0.0960\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9509, Val Acc: 0.8505, Val F1: 0.8552, Gap: 0.1005\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9536, Val Acc: 0.8673, Val F1: 0.8705, Gap: 0.0863\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▇▆▃██▇▅▇▇▇▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▇▆▁▇▇▇▃▆▅▅▅██</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▄▁▁█▃▃▂▇▄▄▅▅▁▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▆▄███▅▇▇▇▆▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▂▃▆▇▆▇▇██▇██▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄█▇▁▇▇▇▃▅▅▅▄▅▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆▆▇▅██▆█▇▇█▃▆</td></tr><tr><td>Class_Negative_Precision</td><td>▃▆▇▄█▁▇█▃▆▇▇▆▅▂</td></tr><tr><td>Class_Negative_Recall</td><td>▂▃▃▅▃█▄▃▇▆▃▃▅▁█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▄▇▂████▇█▆▅█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▆▁▅█▄▄▆▄▃▄▅▂▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▆▅▇▆▁▇▇▇██▇▆▆▆</td></tr><tr><td>Class_Positive_F1</td><td>▄▇▇▁█▅▇█▇█▇▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▅▆▆█▅▁▆▅▆▆▆▅▄▃▅</td></tr><tr><td>Class_Positive_Recall</td><td>▄▆▆▁▇█▅▇▆▆▆▆▇▇▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▅▆▆██▇█▇▇▇▆█</td></tr><tr><td>Validation F1</td><td>▁▆▇▄▅▆██▇█▇▇▇▇█</td></tr><tr><td>Validation Loss</td><td>▇▂▂▅▁▃▂▁▄▄▅▃▆█▄</td></tr><tr><td>Validation Precision</td><td>▁▅▇▆▅▅██▆█▇▇▆▇█</td></tr><tr><td>Validation Recall</td><td>▁▆▆▃▇▇▇█▇█▇██▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87494</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.9136</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.83942</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.85313</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83422</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.87292</td></tr><tr><td>Class_Negative_F1</td><td>0.88046</td></tr><tr><td>Class_Negative_Precision</td><td>0.86637</td></tr><tr><td>Class_Negative_Recall</td><td>0.89501</td></tr><tr><td>Class_Neutral_F1</td><td>0.85474</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86372</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84595</td></tr><tr><td>Class_Positive_F1</td><td>0.88914</td></tr><tr><td>Class_Positive_Precision</td><td>0.8915</td></tr><tr><td>Class_Positive_Recall</td><td>0.88679</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95364</td></tr><tr><td>Train Loss</td><td>0.14619</td></tr><tr><td>Validation Accuracy</td><td>0.86735</td></tr><tr><td>Validation F1</td><td>0.87048</td></tr><tr><td>Validation Loss</td><td>0.48529</td></tr><tr><td>Validation Precision</td><td>0.87388</td></tr><tr><td>Validation Recall</td><td>0.86802</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/yse40mjo' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/yse40mjo</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_143627-yse40mjo/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 15:26:30,846] Trial 10 finished with value: 0.8677113702623906 and parameters: {'learning_rate': 2.19639031138828e-05, 'weight_decay': 8.26735740246045e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 9 with value: 0.870019436345967.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_152633-o2y1r9oq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/o2y1r9oq' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/o2y1r9oq' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/o2y1r9oq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.7125, Val Acc: 0.7923, Val F1: 0.7890, Gap: -0.0798\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8382, Val Acc: 0.8401, Val F1: 0.8476, Gap: -0.0019\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8711, Val Acc: 0.8533, Val F1: 0.8564, Gap: 0.0178\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8900, Val Acc: 0.8557, Val F1: 0.8594, Gap: 0.0343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8997, Val Acc: 0.8578, Val F1: 0.8624, Gap: 0.0419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9077, Val Acc: 0.8724, Val F1: 0.8738, Gap: 0.0352\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9151, Val Acc: 0.8654, Val F1: 0.8696, Gap: 0.0497\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9206, Val Acc: 0.8554, Val F1: 0.8585, Gap: 0.0652\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9255, Val Acc: 0.8567, Val F1: 0.8599, Gap: 0.0689\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9279, Val Acc: 0.8706, Val F1: 0.8740, Gap: 0.0573\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9340, Val Acc: 0.8659, Val F1: 0.8693, Gap: 0.0681\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9357, Val Acc: 0.8598, Val F1: 0.8629, Gap: 0.0759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9387, Val Acc: 0.8710, Val F1: 0.8745, Gap: 0.0677\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9409, Val Acc: 0.8619, Val F1: 0.8650, Gap: 0.0790\n","Early stopping at epoch 14\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▇█▇▇▇█▇▇██▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>█▄▆▇▃█▅▁█▅▅▂▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▇▇▅█▅▇█▆▇▇█▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▇▆▅█▇▅▇██▅▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁█▇▇▅▆█▇▇▇█▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▁▆▅▅█▅▃▇▆▆▄▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▂▅▅▅▆█▇▇▂▆▁▄▆▃</td></tr><tr><td>Class_Negative_Precision</td><td>▆▇▆▆███▇▂▆▁▆▇▄</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▄▄▃▄▃▄▇▄█▃▄▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▆▇█▆▇▅▇▇█▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▄▇▆▆█████▇▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▄▇▇▇▄█▅▃▁▄▃▄▆█</td></tr><tr><td>Class_Positive_F1</td><td>▂▆▁▇▇▇▇▆▆▇██▇▅</td></tr><tr><td>Class_Positive_Precision</td><td>▂▅█▆▅▆▂▃▁▂▆▃▄▇</td></tr><tr><td>Class_Positive_Recall</td><td>▅▅▁▅▆▅█▇██▆▇▇▄</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇█▇▇▇█▇▇█▇</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇██▇▇██▇█▇</td></tr><tr><td>Validation Loss</td><td>█▄▃▃▃▁▂▄▃▃▃▆▃▄</td></tr><tr><td>Validation Precision</td><td>▁▄▆▆▅█▆▄▅▆▆▄▆▆</td></tr><tr><td>Validation Recall</td><td>▁▆▆▆▇▇█▇▇████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87436</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.88878</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8604</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83719</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85296</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82199</td></tr><tr><td>Class_Negative_F1</td><td>0.87589</td></tr><tr><td>Class_Negative_Precision</td><td>0.87363</td></tr><tr><td>Class_Negative_Recall</td><td>0.87816</td></tr><tr><td>Class_Neutral_F1</td><td>0.85844</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81218</td></tr><tr><td>Class_Neutral_Recall</td><td>0.91028</td></tr><tr><td>Class_Positive_F1</td><td>0.87909</td></tr><tr><td>Class_Positive_Precision</td><td>0.94686</td></tr><tr><td>Class_Positive_Recall</td><td>0.82038</td></tr><tr><td>Epoch</td><td>14</td></tr><tr><td>Train Accuracy</td><td>0.94093</td></tr><tr><td>Train Loss</td><td>0.18934</td></tr><tr><td>Validation Accuracy</td><td>0.86188</td></tr><tr><td>Validation F1</td><td>0.86499</td></tr><tr><td>Validation Loss</td><td>0.47429</td></tr><tr><td>Validation Precision</td><td>0.87488</td></tr><tr><td>Validation Recall</td><td>0.85824</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/o2y1r9oq' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/o2y1r9oq</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_152633-o2y1r9oq/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 16:13:17,476] Trial 11 finished with value: 0.8724489795918368 and parameters: {'learning_rate': 4.964231176733226e-05, 'weight_decay': 3.3543626906404976e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_161319-1uu2rfxc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/1uu2rfxc' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/1uu2rfxc' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/1uu2rfxc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.7097, Val Acc: 0.7343, Val F1: 0.7477, Gap: -0.0247\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8259, Val Acc: 0.8066, Val F1: 0.8164, Gap: 0.0193\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8535, Val Acc: 0.8437, Val F1: 0.8488, Gap: 0.0098\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8635, Val Acc: 0.8393, Val F1: 0.8421, Gap: 0.0242\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8709, Val Acc: 0.8499, Val F1: 0.8560, Gap: 0.0210\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8755, Val Acc: 0.8228, Val F1: 0.8258, Gap: 0.0527\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8821, Val Acc: 0.8492, Val F1: 0.8548, Gap: 0.0329\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8876, Val Acc: 0.8627, Val F1: 0.8668, Gap: 0.0249\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8926, Val Acc: 0.8621, Val F1: 0.8658, Gap: 0.0304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8962, Val Acc: 0.8624, Val F1: 0.8667, Gap: 0.0338\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8989, Val Acc: 0.8586, Val F1: 0.8631, Gap: 0.0403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9036, Val Acc: 0.8526, Val F1: 0.8559, Gap: 0.0509\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9075, Val Acc: 0.8500, Val F1: 0.8548, Gap: 0.0576\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9070, Val Acc: 0.8454, Val F1: 0.8500, Gap: 0.0616\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9095, Val Acc: 0.8666, Val F1: 0.8708, Gap: 0.0429\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▅▆▃▇▁▇▇▇██▆▇▆█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▅▄▇▆▁▇▅█▆▅▇▇▆▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▅▇▁▅█▄▇▃▆▇▄▅▄▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▆▆▇▃▇▇█▇▇▆▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▃▅▇▂▇▆▁▇▅▄▃▅▇▃█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▅▆▅▂█▆▇▇▇▆▆▇▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▇▇▅▇▇▇█▄▇▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▆▇█▅▇█▄▆█▇▇▁▄▅▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▅▆▆▅▆▆▅▆▇▆█▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇▇▇▇▇█████▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▆▆▅▇█▇▅█▇▆▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇▆▆▆▆▆▇█▆▇▇▅▅▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▇▇▆▇█▇▇▇█▆▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▆▆▆▆▅▇▇█▆█▇▄▅▇</td></tr><tr><td>Class_Positive_Recall</td><td>█▄▅▆▇▇▄▄▃▆▁▄▇▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇▇▆▇████▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▇▆▇▅▇████▇▇▇█</td></tr><tr><td>Validation Loss</td><td>█▅▃▃▂▄▂▁▂▁▂▂▃▂▁</td></tr><tr><td>Validation Precision</td><td>▁▅▆▆▆▅▇▇█▇▇▇▆▆▇</td></tr><tr><td>Validation Recall</td><td>▁▄▇▆▇▆▇█▇█▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87866</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83143</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.93157</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83752</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86141</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81493</td></tr><tr><td>Class_Negative_F1</td><td>0.88355</td></tr><tr><td>Class_Negative_Precision</td><td>0.92488</td></tr><tr><td>Class_Negative_Recall</td><td>0.84576</td></tr><tr><td>Class_Neutral_F1</td><td>0.85629</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83375</td></tr><tr><td>Class_Neutral_Recall</td><td>0.88009</td></tr><tr><td>Class_Positive_F1</td><td>0.8981</td></tr><tr><td>Class_Positive_Precision</td><td>0.90498</td></tr><tr><td>Class_Positive_Recall</td><td>0.89132</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.90949</td></tr><tr><td>Train Loss</td><td>0.27081</td></tr><tr><td>Validation Accuracy</td><td>0.86662</td></tr><tr><td>Validation F1</td><td>0.87082</td></tr><tr><td>Validation Loss</td><td>0.39896</td></tr><tr><td>Validation Precision</td><td>0.87129</td></tr><tr><td>Validation Recall</td><td>0.87273</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/1uu2rfxc' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/1uu2rfxc</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_161319-1uu2rfxc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 17:03:19,681] Trial 12 finished with value: 0.8666180758017493 and parameters: {'learning_rate': 4.611472085967962e-05, 'weight_decay': 9.454035191298539e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_170321-4m3xm649</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4m3xm649' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4m3xm649' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4m3xm649</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6758, Val Acc: 0.7753, Val F1: 0.7835, Gap: -0.0994\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8216, Val Acc: 0.8213, Val F1: 0.8284, Gap: 0.0003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8636, Val Acc: 0.8081, Val F1: 0.8126, Gap: 0.0556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8906, Val Acc: 0.8612, Val F1: 0.8655, Gap: 0.0294\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9045, Val Acc: 0.8608, Val F1: 0.8660, Gap: 0.0438\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9184, Val Acc: 0.8547, Val F1: 0.8580, Gap: 0.0637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9244, Val Acc: 0.8575, Val F1: 0.8605, Gap: 0.0669\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9361, Val Acc: 0.8533, Val F1: 0.8562, Gap: 0.0829\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9401, Val Acc: 0.8565, Val F1: 0.8601, Gap: 0.0836\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9433, Val Acc: 0.8508, Val F1: 0.8547, Gap: 0.0925\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9474, Val Acc: 0.8670, Val F1: 0.8695, Gap: 0.0804\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9508, Val Acc: 0.8650, Val F1: 0.8690, Gap: 0.0857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9531, Val Acc: 0.8557, Val F1: 0.8608, Gap: 0.0974\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9552, Val Acc: 0.8523, Val F1: 0.8546, Gap: 0.1029\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9584, Val Acc: 0.8630, Val F1: 0.8663, Gap: 0.0955\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▂▇█▆▆▄▇▇▇██▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▇▁▆▆█▄▂▆▇▅▇▆▆▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▁▇▅▅▁▇█▄▃▆▄▅▄▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▄█▇█▇▆▇▇█████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▃▃▁▅█▅▆█▇▆▆▂█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▃▇█▇▅▄▆▅▆▆▆▇▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▆▄▆█▆▄▆▇▅▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▆▇█▆▂▇█▅▁▃▅█▇▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▃▃▄▅▆▃▆▅▇█▆▁▃▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▃▇▇▇▇▇▇▆█▇▆▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▇▇█▆▅█▆▆▇▆▅▅▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▄▁▅▅▅█▅▆▅▇▆▆▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▁▇▇▇▇▇▇▆█▇▆▃▇</td></tr><tr><td>Class_Positive_Precision</td><td>▂▃▁▅▆▅█▅▅▄▇▅▄█▅</td></tr><tr><td>Class_Positive_Recall</td><td>▇▇█▇▆█▄█▇█▅▇█▁▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▄██▇▇▇▇▇██▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▃██▇▇▇▇▇██▇▇█</td></tr><tr><td>Validation Loss</td><td>█▄▅▁▁▂▃▃▄▅▄▄▆▆▆</td></tr><tr><td>Validation Precision</td><td>▁▅▃██▇█▇▇▇██▇██</td></tr><tr><td>Validation Recall</td><td>▁▄▅██▇▇█▇▇██▇▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87006</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83841</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.9042</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8394</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8735</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80787</td></tr><tr><td>Class_Negative_F1</td><td>0.89308</td></tr><tr><td>Class_Negative_Precision</td><td>0.91272</td></tr><tr><td>Class_Negative_Recall</td><td>0.87427</td></tr><tr><td>Class_Neutral_F1</td><td>0.84866</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84699</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85033</td></tr><tr><td>Class_Positive_F1</td><td>0.88046</td></tr><tr><td>Class_Positive_Precision</td><td>0.84418</td></tr><tr><td>Class_Positive_Recall</td><td>0.92</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95844</td></tr><tr><td>Train Loss</td><td>0.1373</td></tr><tr><td>Validation Accuracy</td><td>0.86297</td></tr><tr><td>Validation F1</td><td>0.86633</td></tr><tr><td>Validation Loss</td><td>0.56099</td></tr><tr><td>Validation Precision</td><td>0.86316</td></tr><tr><td>Validation Recall</td><td>0.87133</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4m3xm649' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4m3xm649</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_170321-4m3xm649/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 17:53:29,835] Trial 13 finished with value: 0.8669825072886297 and parameters: {'learning_rate': 2.0112305715065588e-05, 'weight_decay': 3.8827169320974084e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 37125 samples\n","Label distribution: [4385 7934 8170 9137 7499]\n","Class weights computed:\n","Extremely Negative (0): 1.693\n","Extremely Positive (1): 0.936\n","Negative (2): 0.909\n","Neutral (3): 0.813\n","Positive (4): 0.990\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_175332-3pk3b8c6</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3pk3b8c6' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3pk3b8c6' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3pk3b8c6</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6974, Val Acc: 0.7136, Val F1: 0.7264, Gap: -0.0162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8338, Val Acc: 0.8007, Val F1: 0.8082, Gap: 0.0331\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8728, Val Acc: 0.8392, Val F1: 0.8438, Gap: 0.0336\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8933, Val Acc: 0.8513, Val F1: 0.8561, Gap: 0.0420\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9056, Val Acc: 0.8578, Val F1: 0.8610, Gap: 0.0478\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9163, Val Acc: 0.8571, Val F1: 0.8599, Gap: 0.0592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9261, Val Acc: 0.8592, Val F1: 0.8626, Gap: 0.0669\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9318, Val Acc: 0.8366, Val F1: 0.8418, Gap: 0.0952\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9373, Val Acc: 0.8471, Val F1: 0.8500, Gap: 0.0902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9377, Val Acc: 0.8671, Val F1: 0.8705, Gap: 0.0706\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9432, Val Acc: 0.8601, Val F1: 0.8640, Gap: 0.0832\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9449, Val Acc: 0.8414, Val F1: 0.8436, Gap: 0.1035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9480, Val Acc: 0.8650, Val F1: 0.8680, Gap: 0.0830\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9486, Val Acc: 0.8557, Val F1: 0.8589, Gap: 0.0929\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9525, Val Acc: 0.8526, Val F1: 0.8558, Gap: 0.0998\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▅▆▇▅▇▇▅█▇▄▇▆▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▃▄▆▃▅▅▃█▇▂▇▄▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▆▆▇▄█▆▅▇▁▁█▂▇▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▅▆▇▆▇▇▆█▇▅█▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▅▄▁▁▅▄▇▂▅▂▅█▇▅▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▆▆▇▆▆▇▅█▆▄▆▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▁▄▆▇▆▇▆▆▆▆▆▇█▃</td></tr><tr><td>Class_Negative_Precision</td><td>▅▇▅▇▇▇▇█▄▅▅▅▆▇▁</td></tr><tr><td>Class_Negative_Recall</td><td>▃▁▅▅▅▅▅▄▇▆▆▆▆▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▇████▇▇██▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▆▇▇▇▆██▇▆▇▆▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▇▇▇██▆▆██▇█▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▇█▇██▆▇██▇█▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄██▆▇█▅▆█▇▆▇▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>█▇▁▂▅▄▂▇▅▁▄▆▅▅▂</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇███▇▇██▇█▇▇</td></tr><tr><td>Validation F1</td><td>▁▅▇▇█▇█▇▇██▇█▇▇</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▂▁▂▂▄▂▃▄▃▄▄</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇▇▇▆▆█▇▆█▇▇</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇███▇███▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86096</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.815</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91241</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83096</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85372</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80938</td></tr><tr><td>Class_Negative_F1</td><td>0.86613</td></tr><tr><td>Class_Negative_Precision</td><td>0.83343</td></tr><tr><td>Class_Negative_Recall</td><td>0.90149</td></tr><tr><td>Class_Neutral_F1</td><td>0.84141</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87224</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81269</td></tr><tr><td>Class_Positive_F1</td><td>0.87934</td></tr><tr><td>Class_Positive_Precision</td><td>0.87867</td></tr><tr><td>Class_Positive_Recall</td><td>0.88</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95246</td></tr><tr><td>Train Loss</td><td>0.14643</td></tr><tr><td>Validation Accuracy</td><td>0.85265</td></tr><tr><td>Validation F1</td><td>0.85576</td></tr><tr><td>Validation Loss</td><td>0.52655</td></tr><tr><td>Validation Precision</td><td>0.85061</td></tr><tr><td>Validation Recall</td><td>0.86319</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_14</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3pk3b8c6' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/3pk3b8c6</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_175332-3pk3b8c6/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 18:43:49,134] Trial 14 finished with value: 0.8671039844509232 and parameters: {'learning_rate': 3.0311844113662203e-05, 'weight_decay': 3.8252125018840304e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_184351-tn9yx8fp</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/tn9yx8fp' target=\"_blank\">trial_15</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/tn9yx8fp' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/tn9yx8fp</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6626, Val Acc: 0.7257, Val F1: 0.7352, Gap: -0.0631\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8134, Val Acc: 0.8344, Val F1: 0.8400, Gap: -0.0210\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8533, Val Acc: 0.8451, Val F1: 0.8505, Gap: 0.0082\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8781, Val Acc: 0.8533, Val F1: 0.8575, Gap: 0.0249\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8952, Val Acc: 0.8533, Val F1: 0.8575, Gap: 0.0419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9070, Val Acc: 0.8501, Val F1: 0.8535, Gap: 0.0569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9174, Val Acc: 0.8681, Val F1: 0.8722, Gap: 0.0493\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9238, Val Acc: 0.8698, Val F1: 0.8736, Gap: 0.0540\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9304, Val Acc: 0.8723, Val F1: 0.8758, Gap: 0.0580\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9320, Val Acc: 0.8584, Val F1: 0.8618, Gap: 0.0737\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9375, Val Acc: 0.8507, Val F1: 0.8539, Gap: 0.0868\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9387, Val Acc: 0.8556, Val F1: 0.8595, Gap: 0.0832\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9427, Val Acc: 0.8489, Val F1: 0.8522, Gap: 0.0938\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9427, Val Acc: 0.8528, Val F1: 0.8561, Gap: 0.0899\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9465, Val Acc: 0.8529, Val F1: 0.8565, Gap: 0.0936\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▆▇▆▅███▇▆▇▆▅▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▆▅▃▂▆▅█▄▃▆█▃▃</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▆▃▅▇█▅▇▃▇▇▄▁▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▆▇▆▆███▇▆█▇▆▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▇▇▆▆▇▇▇██▇▇▇▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▃▄▄▅▂▆▆█▃▁▇▄▃▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇▇▆▇▇█▇▅▇█▄█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄▆▆█▆▇▇▇▇▃▆▇▁█▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▆▅▆▅▆▆▆█▆▇█▅▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▆▇██████▇▆▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▅▄▇▆▇▇▇█▇██▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▅█▅▇▆▆▆▅▅▄▅▅▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▇▇▇██████▇▆█▇█</td></tr><tr><td>Class_Positive_Precision</td><td>█▄▄█▆▇▅▅▅▅▃▁▄▃▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇▇▅▆▆▇▇▇▇██▇█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇▇▇███▇▇▇▇▇▇</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇▇███▇▇▇▇▇▇</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▁▂▁▁▂▃▄▃▄▄▄</td></tr><tr><td>Validation Precision</td><td>▁▅▆█▆▆▇▇█▆▆▇▆▆▆</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇▇████▇█▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8541</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.8</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91606</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81211</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80586</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81846</td></tr><tr><td>Class_Negative_F1</td><td>0.86593</td></tr><tr><td>Class_Negative_Precision</td><td>0.89434</td></tr><tr><td>Class_Negative_Recall</td><td>0.83927</td></tr><tr><td>Class_Neutral_F1</td><td>0.85341</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87894</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82932</td></tr><tr><td>Class_Positive_F1</td><td>0.89717</td></tr><tr><td>Class_Positive_Precision</td><td>0.88595</td></tr><tr><td>Class_Positive_Recall</td><td>0.90868</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94653</td></tr><tr><td>Train Loss</td><td>0.17275</td></tr><tr><td>Validation Accuracy</td><td>0.85289</td></tr><tr><td>Validation F1</td><td>0.85654</td></tr><tr><td>Validation Loss</td><td>0.52617</td></tr><tr><td>Validation Precision</td><td>0.85302</td></tr><tr><td>Validation Recall</td><td>0.86236</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_15</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/tn9yx8fp' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/tn9yx8fp</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_184351-tn9yx8fp/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 19:34:05,273] Trial 15 finished with value: 0.8723275024295433 and parameters: {'learning_rate': 1.5629880381668428e-05, 'weight_decay': 5.519667425794469e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_193407-iezuby4r</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/iezuby4r' target=\"_blank\">trial_16</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/iezuby4r' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/iezuby4r</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6439, Val Acc: 0.7512, Val F1: 0.7613, Gap: -0.1073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7894, Val Acc: 0.8130, Val F1: 0.8188, Gap: -0.0237\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8370, Val Acc: 0.8271, Val F1: 0.8335, Gap: 0.0098\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8702, Val Acc: 0.8483, Val F1: 0.8523, Gap: 0.0219\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8907, Val Acc: 0.8483, Val F1: 0.8523, Gap: 0.0424\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9077, Val Acc: 0.8558, Val F1: 0.8598, Gap: 0.0519\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9189, Val Acc: 0.8537, Val F1: 0.8579, Gap: 0.0652\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9328, Val Acc: 0.8560, Val F1: 0.8588, Gap: 0.0768\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9383, Val Acc: 0.8438, Val F1: 0.8473, Gap: 0.0946\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9481, Val Acc: 0.8559, Val F1: 0.8587, Gap: 0.0922\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9524, Val Acc: 0.8622, Val F1: 0.8645, Gap: 0.0902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9543, Val Acc: 0.8414, Val F1: 0.8450, Gap: 0.1129\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9572, Val Acc: 0.8556, Val F1: 0.8585, Gap: 0.1017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9629, Val Acc: 0.8591, Val F1: 0.8621, Gap: 0.1038\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9666, Val Acc: 0.8554, Val F1: 0.8584, Gap: 0.1111\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▆▇▇▇▆▅▇▇▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▃▃▇▃▃▅▄▁▇▆▄█▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▄▅▂▆▇▅▆█▃▄▆▂▃▃</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▅▇▆▇▇▇▆██▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▄▆▆▆▇▇▆▇▇█▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▆█▅▆▇▅▃▇█▄█▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▇▇███▇▇█▇▇█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆█▇██▆▆▆▆▄▄▄▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▄▂▃▄▃▅▄▄▆▆▆██</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▇█▇█▇██▆███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▆▄▅▇▆██▆▇██▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▅██▇▆▇▆█▇▄▆▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▇▇█▇██▇█▆▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▅▇▇██▆▃▅▆▆▆▁▄▄▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▃▄▅▅▆▇▇▆▆▆█▇▇▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇█▇█▇██▇███</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▇███▇██▇███</td></tr><tr><td>Validation Loss</td><td>█▄▂▁▁▁▂▂▄▄▄▇▅▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▆█▇█▇▇▆██▆▇██</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▇███▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86691</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.87828</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.85584</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83308</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84877</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81795</td></tr><tr><td>Class_Negative_F1</td><td>0.85919</td></tr><tr><td>Class_Negative_Precision</td><td>0.82892</td></tr><tr><td>Class_Negative_Recall</td><td>0.89177</td></tr><tr><td>Class_Neutral_F1</td><td>0.85147</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8487</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85427</td></tr><tr><td>Class_Positive_F1</td><td>0.88159</td></tr><tr><td>Class_Positive_Precision</td><td>0.8925</td></tr><tr><td>Class_Positive_Recall</td><td>0.87094</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96657</td></tr><tr><td>Train Loss</td><td>0.12006</td></tr><tr><td>Validation Accuracy</td><td>0.85544</td></tr><tr><td>Validation F1</td><td>0.85845</td></tr><tr><td>Validation Loss</td><td>0.66945</td></tr><tr><td>Validation Precision</td><td>0.85943</td></tr><tr><td>Validation Recall</td><td>0.85815</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_16</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/iezuby4r' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/iezuby4r</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_193407-iezuby4r/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 20:24:32,512] Trial 16 finished with value: 0.8622448979591837 and parameters: {'learning_rate': 1.142329916462929e-05, 'weight_decay': 2.171894761947562e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_202434-rp4fpazn</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/rp4fpazn' target=\"_blank\">trial_17</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/rp4fpazn' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/rp4fpazn</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6690, Val Acc: 0.7364, Val F1: 0.7418, Gap: -0.0674\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8125, Val Acc: 0.7717, Val F1: 0.7801, Gap: 0.0408\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8554, Val Acc: 0.8499, Val F1: 0.8540, Gap: 0.0055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8834, Val Acc: 0.8427, Val F1: 0.8490, Gap: 0.0407\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8992, Val Acc: 0.8557, Val F1: 0.8594, Gap: 0.0435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9098, Val Acc: 0.8560, Val F1: 0.8595, Gap: 0.0538\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9182, Val Acc: 0.8560, Val F1: 0.8607, Gap: 0.0622\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9258, Val Acc: 0.8590, Val F1: 0.8632, Gap: 0.0669\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9312, Val Acc: 0.8687, Val F1: 0.8723, Gap: 0.0625\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9366, Val Acc: 0.8635, Val F1: 0.8640, Gap: 0.0731\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9393, Val Acc: 0.8704, Val F1: 0.8732, Gap: 0.0690\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9435, Val Acc: 0.8650, Val F1: 0.8687, Gap: 0.0784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9455, Val Acc: 0.8610, Val F1: 0.8635, Gap: 0.0845\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9466, Val Acc: 0.8658, Val F1: 0.8693, Gap: 0.0809\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9491, Val Acc: 0.8637, Val F1: 0.8675, Gap: 0.0854\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▇█▇▇▇██▆▇█▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▇▇▅▅▇▇▆█▇▇▅▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>██▃▅▇▇▅▅▆▁▄▅▇▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▇▇▇▇██████▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▅▆▆▆▇▇▆▆▅▇█▆▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▇▇▆▆▆▇▇▇█▇▅▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▇▇▇█▇███▆█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▆▃█▇▇▇▆▇▆▇▇▁▅█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▆▃▄▅▅▆▆▇▆▅█▇▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▆▅█▇▆▆███▇█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▇▅▄▆▇▄▆▇▅▇▆▇█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▄▁▆▅▇▆▇▆▇█▇▆▇▅▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▆██▇▇███▇█▇█</td></tr><tr><td>Class_Positive_Precision</td><td>█▁▆▁▇▃▃▂▅▆▆▂▆▃▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇▆█▆████▇▇█▇█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▇▇▇▇▇▇███████</td></tr><tr><td>Validation F1</td><td>▁▃▇▇▇▇▇▇████▇██</td></tr><tr><td>Validation Loss</td><td>█▆▁▂▂▂▂▂▁▂▂▃▃▃▃</td></tr><tr><td>Validation Precision</td><td>▁▂▇▆▇▇▇▇███▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▇▇▇█▇██▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87094</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86161</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88047</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83734</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8311</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84367</td></tr><tr><td>Class_Negative_F1</td><td>0.88186</td></tr><tr><td>Class_Negative_Precision</td><td>0.95056</td></tr><tr><td>Class_Negative_Recall</td><td>0.82242</td></tr><tr><td>Class_Neutral_F1</td><td>0.85642</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82856</td></tr><tr><td>Class_Neutral_Recall</td><td>0.88621</td></tr><tr><td>Class_Positive_F1</td><td>0.89074</td></tr><tr><td>Class_Positive_Precision</td><td>0.89242</td></tr><tr><td>Class_Positive_Recall</td><td>0.88906</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94909</td></tr><tr><td>Train Loss</td><td>0.16316</td></tr><tr><td>Validation Accuracy</td><td>0.8637</td></tr><tr><td>Validation F1</td><td>0.86746</td></tr><tr><td>Validation Loss</td><td>0.48845</td></tr><tr><td>Validation Precision</td><td>0.87285</td></tr><tr><td>Validation Recall</td><td>0.86437</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_17</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/rp4fpazn' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/rp4fpazn</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_202434-rp4fpazn/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 21:14:47,221] Trial 17 finished with value: 0.8703838678328474 and parameters: {'learning_rate': 1.6120175957462052e-05, 'weight_decay': 5.188307099009166e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 37125 samples\n","Label distribution: [4385 7934 8170 9137 7499]\n","Class weights computed:\n","Extremely Negative (0): 1.693\n","Extremely Positive (1): 0.936\n","Negative (2): 0.909\n","Neutral (3): 0.813\n","Positive (4): 0.990\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_211449-4hq0zetp</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4hq0zetp' target=\"_blank\">trial_18</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4hq0zetp' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4hq0zetp</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5720, Val Acc: 0.6436, Val F1: 0.6534, Gap: -0.0716\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7191, Val Acc: 0.6992, Val F1: 0.7075, Gap: 0.0198\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7736, Val Acc: 0.7566, Val F1: 0.7646, Gap: 0.0171\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8063, Val Acc: 0.7810, Val F1: 0.7872, Gap: 0.0253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8330, Val Acc: 0.7917, Val F1: 0.7989, Gap: 0.0414\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8551, Val Acc: 0.7873, Val F1: 0.7937, Gap: 0.0678\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8703, Val Acc: 0.8271, Val F1: 0.8330, Gap: 0.0432\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8843, Val Acc: 0.8166, Val F1: 0.8224, Gap: 0.0677\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8957, Val Acc: 0.8120, Val F1: 0.8169, Gap: 0.0838\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9053, Val Acc: 0.8327, Val F1: 0.8377, Gap: 0.0726\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9144, Val Acc: 0.8438, Val F1: 0.8476, Gap: 0.0706\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9214, Val Acc: 0.8428, Val F1: 0.8462, Gap: 0.0786\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9294, Val Acc: 0.8373, Val F1: 0.8406, Gap: 0.0921\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9372, Val Acc: 0.8321, Val F1: 0.8359, Gap: 0.1051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9442, Val Acc: 0.8484, Val F1: 0.8515, Gap: 0.0958\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▅▅▇▅█▇▆████▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▄▄▆▄█▅▅▇▇▇▇▆█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▇▅▅▄█▁▇▇▅▅▄▄▆▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▅▆▆▅█▆▆▇██▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▅▆▆▅█▆▇████▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▅▅▇▅▇▆▆▇▇▇▇▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▅▆▆▇█▇████▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▅▆▇▇▇▇▇█▆▅▅▇▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▅▆▅▅▇▆▆▆███▆▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▅▆▆▇▆██▇▇▇███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▄▅▅▆▇▇▆▇██▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▆▅▇▇█▇▇█████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▄▅▄▆▅▇▅▆██▇▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▅▆█▇▇▅▇▇▆▅▇█▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▆▆▇▇▇▇███▇█</td></tr><tr><td>Validation F1</td><td>▁▃▅▆▆▆▇▇▇████▇█</td></tr><tr><td>Validation Loss</td><td>█▆▄▃▂▃▁▁▃▁▁▁▂▄▃</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▆▆▇▇▇▇██▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▆▆▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85059</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83925</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86223</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82291</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81982</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82602</td></tr><tr><td>Class_Negative_F1</td><td>0.86753</td></tr><tr><td>Class_Negative_Precision</td><td>0.89409</td></tr><tr><td>Class_Negative_Recall</td><td>0.84251</td></tr><tr><td>Class_Neutral_F1</td><td>0.84135</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8368</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84595</td></tr><tr><td>Class_Positive_F1</td><td>0.87523</td></tr><tr><td>Class_Positive_Precision</td><td>0.86905</td></tr><tr><td>Class_Positive_Recall</td><td>0.88151</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94422</td></tr><tr><td>Train Loss</td><td>0.17253</td></tr><tr><td>Validation Accuracy</td><td>0.8484</td></tr><tr><td>Validation F1</td><td>0.85152</td></tr><tr><td>Validation Loss</td><td>0.55376</td></tr><tr><td>Validation Precision</td><td>0.8518</td></tr><tr><td>Validation Recall</td><td>0.85164</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_18</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4hq0zetp' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/4hq0zetp</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_211449-4hq0zetp/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 22:05:00,643] Trial 18 finished with value: 0.8483965014577259 and parameters: {'learning_rate': 5.076455029343593e-06, 'weight_decay': 3.96730221550683e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_220503-a1c6b2tq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/a1c6b2tq' target=\"_blank\">trial_19</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/a1c6b2tq' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/a1c6b2tq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6660, Val Acc: 0.7801, Val F1: 0.7879, Gap: -0.1141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8158, Val Acc: 0.8307, Val F1: 0.8350, Gap: -0.0149\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8579, Val Acc: 0.8495, Val F1: 0.8525, Gap: 0.0084\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8864, Val Acc: 0.8397, Val F1: 0.8433, Gap: 0.0468\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9075, Val Acc: 0.8455, Val F1: 0.8498, Gap: 0.0620\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9207, Val Acc: 0.8548, Val F1: 0.8594, Gap: 0.0659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9319, Val Acc: 0.8543, Val F1: 0.8573, Gap: 0.0775\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9391, Val Acc: 0.8642, Val F1: 0.8674, Gap: 0.0749\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9473, Val Acc: 0.8631, Val F1: 0.8658, Gap: 0.0842\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9515, Val Acc: 0.8612, Val F1: 0.8639, Gap: 0.0903\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9552, Val Acc: 0.8637, Val F1: 0.8677, Gap: 0.0915\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9599, Val Acc: 0.8596, Val F1: 0.8628, Gap: 0.1003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9626, Val Acc: 0.8553, Val F1: 0.8585, Gap: 0.1073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9630, Val Acc: 0.8537, Val F1: 0.8571, Gap: 0.1093\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9678, Val Acc: 0.8596, Val F1: 0.8630, Gap: 0.1082\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▄▆█▆██████▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁██▁▄▇▃▇█▅▇▆▆▅█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▁▂█▇▅█▅▄▆▆▆▆▇▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▇▅▆█▆██▇█▇▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▃▅▄▆▆▆▇█▇██▆▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅█▃▅▆▄▆▆▄▅▄▃▅▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆▅▅▇█▆▆▇▅▄▆▅</td></tr><tr><td>Class_Negative_Precision</td><td>▄▆▇█▆█▅▇▄▄▇▅▁▅▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▂▃▁▆▅▆▆▄▄█▆▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▇▇▆▇▇███▇██▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▅▆█▄█▄▅▆▄▆▇▅▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇▇▆▄▇▅█▇▇█▇▆▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▇▇▇▇▆▇▇█▇▇▅▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇█▄▃▃▅▇▆▅▅▅▆█▆</td></tr><tr><td>Class_Positive_Recall</td><td>▃▂▂▇██▇▃▄▆▇▇▅▁▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▆▆▇▇█████▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▇▆▆▇▇█████▇▇█</td></tr><tr><td>Validation Loss</td><td>▆▃▁▃▃▂▃▂▄▄▄▆▇▆█</td></tr><tr><td>Validation Precision</td><td>▁▆█▅▆▇▆██▇█▇▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▇▇███████▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86817</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.87419</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86223</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8361</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80964</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.86435</td></tr><tr><td>Class_Negative_F1</td><td>0.87359</td></tr><tr><td>Class_Negative_Precision</td><td>0.89249</td></tr><tr><td>Class_Negative_Recall</td><td>0.85548</td></tr><tr><td>Class_Neutral_F1</td><td>0.85375</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85677</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85077</td></tr><tr><td>Class_Positive_F1</td><td>0.88319</td></tr><tr><td>Class_Positive_Precision</td><td>0.89658</td></tr><tr><td>Class_Positive_Recall</td><td>0.87019</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96781</td></tr><tr><td>Train Loss</td><td>0.1151</td></tr><tr><td>Validation Accuracy</td><td>0.85957</td></tr><tr><td>Validation F1</td><td>0.86296</td></tr><tr><td>Validation Loss</td><td>0.66617</td></tr><tr><td>Validation Precision</td><td>0.86593</td></tr><tr><td>Validation Recall</td><td>0.8606</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_19</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/a1c6b2tq' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3/runs/a1c6b2tq</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250804_220503-a1c6b2tq/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-04 22:55:12,222] Trial 19 finished with value: 0.8641885325558795 and parameters: {'learning_rate': 1.6483782188925505e-05, 'weight_decay': 2.4062536869093416e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 11 with value: 0.8724489795918368.\n"]},{"name":"stdout","output_type":"stream","text":["\n"," Best Results:\n","Validation Accuracy: 0.8724\n","Best hyperparameters:\n","  learning_rate: 4.964231176733226e-05\n","  weight_decay: 3.3543626906404976e-05\n","  patience: 7\n","  batch_size: 32\n","  num_layers: 0\n","  dropout_rate: 0.4\n","  gradient_clip_val: 0.5\n","  use_class_weights: False\n","\n","Best model saved: best_model_trial_11.pt\n"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 3:\")\n","study3 = optuna.create_study(direction=\"maximize\")\n","study3.optimize(objective, n_trials=20)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study3.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model3.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nFzFttjb25m3"},"source":["---\n","\n","### **Study 3 Summary – Augmented Training Results**\n","\n","Following the integration of class-specific augmented data, we achieved stable and improved overall performance:\n","\n","| **Metric**               | **Mean** | **Best Run** |\n","| ------------------------ | -------- | ------------ |\n","| **Validation F1**        | 85.68%   | **87.22%**   |\n","| **Validation Accuracy**  | 85.32%   | **86.89%**   |\n","| **Validation Precision** | 85.84%   | 87.89%       |\n","| **Validation Recall**    | 85.76%   | 87.27%       |\n","| **Overfitting Gap**      | 9.03%    | 12.49%       |\n","| **Validation Loss**      | 0.561    | —            |\n","\n","These results confirm a **strong and consistent improvement** over earlier studies, especially in terms of **Recall** and **F1 stability**, despite adding noisy synthetic data.\n","\n","---\n","\n","### **Per-Class Performance Check**\n","\n","| **Class**              | **F1 Score** | **Precision** | **Recall**  |\n","| ---------------------- | ------------ | ------------- | ----------- |\n","| **Extremely Positive** | **0.82**     | 0.85          | **0.80** 🔽 |\n","| **Neutral**            | **0.84**     | 0.86          | **0.81** 🔽 |\n","| Extremely Negative     | 0.86         | 0.82 🔽       | 0.90        |\n","| Negative               | 0.87         | 0.87          | 0.88        |\n","| Positive               | 0.87         | 0.84          | 0.91        |\n","\n","---\n","\n","### Conclusion\n","\n","* The **overall model improved** across all metrics.\n","* However, **Recall remains slightly lower** for the previously weak classes:\n","\n","  * **Neutral** (Recall = 0.81)\n","  * **Extremely Positive** (Recall = 0.80)\n","* This indicates that while **augmentation helped**, it **did not fully solve the recall gap**.\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"Q0qunVBZ4w-d"},"source":["### **Study 4 – Manual Class Weights for Recall Boost**\n","\n","> In this experiment, we apply **manual class weights** to directly address the **recall gap** observed in weaker classes (Neutral, Extremely Positive).\n","> This targeted adjustment allows us to amplify the loss contribution of underperforming labels without introducing new data noise or architectural changes.\n","\n","We set the weights based on the per-class F1 and recall analysis from Study 3:\n","\n","```python\n","manual_weights = torch.tensor([\n","    1.0,  # Extremely Negative – no recall issue\n","    1.0,  # Negative – balanced\n","    1.2,  # Neutral – low recall (0.81)\n","    1.0,  # Positive – high recall (0.91)\n","    1.3   # Extremely Positive – lowest recall (0.80)\n","], dtype=torch.float).to(device)\n","```\n","Manual weights are applied with moderate strength (1.2–1.3) to further improve recall on previously underperforming classes, without introducing bias or instability.\n","This configuration keeps the model architecture and training regime (Hyperparameters) identical to Study 3, isolating the effect of **loss reweighting**.\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bc164ee4d46644a1b3dbc295839cc5c7","8f657983937a40b38a03374ae927ae52","49aa6d67c3924651ada463cf952dbd2a","dd3b4596496c4439a72599a5040732fe","b15b00097c2a4230a04afe3f89dddd35","cabfe531a42342b29da1bdd34531c97b","fe0d00a5ce254f20aca70ed013baf782","092780a508194683830af1279095ff7c","7fa77fb5704f4e508d96ff6aded73f4c","cf697038d0e34a27bac98b6be9bd36a2","f18730ab599541bbbc9c2b62b92c3882","d52142340819447c95e7c14bac28e116","892f8b68d1bf488381a3b0dc95147a32","19370daece5c4826a61bd9042b2c4ab2","109363b6296b452982d78646bd17f7f4","544775c9c728446b84d412c1aa309b78","588b467cb0ee4275baa04b3fb4de0da1","ea0cf48df68c4aeeb497469ecac9db80","8e8dfa98cdad4f72a5b98d761fa9e7a2","648f8170f41f43f58b4e7da88d4970d8","791cc64adb534880b67734d732f0d471","fe58d4cdfb8b4d2f94bdad4cc99fc110","8696082903eb488cb8d7f9f01618183d","90a8de76d56043c2a484a371ee9125ad","67366159964541148d94ae24b0b3c4d4","75bfbc56ce794f7f84e8e3ac0ed9e257","03a767631ae846fa8e20af9d9b9ac6bd","6c0e421be8b3418c8904f3db2c6d1aef","84507535a8274756bd1ce86eca45f9aa","84c6f8d7aa034c6da5664b106b441a6b","9854c0f9ee6b493799795a009ce47d44","74e6dc2bd47d49f0b63f374b77187e98","c2bb406eeef54c22a9d428c85d444c6f","31243a99909b4863827c6444f8c01666","3bf0923fc37f4578bcce249c7dd5674a","58e2dddda9b141d78cfba42d0c6a4064","77670cb4c59e4a38b19a55a5168bbc69","67936f439d8e43aa89240cf5af1e7b9a","6543cc2a33334618a555b235020b3761","d02430754b884da69c9917e3eda428ab","a481a32941a4417d812aec82e110d4e3","f8854d44b6444c11919eb6e38821cb7a","2f31616899994b32a74683ad8c2d21f2","9e65aa16b1494f1e82d70993b0f5d3f2","f2ea1e3adda84b9caaddb06c9b74679f","ae62a159c71b4bc88ffd98e88f2f39fe","e94ae55261ba48eab7af2aa18802e084","bf506cbae7a24f67b4a926b016d75438","9df2883543dc455da9572e7f3bf31992","bbb53446b54448c2a5203940f4a88706","f1cf1504e2fc47abb93039192ac9fe7b","303b2446c0674b1b99a35240c3f83483","9452caa3cff943c4a702dadb7ed32e5c","823c657b1d6b4854beef959796b2cb95","692d90f342cd4b119395b69ef5950698","b117c854525c4707b26cc36bb434b862","5bb25d0c047d4e77b18ff7397cfffd40","349610bc77e248e0bfb3f8a9a4d7509e","a28ed6546f3b4f729a9acd134e4d110c","862c1c6aad5f488e80b18982f2b3b5fa","b1cabdf2befd4180986a68c3cd278deb","dce87bf63bb3422fb308e05ffac3190d","3a9589ca4b1e4fc9bac5cb706fd3833f","f8acd37462834e9c8459e9d433c55b0d","7e0f94c87a92477181b4c80144421cf3","68752be6a8f94661b0442a7561488549"]},"id":"2PDP9dXjvoMZ","outputId":"5e235b5b-dce1-47f4-fb56-6fdb4f0da69c"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 06:34:10,142] A new study created in memory with name: no-name-8fcbfe29-5525-4ccb-997c-c0b514f5fde4\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 4:\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc164ee4d46644a1b3dbc295839cc5c7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d52142340819447c95e7c14bac28e116","version_major":2,"version_minor":0},"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8696082903eb488cb8d7f9f01618183d","version_major":2,"version_minor":0},"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31243a99909b4863827c6444f8c01666","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2ea1e3adda84b9caaddb06c9b74679f","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b117c854525c4707b26cc36bb434b862","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_063416-hvez3lt1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hvez3lt1' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hvez3lt1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hvez3lt1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5835, Val Acc: 0.6532, Val F1: 0.6654, Gap: -0.0697\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7224, Val Acc: 0.7385, Val F1: 0.7473, Gap: -0.0160\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7775, Val Acc: 0.7720, Val F1: 0.7800, Gap: 0.0055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8133, Val Acc: 0.7971, Val F1: 0.8037, Gap: 0.0162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8378, Val Acc: 0.8059, Val F1: 0.8125, Gap: 0.0319\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8556, Val Acc: 0.8003, Val F1: 0.8063, Gap: 0.0554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8729, Val Acc: 0.8213, Val F1: 0.8270, Gap: 0.0516\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8861, Val Acc: 0.8211, Val F1: 0.8249, Gap: 0.0651\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8954, Val Acc: 0.8337, Val F1: 0.8385, Gap: 0.0617\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9066, Val Acc: 0.8406, Val F1: 0.8451, Gap: 0.0660\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9163, Val Acc: 0.8318, Val F1: 0.8361, Gap: 0.0845\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9240, Val Acc: 0.8387, Val F1: 0.8429, Gap: 0.0853\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9318, Val Acc: 0.8495, Val F1: 0.8524, Gap: 0.0823\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9373, Val Acc: 0.8445, Val F1: 0.8484, Gap: 0.0928\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9433, Val Acc: 0.8525, Val F1: 0.8560, Gap: 0.0908\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▆▆▆▇▆▇█▇█▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▄▅▅▅▆▄▆▇▅▇▆█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▁▄▄▅▅▆█▆▃▇▅▆▁▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▅▆▆▆▇▆▇█▇████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅▆▆▇▇▇▇█▇██▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▅▆▆▅▅▅▇▇▆▇▇█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆▇▇▇██████▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▂▆▇▆▇▇█▅▇▅▇▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▇▅▆▇▇▇▇█▇█▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▆▅▇▇▇▇▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▆▆▇▇▆██▇███▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▄▆▅▅▇▇▇▇▇▆███</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▆▆▅▇▇▇▇█▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▅▅▅▁▅▆▆▅▇▅█▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▄▆▆█▇▆▆▇▆▇▆▆▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▆▆▇▇▇█▇████</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▆▆▇▇▇█▇████</td></tr><tr><td>Validation Loss</td><td>█▅▃▂▂▂▁▂▁▁▂▂▁▂▂</td></tr><tr><td>Validation Precision</td><td>▁▄▅▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8603</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83448</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88777</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8235</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83068</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81644</td></tr><tr><td>Class_Negative_F1</td><td>0.87397</td></tr><tr><td>Class_Negative_Precision</td><td>0.89257</td></tr><tr><td>Class_Negative_Recall</td><td>0.85612</td></tr><tr><td>Class_Neutral_F1</td><td>0.84694</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82783</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86696</td></tr><tr><td>Class_Positive_F1</td><td>0.87505</td></tr><tr><td>Class_Positive_Precision</td><td>0.90354</td></tr><tr><td>Class_Positive_Recall</td><td>0.8483</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94333</td></tr><tr><td>Train Loss</td><td>0.17616</td></tr><tr><td>Validation Accuracy</td><td>0.85253</td></tr><tr><td>Validation F1</td><td>0.85595</td></tr><tr><td>Validation Loss</td><td>0.53616</td></tr><tr><td>Validation Precision</td><td>0.85782</td></tr><tr><td>Validation Recall</td><td>0.85512</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hvez3lt1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hvez3lt1</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_063416-hvez3lt1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 07:23:30,022] Trial 0 finished with value: 0.8525267249757046 and parameters: {'learning_rate': 4.926164104140307e-06, 'weight_decay': 3.980640836223991e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 0 with value: 0.8525267249757046.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_072331-bjtj68xy</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/bjtj68xy' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/bjtj68xy' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/bjtj68xy</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6915, Val Acc: 0.7906, Val F1: 0.7974, Gap: -0.0990\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8282, Val Acc: 0.8418, Val F1: 0.8462, Gap: -0.0137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8654, Val Acc: 0.8585, Val F1: 0.8619, Gap: 0.0069\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8841, Val Acc: 0.8587, Val F1: 0.8621, Gap: 0.0254\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8959, Val Acc: 0.8581, Val F1: 0.8622, Gap: 0.0378\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9045, Val Acc: 0.8596, Val F1: 0.8644, Gap: 0.0449\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9078, Val Acc: 0.8543, Val F1: 0.8574, Gap: 0.0534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9132, Val Acc: 0.8474, Val F1: 0.8507, Gap: 0.0658\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9170, Val Acc: 0.8539, Val F1: 0.8583, Gap: 0.0632\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9209, Val Acc: 0.8676, Val F1: 0.8708, Gap: 0.0533\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9218, Val Acc: 0.8733, Val F1: 0.8759, Gap: 0.0485\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9243, Val Acc: 0.8513, Val F1: 0.8552, Gap: 0.0730\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9264, Val Acc: 0.8366, Val F1: 0.8425, Gap: 0.0898\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9298, Val Acc: 0.8641, Val F1: 0.8682, Gap: 0.0658\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9313, Val Acc: 0.8599, Val F1: 0.8630, Gap: 0.0714\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▆██▆▄█▇█▇██▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▇▇▄▆▆▇▂█▇▇▄▇▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▁▂▇▆▆▂█▃▄▄▇▄▆▃</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▇▆▇▇▇▅█▇█▆▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▇▇▆▄▇▆▅▇▇██▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁██▅▇▆▇▃███▅▆▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇▇▄▇█▇█▆▅▇▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄▃▆█▄▇▃█▆▇▇▇▂▆▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▅▅▇▅▅▅▇▅▇▅▆▅█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▇▇▆▆▇▆▄██▆▃▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▃▆█▅▅▆▇▅▄▆▄▅▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▇▅▃▅▅▄▂▇█▄▁▆▄</td></tr><tr><td>Class_Positive_F1</td><td>▂▄▇█▆▇▇▇▃█▇▆▁█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▃▇▇▅▃▅▆▄▂▇█▃▁▅▅</td></tr><tr><td>Class_Positive_Recall</td><td>▄▁▃▆▇▆▅▆█▄▂▇█▆▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇▇▇▆▆▆██▆▅▇▇</td></tr><tr><td>Validation F1</td><td>▁▅▇▇▇▇▆▆▆██▆▅▇▇</td></tr><tr><td>Validation Loss</td><td>█▃▁▁▂▂▂▅▄▁▂▄▆▃▃</td></tr><tr><td>Validation Precision</td><td>▁▆▇▆▆▆▆▅▆▇█▅▄▆▆</td></tr><tr><td>Validation Recall</td><td>▁▄▆███▆▇▇▇█▇▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86784</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.87921</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.85675</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83741</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84647</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82854</td></tr><tr><td>Class_Negative_F1</td><td>0.87974</td></tr><tr><td>Class_Negative_Precision</td><td>0.87301</td></tr><tr><td>Class_Negative_Recall</td><td>0.88658</td></tr><tr><td>Class_Neutral_F1</td><td>0.84901</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86302</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83545</td></tr><tr><td>Class_Positive_F1</td><td>0.88118</td></tr><tr><td>Class_Positive_Precision</td><td>0.84488</td></tr><tr><td>Class_Positive_Recall</td><td>0.92075</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.93131</td></tr><tr><td>Train Loss</td><td>0.21188</td></tr><tr><td>Validation Accuracy</td><td>0.85994</td></tr><tr><td>Validation F1</td><td>0.86304</td></tr><tr><td>Validation Loss</td><td>0.44045</td></tr><tr><td>Validation Precision</td><td>0.86132</td></tr><tr><td>Validation Recall</td><td>0.86562</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/bjtj68xy' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/bjtj68xy</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_072331-bjtj68xy/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 08:12:45,624] Trial 1 finished with value: 0.8732993197278912 and parameters: {'learning_rate': 2.414445129773896e-05, 'weight_decay': 6.987293068479827e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-589794400.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(manual_weights, dtype=torch.float)\n"]},{"name":"stdout","output_type":"stream","text":["Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_081246-i7tznbu2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/i7tznbu2' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/i7tznbu2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/i7tznbu2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6262, Val Acc: 0.7127, Val F1: 0.7234, Gap: -0.0866\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7731, Val Acc: 0.7976, Val F1: 0.8037, Gap: -0.0245\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8270, Val Acc: 0.7641, Val F1: 0.7707, Gap: 0.0630\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8578, Val Acc: 0.8150, Val F1: 0.8193, Gap: 0.0428\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8802, Val Acc: 0.8422, Val F1: 0.8470, Gap: 0.0380\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9002, Val Acc: 0.8342, Val F1: 0.8394, Gap: 0.0660\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9133, Val Acc: 0.8452, Val F1: 0.8489, Gap: 0.0681\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9255, Val Acc: 0.8364, Val F1: 0.8399, Gap: 0.0892\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9368, Val Acc: 0.8439, Val F1: 0.8478, Gap: 0.0929\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9442, Val Acc: 0.8370, Val F1: 0.8403, Gap: 0.1072\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9499, Val Acc: 0.8360, Val F1: 0.8403, Gap: 0.1139\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9575, Val Acc: 0.8491, Val F1: 0.8521, Gap: 0.1083\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9623, Val Acc: 0.8542, Val F1: 0.8578, Gap: 0.1080\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9663, Val Acc: 0.8446, Val F1: 0.8482, Gap: 0.1217\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9685, Val Acc: 0.8457, Val F1: 0.8496, Gap: 0.1228\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▃▅▇█▇▆█▇█████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▂▄▆▇▅▄▆▅█▇▇▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▁▇▇▆▅▇█▇▇▂▄▆▅▃</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▄▆▇▇▇▆▇▇█████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▆▆▇▇▇▇▇█▇██▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▂▄▇▇▇▆▇▆█████</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆▇▇██▆▇▅▇█▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▇▇▇█▇█▄▄▆▄█▄▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▃▅▄▅▄▇▇▃█▅▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▂▇▇▆███▇▇███▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▆▆▆▇▇▇█▆▇▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▁▆█▆██▇▆▇██▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▂▆▇▆█▇▇▇▇▇█▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▇▇▁▅▇▅▇▇█▆▅█▇▇▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▅█▇▆▇▆▆▅▇█▅▇▆▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▄▆▇▇█▇▇▇▇████</td></tr><tr><td>Validation F1</td><td>▁▅▃▆▇▇█▇▇▇▇██▇█</td></tr><tr><td>Validation Loss</td><td>█▃▅▃▁▂▂▃▃▄▅▄▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▃▆▇▇▇▇▇▇▇██▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▄▆▇▇█▇▇█▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85701</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86096</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8531</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83068</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83384</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82753</td></tr><tr><td>Class_Negative_F1</td><td>0.8753</td></tr><tr><td>Class_Negative_Precision</td><td>0.91455</td></tr><tr><td>Class_Negative_Recall</td><td>0.83927</td></tr><tr><td>Class_Neutral_F1</td><td>0.82588</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82769</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82407</td></tr><tr><td>Class_Positive_F1</td><td>0.85917</td></tr><tr><td>Class_Positive_Precision</td><td>0.81237</td></tr><tr><td>Class_Positive_Recall</td><td>0.9117</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96854</td></tr><tr><td>Train Loss</td><td>0.10519</td></tr><tr><td>Validation Accuracy</td><td>0.84572</td></tr><tr><td>Validation F1</td><td>0.84961</td></tr><tr><td>Validation Loss</td><td>0.74499</td></tr><tr><td>Validation Precision</td><td>0.84988</td></tr><tr><td>Validation Recall</td><td>0.85114</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/i7tznbu2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/i7tznbu2</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_081246-i7tznbu2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 09:02:03,270] Trial 2 finished with value: 0.8542274052478134 and parameters: {'learning_rate': 9.029004576874207e-06, 'weight_decay': 3.2771076039674638e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_090204-de9jjjs7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/de9jjjs7' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/de9jjjs7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/de9jjjs7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6557, Val Acc: 0.7671, Val F1: 0.7743, Gap: -0.1114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7979, Val Acc: 0.8198, Val F1: 0.8258, Gap: -0.0220\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8499, Val Acc: 0.8053, Val F1: 0.8108, Gap: 0.0446\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8796, Val Acc: 0.8367, Val F1: 0.8422, Gap: 0.0429\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8987, Val Acc: 0.8450, Val F1: 0.8501, Gap: 0.0538\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9152, Val Acc: 0.8490, Val F1: 0.8535, Gap: 0.0662\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9274, Val Acc: 0.8570, Val F1: 0.8604, Gap: 0.0703\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9358, Val Acc: 0.8456, Val F1: 0.8493, Gap: 0.0902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9428, Val Acc: 0.8531, Val F1: 0.8569, Gap: 0.0897\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9496, Val Acc: 0.8431, Val F1: 0.8481, Gap: 0.1066\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9543, Val Acc: 0.8559, Val F1: 0.8590, Gap: 0.0983\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9576, Val Acc: 0.8539, Val F1: 0.8570, Gap: 0.1038\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9628, Val Acc: 0.8489, Val F1: 0.8523, Gap: 0.1139\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9626, Val Acc: 0.8582, Val F1: 0.8610, Gap: 0.1044\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9676, Val Acc: 0.8507, Val F1: 0.8550, Gap: 0.1169\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▃▇▇▇▇▆█▇█▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▇▇▁▆▇▇▇▄▇█▇▇▇▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▄█▇▆▆▆█▇▆▆▇▇▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▂▇█▇█▇██▇█▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▃▇▇▆▇▆▇▇█▇█▆▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▁▄▅▆▆▅▅▆▄▆▃▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▄▇█▇██▇▇▆▇▆▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄██▇█▇▇▄█▂▄▃▃▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▄▁▄▆▄▆▅█▄▇▇▇▇▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▄▅▅▇▇▇▇▆█▇▇█▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▆▆▆▆▆▇█▆▇▇▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▄▅▁▄▄▆█▅▄▅▇▅▆▇▃</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▅▆▆▇▇▇▇▆█▇▇█▆</td></tr><tr><td>Class_Positive_Precision</td><td>▆█▁▁▁▅▆▄▃▂▆▅▃▇▂</td></tr><tr><td>Class_Positive_Recall</td><td>▁▃▇██▇▆▇██▇▇█▆█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▄▆▇▇█▇█▇██▇█▇</td></tr><tr><td>Validation F1</td><td>▁▅▄▆▇▇█▇█▇██▇██</td></tr><tr><td>Validation Loss</td><td>▅▂▃▂▁▁▂▃▂▄▅▅▇▄█</td></tr><tr><td>Validation Precision</td><td>▁▅▃▆▇▇█▆▇▇▇▇▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▅▅▇▇▇█▇█▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86796</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83844</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89964</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83151</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8197</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84367</td></tr><tr><td>Class_Negative_F1</td><td>0.88187</td></tr><tr><td>Class_Negative_Precision</td><td>0.92587</td></tr><tr><td>Class_Negative_Recall</td><td>0.84187</td></tr><tr><td>Class_Neutral_F1</td><td>0.83007</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86556</td></tr><tr><td>Class_Neutral_Recall</td><td>0.79737</td></tr><tr><td>Class_Positive_F1</td><td>0.8637</td></tr><tr><td>Class_Positive_Precision</td><td>0.81155</td></tr><tr><td>Class_Positive_Recall</td><td>0.92302</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96757</td></tr><tr><td>Train Loss</td><td>0.11497</td></tr><tr><td>Validation Accuracy</td><td>0.8507</td></tr><tr><td>Validation F1</td><td>0.85502</td></tr><tr><td>Validation Loss</td><td>0.7447</td></tr><tr><td>Validation Precision</td><td>0.85222</td></tr><tr><td>Validation Recall</td><td>0.86111</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/de9jjjs7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/de9jjjs7</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_090204-de9jjjs7/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 09:51:20,682] Trial 3 finished with value: 0.8582361516034985 and parameters: {'learning_rate': 1.2367807195283e-05, 'weight_decay': 2.217858105772343e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_095121-xxq1lyg8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/xxq1lyg8' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/xxq1lyg8' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/xxq1lyg8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6868, Val Acc: 0.7686, Val F1: 0.7769, Gap: -0.0818\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8272, Val Acc: 0.8282, Val F1: 0.8340, Gap: -0.0010\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8687, Val Acc: 0.8376, Val F1: 0.8430, Gap: 0.0311\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8983, Val Acc: 0.8477, Val F1: 0.8527, Gap: 0.0506\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9182, Val Acc: 0.8461, Val F1: 0.8505, Gap: 0.0722\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9332, Val Acc: 0.8625, Val F1: 0.8663, Gap: 0.0707\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9435, Val Acc: 0.8578, Val F1: 0.8613, Gap: 0.0858\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9523, Val Acc: 0.8518, Val F1: 0.8560, Gap: 0.1005\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9566, Val Acc: 0.8592, Val F1: 0.8612, Gap: 0.0973\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9607, Val Acc: 0.8501, Val F1: 0.8534, Gap: 0.1106\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9668, Val Acc: 0.8422, Val F1: 0.8463, Gap: 0.1246\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9688, Val Acc: 0.8415, Val F1: 0.8443, Gap: 0.1274\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9726, Val Acc: 0.8432, Val F1: 0.8486, Gap: 0.1294\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9747, Val Acc: 0.8520, Val F1: 0.8542, Gap: 0.1227\n","Early stopping at epoch 14\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆█▇█▇▇▇▆▆▆█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▇▄▇▆▇█▅▆▆▄▅▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▁█▅▆▄▂█▅▄█▇▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▅▇▇██▇█▇▆▆██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▄▆▆▇▆▆▇▇▅██▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▅▇▆▇█▇▇▇▅▂▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆▅▆█▇▇▆▇▅▅█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄▆▆██▆▄▆▃▄▆▁▆▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▄▃▄▇▇▆▇▇▄█▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▆▆▇▇▇█▆▇▇▄▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▆▁▇▇▇▇▆█▇▆▆▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▅█▄▅▅▅▇▄▅▅▃▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▇▅▇▇▇▇▇▆█▇▃▄</td></tr><tr><td>Class_Positive_Precision</td><td>▄▂▆▇▃▄▅▅▇▄▅▅▁█</td></tr><tr><td>Class_Positive_Recall</td><td>▂▇▅▂▇▇▆▅▄▇▆▆█▁</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇██▇█▇▆▆▇▇</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▇██▇█▇▆▆▇▇</td></tr><tr><td>Validation Loss</td><td>▄▂▂▁▂▂▂▄▃▅▅▇█▇</td></tr><tr><td>Validation Precision</td><td>▁▅▆█▆██▇█▆▆▆▆█</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆▇█▇▇▇▇▇▇▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86649</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85123</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8823</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83571</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.843</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82854</td></tr><tr><td>Class_Negative_F1</td><td>0.88023</td></tr><tr><td>Class_Negative_Precision</td><td>0.86776</td></tr><tr><td>Class_Negative_Recall</td><td>0.89307</td></tr><tr><td>Class_Neutral_F1</td><td>0.84413</td></tr><tr><td>Class_Neutral_Precision</td><td>0.80768</td></tr><tr><td>Class_Neutral_Recall</td><td>0.88403</td></tr><tr><td>Class_Positive_F1</td><td>0.84431</td></tr><tr><td>Class_Positive_Precision</td><td>0.95085</td></tr><tr><td>Class_Positive_Recall</td><td>0.75925</td></tr><tr><td>Epoch</td><td>14</td></tr><tr><td>Train Accuracy</td><td>0.97473</td></tr><tr><td>Train Loss</td><td>0.09877</td></tr><tr><td>Validation Accuracy</td><td>0.85204</td></tr><tr><td>Validation F1</td><td>0.85417</td></tr><tr><td>Validation Loss</td><td>0.77279</td></tr><tr><td>Validation Precision</td><td>0.8641</td></tr><tr><td>Validation Recall</td><td>0.84944</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/xxq1lyg8' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/xxq1lyg8</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_095121-xxq1lyg8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 10:37:22,705] Trial 4 finished with value: 0.8624878522837707 and parameters: {'learning_rate': 2.0591336048360847e-05, 'weight_decay': 9.898935662511675e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_103723-wryqcs5r</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/wryqcs5r' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/wryqcs5r' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/wryqcs5r</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5249, Val Acc: 0.5988, Val F1: 0.6133, Gap: -0.0739\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6637, Val Acc: 0.6900, Val F1: 0.7017, Gap: -0.0263\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7204, Val Acc: 0.7212, Val F1: 0.7328, Gap: -0.0008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7598, Val Acc: 0.7496, Val F1: 0.7575, Gap: 0.0101\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7857, Val Acc: 0.7789, Val F1: 0.7870, Gap: 0.0068\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8061, Val Acc: 0.7958, Val F1: 0.8028, Gap: 0.0103\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8202, Val Acc: 0.8065, Val F1: 0.8133, Gap: 0.0137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8366, Val Acc: 0.8132, Val F1: 0.8186, Gap: 0.0234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8483, Val Acc: 0.8203, Val F1: 0.8263, Gap: 0.0279\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8598, Val Acc: 0.8292, Val F1: 0.8343, Gap: 0.0306\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8681, Val Acc: 0.8128, Val F1: 0.8175, Gap: 0.0553\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8731, Val Acc: 0.8388, Val F1: 0.8437, Gap: 0.0343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8816, Val Acc: 0.8269, Val F1: 0.8318, Gap: 0.0547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8890, Val Acc: 0.8285, Val F1: 0.8341, Gap: 0.0605\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8931, Val Acc: 0.8420, Val F1: 0.8463, Gap: 0.0511\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▄▆▆▇▇▇▇▆█▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▆▂▅▆▇▆▇▆▄▇▅█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▂▁▇▅▅▅▆▆▇█▇▇▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▄▆▇▇▇▇▇▆█▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▄▅▅▆▆▇▇▆▇▆▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▅▄▆▇▇▇▇▇▆█▇█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▆▇▇▇▇████▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▆▆▆▇▇▇▇▇█▇███</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▃▆▇▆▇▇▇▇▇██▇▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▇▇▇▇▇████▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▄▆▆▇▇▇▇██████</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▅▆▆▇▇█▇█▇██▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▆▆▆▇▇▇████▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▃▇▇▇▇▇▆▇▇▇█▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▅▁▆▃▃▄▆▅▇▆▆▆▅█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▅▆▇▇▇▇█▇████</td></tr><tr><td>Validation F1</td><td>▁▄▅▅▆▇▇▇▇█▇████</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▂▂▂▂▁▂▁▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▄▅▅▆▇▇▇▇█▇████</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▆▆▇▇▇█▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84606</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.7794</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92518</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80252</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83607</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77156</td></tr><tr><td>Class_Negative_F1</td><td>0.87029</td></tr><tr><td>Class_Negative_Precision</td><td>0.93323</td></tr><tr><td>Class_Negative_Recall</td><td>0.81529</td></tr><tr><td>Class_Neutral_F1</td><td>0.83266</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8137</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85252</td></tr><tr><td>Class_Positive_F1</td><td>0.88003</td></tr><tr><td>Class_Positive_Precision</td><td>0.86902</td></tr><tr><td>Class_Positive_Recall</td><td>0.89132</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.89306</td></tr><tr><td>Train Loss</td><td>0.32105</td></tr><tr><td>Validation Accuracy</td><td>0.84196</td></tr><tr><td>Validation F1</td><td>0.84631</td></tr><tr><td>Validation Loss</td><td>0.48004</td></tr><tr><td>Validation Precision</td><td>0.84628</td></tr><tr><td>Validation Recall</td><td>0.85117</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/wryqcs5r' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/wryqcs5r</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_103723-wryqcs5r/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 11:26:42,074] Trial 5 finished with value: 0.841958211856171 and parameters: {'learning_rate': 2.769511891109534e-06, 'weight_decay': 7.047858887263742e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-589794400.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(manual_weights, dtype=torch.float)\n"]},{"name":"stdout","output_type":"stream","text":["Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_112643-v1f7ez99</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/v1f7ez99' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/v1f7ez99' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/v1f7ez99</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6247, Val Acc: 0.6996, Val F1: 0.7130, Gap: -0.0749\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7649, Val Acc: 0.7749, Val F1: 0.7838, Gap: -0.0100\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8215, Val Acc: 0.7847, Val F1: 0.7918, Gap: 0.0368\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8539, Val Acc: 0.8315, Val F1: 0.8370, Gap: 0.0224\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8787, Val Acc: 0.8400, Val F1: 0.8456, Gap: 0.0387\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8971, Val Acc: 0.8321, Val F1: 0.8369, Gap: 0.0649\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9116, Val Acc: 0.8451, Val F1: 0.8495, Gap: 0.0665\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9259, Val Acc: 0.8473, Val F1: 0.8515, Gap: 0.0786\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9346, Val Acc: 0.8432, Val F1: 0.8466, Gap: 0.0915\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9432, Val Acc: 0.8444, Val F1: 0.8482, Gap: 0.0988\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9477, Val Acc: 0.8435, Val F1: 0.8475, Gap: 0.1042\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9560, Val Acc: 0.8443, Val F1: 0.8485, Gap: 0.1117\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9610, Val Acc: 0.8507, Val F1: 0.8543, Gap: 0.1103\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9646, Val Acc: 0.8348, Val F1: 0.8374, Gap: 0.1298\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9689, Val Acc: 0.8457, Val F1: 0.8474, Gap: 0.1232\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▅▇█▇███████▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▇▃▇▇▅▆▆▆▆▅▅▆▅█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▁▇▄▅██▇▆▇██▇▇▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▅▇▇▇███████▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▆▇▇▇█████▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▂█▆▆▇▇▇▇▆▇▇▅█</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇█████▇▇██▆▆</td></tr><tr><td>Class_Negative_Precision</td><td>▃▄▇▇██▇▇▅▆▅▆▆▁▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▅▆▆▆▇▇▇▆▇▇▇██</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▇▇▇▇▇▇█▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▂▄▃▆▆▆▇▆▆▇▆█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▆█▆▆▇▆▇▇▆▇▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▄▇▇▆▇▇▇▇█▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▄▁▃▆█▄▅▆▅▆▆▆█▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁██▇▅█████▇▇▆█▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▇█▇███████▇█</td></tr><tr><td>Validation F1</td><td>▁▅▅▇█▇███████▇█</td></tr><tr><td>Validation Loss</td><td>█▄▄▁▁▂▁▂▃▃▃▅▅█▇</td></tr><tr><td>Validation Precision</td><td>▁▄▅▇█▇██▇█▇▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▅▇▇▇████████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8375</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.88516</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.79471</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82178</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82157</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82199</td></tr><tr><td>Class_Negative_F1</td><td>0.85372</td></tr><tr><td>Class_Negative_Precision</td><td>0.83118</td></tr><tr><td>Class_Negative_Recall</td><td>0.87751</td></tr><tr><td>Class_Neutral_F1</td><td>0.84526</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84545</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84508</td></tr><tr><td>Class_Positive_F1</td><td>0.87892</td></tr><tr><td>Class_Positive_Precision</td><td>0.87047</td></tr><tr><td>Class_Positive_Recall</td><td>0.88755</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.96894</td></tr><tr><td>Train Loss</td><td>0.10714</td></tr><tr><td>Validation Accuracy</td><td>0.84572</td></tr><tr><td>Validation F1</td><td>0.84744</td></tr><tr><td>Validation Loss</td><td>0.71264</td></tr><tr><td>Validation Precision</td><td>0.85077</td></tr><tr><td>Validation Recall</td><td>0.84537</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/v1f7ez99' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/v1f7ez99</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_112643-v1f7ez99/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 12:16:05,248] Trial 6 finished with value: 0.8507045675413022 and parameters: {'learning_rate': 8.490249599975144e-06, 'weight_decay': 4.459799941295417e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-589794400.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(manual_weights, dtype=torch.float)\n"]},{"name":"stdout","output_type":"stream","text":["Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_121606-6q4enlzo</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/6q4enlzo' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/6q4enlzo' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/6q4enlzo</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6823, Val Acc: 0.7219, Val F1: 0.7310, Gap: -0.0396\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8216, Val Acc: 0.8421, Val F1: 0.8462, Gap: -0.0205\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8706, Val Acc: 0.8429, Val F1: 0.8482, Gap: 0.0277\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.9017, Val Acc: 0.8511, Val F1: 0.8542, Gap: 0.0507\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9192, Val Acc: 0.8494, Val F1: 0.8538, Gap: 0.0699\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9363, Val Acc: 0.8435, Val F1: 0.8461, Gap: 0.0927\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9497, Val Acc: 0.8344, Val F1: 0.8393, Gap: 0.1152\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9561, Val Acc: 0.8568, Val F1: 0.8606, Gap: 0.0993\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9632, Val Acc: 0.8492, Val F1: 0.8527, Gap: 0.1140\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9693, Val Acc: 0.8378, Val F1: 0.8420, Gap: 0.1314\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9729, Val Acc: 0.8547, Val F1: 0.8583, Gap: 0.1182\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9769, Val Acc: 0.8513, Val F1: 0.8541, Gap: 0.1256\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9792, Val Acc: 0.8518, Val F1: 0.8554, Gap: 0.1274\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9805, Val Acc: 0.8548, Val F1: 0.8584, Gap: 0.1257\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9819, Val Acc: 0.8557, Val F1: 0.8595, Gap: 0.1262\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▇▆█▆▇██▆█▇▇▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁█▆█▇▄▅▇▆▄▇█▇▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▁▅▁▅█▇▅▆█▆▄▄▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▇▇██▆▇██▆████▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▂▁▇▄▄█▆▅█▅▇▇▆█▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁█▆▇▇▅▆▇▆▆▇▇▇▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇▇▅▅▂▆▄▆▄▆▆▆█</td></tr><tr><td>Class_Negative_Precision</td><td>▅▇▇▇▆▃▆▆▁▄▁▅▆▄█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▅▆▅█▁▆█▇█▆▆▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▇▇█▇█▇██▇█████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▅▅██▆▆▆█▇▄█▆▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▆▇▆▆▆▇▇▅▇█▆▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁█▇█▇█▇██▇█▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▆▇▆▇▆▇▇▆▇█▆▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>█▄▅▃▆▆▆▄▃▆▄▁▇▄▄</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▇▇██▇▇██▇█████</td></tr><tr><td>Validation F1</td><td>▁▇▇██▇▇██▇█████</td></tr><tr><td>Validation Loss</td><td>▆▁▁▁▁▃▃▄▅▆▆█▇▇█</td></tr><tr><td>Validation Precision</td><td>▁▇▇█▇▇▆█▇▆▇█▇██</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇██▇█▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8613</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81129</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91788</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82311</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82374</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82249</td></tr><tr><td>Class_Negative_F1</td><td>0.89611</td></tr><tr><td>Class_Negative_Precision</td><td>0.93768</td></tr><tr><td>Class_Negative_Recall</td><td>0.85807</td></tr><tr><td>Class_Neutral_F1</td><td>0.84634</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84541</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84726</td></tr><tr><td>Class_Positive_F1</td><td>0.87059</td></tr><tr><td>Class_Positive_Precision</td><td>0.87557</td></tr><tr><td>Class_Positive_Recall</td><td>0.86566</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.9819</td></tr><tr><td>Train Loss</td><td>0.06868</td></tr><tr><td>Validation Accuracy</td><td>0.85569</td></tr><tr><td>Validation F1</td><td>0.85949</td></tr><tr><td>Validation Loss</td><td>0.81749</td></tr><tr><td>Validation Precision</td><td>0.85874</td></tr><tr><td>Validation Recall</td><td>0.86227</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/6q4enlzo' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/6q4enlzo</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_121606-6q4enlzo/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 13:05:28,334] Trial 7 finished with value: 0.8567784256559767 and parameters: {'learning_rate': 2.0729274320192885e-05, 'weight_decay': 2.716340686263955e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-589794400.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(manual_weights, dtype=torch.float)\n"]},{"name":"stdout","output_type":"stream","text":["Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_130529-97wtvidr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/97wtvidr' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/97wtvidr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/97wtvidr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5874, Val Acc: 0.6714, Val F1: 0.6834, Gap: -0.0840\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7301, Val Acc: 0.7218, Val F1: 0.7297, Gap: 0.0083\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7835, Val Acc: 0.7802, Val F1: 0.7878, Gap: 0.0032\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8211, Val Acc: 0.8106, Val F1: 0.8167, Gap: 0.0105\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8447, Val Acc: 0.8174, Val F1: 0.8236, Gap: 0.0272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8622, Val Acc: 0.7973, Val F1: 0.8051, Gap: 0.0650\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8769, Val Acc: 0.8424, Val F1: 0.8473, Gap: 0.0344\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8904, Val Acc: 0.8486, Val F1: 0.8529, Gap: 0.0418\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9026, Val Acc: 0.8305, Val F1: 0.8348, Gap: 0.0720\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9115, Val Acc: 0.8445, Val F1: 0.8487, Gap: 0.0670\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9235, Val Acc: 0.8483, Val F1: 0.8525, Gap: 0.0753\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9286, Val Acc: 0.8516, Val F1: 0.8554, Gap: 0.0771\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9342, Val Acc: 0.8533, Val F1: 0.8568, Gap: 0.0809\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9400, Val Acc: 0.8405, Val F1: 0.8452, Gap: 0.0995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9456, Val Acc: 0.8421, Val F1: 0.8452, Gap: 0.1035\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▅▆▆▇▇█▇▇█████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▁▅▇▆▆▇▇▅▆▇▇▇█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▆▃▁▅▅▅▅█▇▆▆▇▅▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▅▇▆▆▇▇▇▇████▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▄▆▅▇▇▆▇▇▇▇▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▁▆▇▇▆▇█▆▇█▇█▇▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▄▇▆▇████████▆</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▇▅▇▇▇▇█▇█▇▆▇▃</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▁▅▄▄▅▆▅▆▅▆▆▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▆▆▇▅██▇▇███▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▆▆▄▆▇▇█▇▆█▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▆▆▇▅██▇▇██▇▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▆▆▇▄██▇▇███▆▇</td></tr><tr><td>Class_Positive_Precision</td><td>▂▁▆▄█▁██▄▆▇▇▇▃▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▅▄▆▃█▅▄▇▆▅▆▆█▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▇▆██▇██████</td></tr><tr><td>Validation F1</td><td>▁▃▅▆▇▆██▇██████</td></tr><tr><td>Validation Loss</td><td>█▆▄▂▂▃▁▁▂▁▁▁▁▃▂</td></tr><tr><td>Validation Precision</td><td>▁▃▆▆▇▆██▇████▇▇</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▆▆▇█▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86063</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.82333</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90146</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81055</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85932</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.76702</td></tr><tr><td>Class_Negative_F1</td><td>0.84438</td></tr><tr><td>Class_Negative_Precision</td><td>0.80494</td></tr><tr><td>Class_Negative_Recall</td><td>0.88788</td></tr><tr><td>Class_Neutral_F1</td><td>0.84031</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86441</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81751</td></tr><tr><td>Class_Positive_F1</td><td>0.87004</td></tr><tr><td>Class_Positive_Precision</td><td>0.84703</td></tr><tr><td>Class_Positive_Recall</td><td>0.89434</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94559</td></tr><tr><td>Train Loss</td><td>0.16892</td></tr><tr><td>Validation Accuracy</td><td>0.84208</td></tr><tr><td>Validation F1</td><td>0.84518</td></tr><tr><td>Validation Loss</td><td>0.52554</td></tr><tr><td>Validation Precision</td><td>0.83981</td></tr><tr><td>Validation Recall</td><td>0.85364</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/97wtvidr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/97wtvidr</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_130529-97wtvidr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 13:55:05,302] Trial 8 finished with value: 0.8532555879494655 and parameters: {'learning_rate': 5.245656664923903e-06, 'weight_decay': 2.0086269414200097e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-589794400.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(manual_weights, dtype=torch.float)\n"]},{"name":"stdout","output_type":"stream","text":["Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_135506-h1vkzr7r</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/h1vkzr7r' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/h1vkzr7r' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/h1vkzr7r</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5921, Val Acc: 0.6122, Val F1: 0.6221, Gap: -0.0202\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7415, Val Acc: 0.7468, Val F1: 0.7571, Gap: -0.0053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8005, Val Acc: 0.7798, Val F1: 0.7882, Gap: 0.0207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8355, Val Acc: 0.7664, Val F1: 0.7735, Gap: 0.0691\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8557, Val Acc: 0.8098, Val F1: 0.8167, Gap: 0.0459\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8758, Val Acc: 0.8209, Val F1: 0.8266, Gap: 0.0549\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8924, Val Acc: 0.8311, Val F1: 0.8356, Gap: 0.0613\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9036, Val Acc: 0.8324, Val F1: 0.8364, Gap: 0.0713\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9168, Val Acc: 0.8137, Val F1: 0.8179, Gap: 0.1031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9259, Val Acc: 0.8426, Val F1: 0.8460, Gap: 0.0833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9351, Val Acc: 0.8443, Val F1: 0.8477, Gap: 0.0908\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9406, Val Acc: 0.8318, Val F1: 0.8349, Gap: 0.1089\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9484, Val Acc: 0.8327, Val F1: 0.8349, Gap: 0.1156\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9547, Val Acc: 0.8405, Val F1: 0.8447, Gap: 0.1142\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9574, Val Acc: 0.8465, Val F1: 0.8503, Gap: 0.1110\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▆▆█▇▇▇▇██▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▇▆▅█▇▇▇▇▇█▇▆▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▁▆▇▅▆▇▇▇▆▆▇█▇▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▆▆█▇▇▇▇██▇▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▅▇▇▆▇▇█████▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▇▆██▇▇▇██▇▆██</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆▇▇███▇█▇▇▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▁▂▇█▅▇▇▂▅▃▂▁▂█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▆▆▆▇▇▇█▇▇███▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▅▆▇▇█▇██████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▇▆▆█▇▇██▇▇██▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▅▄▆▆▇▇▆▇█▇▇▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▄▆▇▇█▆██▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▆▂▄▆▆▇▄▇█▆▇█▆</td></tr><tr><td>Class_Positive_Recall</td><td>▂▅▃█▆▅▅▄▇▅▁▅▃▂▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇██▇██████</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇██▇██████</td></tr><tr><td>Validation Loss</td><td>█▃▂▃▁▁▁▁▃▁▂▃▂▃▃</td></tr><tr><td>Validation Precision</td><td>▁▅▆▅▇▇▇█▇██▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆▇▇██▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84929</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.80211</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90237</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81713</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83142</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80333</td></tr><tr><td>Class_Negative_F1</td><td>0.87873</td></tr><tr><td>Class_Negative_Precision</td><td>0.92051</td></tr><tr><td>Class_Negative_Recall</td><td>0.84057</td></tr><tr><td>Class_Neutral_F1</td><td>0.83311</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83828</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82801</td></tr><tr><td>Class_Positive_F1</td><td>0.87309</td></tr><tr><td>Class_Positive_Precision</td><td>0.84474</td></tr><tr><td>Class_Positive_Recall</td><td>0.9034</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95741</td></tr><tr><td>Train Loss</td><td>0.13544</td></tr><tr><td>Validation Accuracy</td><td>0.84645</td></tr><tr><td>Validation F1</td><td>0.85027</td></tr><tr><td>Validation Loss</td><td>0.64361</td></tr><tr><td>Validation Precision</td><td>0.84741</td></tr><tr><td>Validation Recall</td><td>0.85554</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/h1vkzr7r' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/h1vkzr7r</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_135506-h1vkzr7r/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 14:44:29,045] Trial 9 finished with value: 0.8464528668610302 and parameters: {'learning_rate': 6.623732793894006e-06, 'weight_decay': 1.3838323373618483e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_144430-fl7xdy3g</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/fl7xdy3g' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/fl7xdy3g' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/fl7xdy3g</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.7048, Val Acc: 0.7869, Val F1: 0.7969, Gap: -0.0821\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8262, Val Acc: 0.8406, Val F1: 0.8456, Gap: -0.0144\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8575, Val Acc: 0.8458, Val F1: 0.8513, Gap: 0.0116\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8710, Val Acc: 0.8214, Val F1: 0.8265, Gap: 0.0496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8803, Val Acc: 0.8461, Val F1: 0.8525, Gap: 0.0342\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8888, Val Acc: 0.8189, Val F1: 0.8242, Gap: 0.0700\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8917, Val Acc: 0.8421, Val F1: 0.8394, Gap: 0.0496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8968, Val Acc: 0.8541, Val F1: 0.8578, Gap: 0.0426\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8998, Val Acc: 0.8480, Val F1: 0.8543, Gap: 0.0518\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9047, Val Acc: 0.8426, Val F1: 0.8380, Gap: 0.0622\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9086, Val Acc: 0.8482, Val F1: 0.8533, Gap: 0.0604\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9097, Val Acc: 0.8494, Val F1: 0.8551, Gap: 0.0603\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9130, Val Acc: 0.8559, Val F1: 0.8588, Gap: 0.0571\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9154, Val Acc: 0.8601, Val F1: 0.8648, Gap: 0.0553\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9179, Val Acc: 0.8629, Val F1: 0.8677, Gap: 0.0550\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▅▇▇▆▇▅▃▇█▁█▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▄▃▂▄▁█▃▆█▆▇▃▄▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▆▇█▇█▂█▆▁▆▅█▇█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▆▃▅▄▇▆█▆█▇▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▆▄▄█▄▇▇▄▆▇▇▅█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▆▆▅▄▇▁█▄▆█▇▄▅▆▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▄▆▃▆▇▄▆▇▅▄█▅▇</td></tr><tr><td>Class_Negative_Precision</td><td>▃▆▃▅█▇▄▁▅▇▆▄█▅█</td></tr><tr><td>Class_Negative_Recall</td><td>▃▃▆▆▁▄██▆▅▄▅▅▅▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▇▇▆▇▄▇█▆█▆▆██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▆▂▆▃▆▃▁█▅▃▅▂▃▇▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇▅▆▆▄█▆▅█▅▇█▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▂▄▇▁▇▃▃█▅▇▅▇▄██</td></tr><tr><td>Class_Positive_Precision</td><td>▂▇▅█▆▁█▅▂▇▂▃█▆▅</td></tr><tr><td>Class_Positive_Recall</td><td>▆▃▆▁▅▇▂▆█▅▇█▃▆▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▄▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▄▆▄▆▇▇▆▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▆▆▄▆▄▅▇▇▅▇▇▇██</td></tr><tr><td>Validation Loss</td><td>█▃▂▅▂█▃▁▃▂▄▃▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▆▅▄▆▃█▆▆█▆▆▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▅▆▄▆▅▃█▇▃▆▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87608</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.82899</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92883</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83791</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.87922</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.8003</td></tr><tr><td>Class_Negative_F1</td><td>0.89108</td></tr><tr><td>Class_Negative_Precision</td><td>0.93519</td></tr><tr><td>Class_Negative_Recall</td><td>0.85094</td></tr><tr><td>Class_Neutral_F1</td><td>0.84278</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81796</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86915</td></tr><tr><td>Class_Positive_F1</td><td>0.89079</td></tr><tr><td>Class_Positive_Precision</td><td>0.8771</td></tr><tr><td>Class_Positive_Recall</td><td>0.90491</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.91787</td></tr><tr><td>Train Loss</td><td>0.24621</td></tr><tr><td>Validation Accuracy</td><td>0.86285</td></tr><tr><td>Validation F1</td><td>0.86772</td></tr><tr><td>Validation Loss</td><td>0.43846</td></tr><tr><td>Validation Precision</td><td>0.86769</td></tr><tr><td>Validation Recall</td><td>0.87083</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/fl7xdy3g' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/fl7xdy3g</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_144430-fl7xdy3g/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 15:33:53,018] Trial 10 finished with value: 0.8628522837706512 and parameters: {'learning_rate': 3.800975278900216e-05, 'weight_decay': 8.224357961383999e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_153354-jxj3zkpn</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/jxj3zkpn' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/jxj3zkpn' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/jxj3zkpn</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.7075, Val Acc: 0.7983, Val F1: 0.8054, Gap: -0.0908\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8247, Val Acc: 0.8293, Val F1: 0.8353, Gap: -0.0046\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8493, Val Acc: 0.8401, Val F1: 0.8437, Gap: 0.0092\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8566, Val Acc: 0.8514, Val F1: 0.8535, Gap: 0.0051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8679, Val Acc: 0.8484, Val F1: 0.8520, Gap: 0.0195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8768, Val Acc: 0.8401, Val F1: 0.8384, Gap: 0.0367\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8822, Val Acc: 0.8551, Val F1: 0.8592, Gap: 0.0272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8883, Val Acc: 0.8659, Val F1: 0.8710, Gap: 0.0224\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8905, Val Acc: 0.8664, Val F1: 0.8712, Gap: 0.0241\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8964, Val Acc: 0.8652, Val F1: 0.8705, Gap: 0.0313\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8981, Val Acc: 0.8638, Val F1: 0.8683, Gap: 0.0343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9015, Val Acc: 0.8366, Val F1: 0.8420, Gap: 0.0649\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9048, Val Acc: 0.8559, Val F1: 0.8596, Gap: 0.0489\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9076, Val Acc: 0.8604, Val F1: 0.8648, Gap: 0.0471\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9107, Val Acc: 0.8672, Val F1: 0.8706, Gap: 0.0435\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▅▄▄▅▁▆████▃▅▇▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▁▇▇▁█▂▆▄▄▄█▇▃▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄█▃▃█▁█▆▇█▇▂▄█▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▆▇▄▄▅▇▇█▇▄▆▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁█▂▃▅▃▄▄▅█▅▄▄▄▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▁██▄▅▅█▇▅▇▄▆▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▅▅▇▁▆▇██▇▇▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▆▇▆▆▇▁▇███▇▇▇██</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▄▄▄█▄▄▄▄▄▄▄▄▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▇▇██▇▇▇█▅▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▃▆▄▇▆██▆▅▆▁▄▆▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▃▇▅▇▅▅▇▆▇▇█▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▇▇▆▇▇▇▇▆▇█▆█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▄▇▄▇▆▅▇▄▇▄▆██</td></tr><tr><td>Class_Positive_Recall</td><td>▆█▆▃▇▂▅▇▃▇▂▇▅▁▃</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▆▅▇████▅▇▇█</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▆▅▇████▅▇▇█</td></tr><tr><td>Validation Loss</td><td>█▅▄▂▂▄▂▁▁▁▁▆▃▂▂</td></tr><tr><td>Validation Precision</td><td>▁▃▅▇▅▆▆▇▇▇▇▆▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▄▅▇▃▇███▇▄▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86299</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.90159</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.82755</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84597</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82107</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.87242</td></tr><tr><td>Class_Negative_F1</td><td>0.89216</td></tr><tr><td>Class_Negative_Precision</td><td>0.92308</td></tr><tr><td>Class_Negative_Recall</td><td>0.86325</td></tr><tr><td>Class_Neutral_F1</td><td>0.85678</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82582</td></tr><tr><td>Class_Neutral_Recall</td><td>0.89015</td></tr><tr><td>Class_Positive_F1</td><td>0.89519</td></tr><tr><td>Class_Positive_Precision</td><td>0.93652</td></tr><tr><td>Class_Positive_Recall</td><td>0.85736</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.91068</td></tr><tr><td>Train Loss</td><td>0.27347</td></tr><tr><td>Validation Accuracy</td><td>0.86723</td></tr><tr><td>Validation F1</td><td>0.87062</td></tr><tr><td>Validation Loss</td><td>0.42364</td></tr><tr><td>Validation Precision</td><td>0.88162</td></tr><tr><td>Validation Recall</td><td>0.86215</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/jxj3zkpn' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/jxj3zkpn</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_153354-jxj3zkpn/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 16:23:18,176] Trial 11 finished with value: 0.8672254616132167 and parameters: {'learning_rate': 4.908115536997722e-05, 'weight_decay': 9.063464027874585e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_162319-hmid31wg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hmid31wg' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hmid31wg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hmid31wg</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.7101, Val Acc: 0.8082, Val F1: 0.8154, Gap: -0.0981\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8331, Val Acc: 0.8355, Val F1: 0.8412, Gap: -0.0024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8692, Val Acc: 0.8308, Val F1: 0.8344, Gap: 0.0384\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8874, Val Acc: 0.8604, Val F1: 0.8632, Gap: 0.0270\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8997, Val Acc: 0.8550, Val F1: 0.8629, Gap: 0.0447\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9074, Val Acc: 0.8575, Val F1: 0.8625, Gap: 0.0499\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9129, Val Acc: 0.8597, Val F1: 0.8641, Gap: 0.0532\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9188, Val Acc: 0.8669, Val F1: 0.8695, Gap: 0.0520\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9217, Val Acc: 0.8666, Val F1: 0.8695, Gap: 0.0551\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9279, Val Acc: 0.8615, Val F1: 0.8651, Gap: 0.0664\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9307, Val Acc: 0.8466, Val F1: 0.8510, Gap: 0.0841\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9350, Val Acc: 0.8686, Val F1: 0.8721, Gap: 0.0664\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9356, Val Acc: 0.8690, Val F1: 0.8727, Gap: 0.0665\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9382, Val Acc: 0.8693, Val F1: 0.8726, Gap: 0.0689\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9410, Val Acc: 0.8664, Val F1: 0.8705, Gap: 0.0747\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▁▅▇▆▆▇▇▆▇██▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▃▁█▆▆█▆▅▅▅▆▇▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▇█▁▄▄▂▅▆▅▆▅▄▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▃▇▅▇▇█▇▇▆██▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▆▅▇▆▁█▇▇█▇██▇▆▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▂▇█▅▆▇▆▆▅▆▇▆▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆█▇▅▇█▃▆▂▆▇█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▅▇▇▇██▇▇▁▆▂▄▇▇▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▃▄▃▁▄▄█▄▅▇▃▄▃</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▇▆▆▆██▇▅▇▇█▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▅▃█▄▄▅▇▆▇▆▃▆▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▂▃▇▁▅▅▇▄▅▁▄█▅▄</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▂▃█▇▆▃▇▅▁▆▅▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▃▄▃▇▆▄▄█▆▅▁▅█▅▄</td></tr><tr><td>Class_Positive_Recall</td><td>▅▆▆▁▅▇▇▁▅▅█▆▂▆▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▄▇▆▇▇██▇▅████</td></tr><tr><td>Validation F1</td><td>▁▄▃▇▇▇▇██▇▅████</td></tr><tr><td>Validation Loss</td><td>█▄▅▁▄▄▂▃▂▄▇▄▆▃▆</td></tr><tr><td>Validation Precision</td><td>▁▃▂▇▆▆▆▇▆▆▄▆█▇▆</td></tr><tr><td>Validation Recall</td><td>▁▅▄▅▆▆▆▇█▇▆█▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87647</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86631</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88686</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84592</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85023</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84165</td></tr><tr><td>Class_Negative_F1</td><td>0.89001</td></tr><tr><td>Class_Negative_Precision</td><td>0.92822</td></tr><tr><td>Class_Negative_Recall</td><td>0.85483</td></tr><tr><td>Class_Neutral_F1</td><td>0.84903</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84773</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85033</td></tr><tr><td>Class_Positive_F1</td><td>0.8909</td></tr><tr><td>Class_Positive_Precision</td><td>0.85704</td></tr><tr><td>Class_Positive_Recall</td><td>0.92755</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94104</td></tr><tr><td>Train Loss</td><td>0.18463</td></tr><tr><td>Validation Accuracy</td><td>0.86638</td></tr><tr><td>Validation F1</td><td>0.87047</td></tr><tr><td>Validation Loss</td><td>0.51012</td></tr><tr><td>Validation Precision</td><td>0.86991</td></tr><tr><td>Validation Recall</td><td>0.87224</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hmid31wg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/hmid31wg</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_162319-hmid31wg/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 17:12:41,085] Trial 12 finished with value: 0.869290573372206 and parameters: {'learning_rate': 4.733527832416233e-05, 'weight_decay': 3.858692918397283e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_171242-aviv1clb</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/aviv1clb' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/aviv1clb' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/aviv1clb</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6998, Val Acc: 0.8033, Val F1: 0.8099, Gap: -0.1036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8322, Val Acc: 0.8019, Val F1: 0.8102, Gap: 0.0303\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8722, Val Acc: 0.8373, Val F1: 0.8423, Gap: 0.0348\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8943, Val Acc: 0.8590, Val F1: 0.8635, Gap: 0.0353\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9093, Val Acc: 0.8604, Val F1: 0.8647, Gap: 0.0489\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9177, Val Acc: 0.8697, Val F1: 0.8722, Gap: 0.0481\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9260, Val Acc: 0.8593, Val F1: 0.8635, Gap: 0.0667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9322, Val Acc: 0.8664, Val F1: 0.8705, Gap: 0.0659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9373, Val Acc: 0.8338, Val F1: 0.8362, Gap: 0.1035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9397, Val Acc: 0.8582, Val F1: 0.8577, Gap: 0.0815\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9437, Val Acc: 0.8639, Val F1: 0.8664, Gap: 0.0797\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9471, Val Acc: 0.8613, Val F1: 0.8647, Gap: 0.0859\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9483, Val Acc: 0.8587, Val F1: 0.8617, Gap: 0.0895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9503, Val Acc: 0.8438, Val F1: 0.8474, Gap: 0.1065\n","Early stopping at epoch 14\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▃▃▄█▇██▇▁▃▆▇▆▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▄▇▃▅▇▅▆▇▁█▆▄▄▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▁▇▆▄▆▅▄█▁▅▇▇▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▂▃▃▆████▁▇▇▆▆▅</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▃▄▆█▇▆▅▅▅▇▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▆▃▅██▆▇▇▁█▇▅▅▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▇█▇▇█▇▅▆▇▇▄</td></tr><tr><td>Class_Negative_Precision</td><td>▄▄▇▆█▃▇█▆▁▆█▂▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▄▅▄▇▄▅▅▇▄▄█▃</td></tr><tr><td>Class_Neutral_F1</td><td>▂▁▆▇▆▇▆▇▇▇█▇▇▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▅▁▇█▅▇▆▄▇▆▆▆█▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▄▆▆▅█▅▇▇▆▅▅</td></tr><tr><td>Class_Positive_F1</td><td>▂▁▆▇▇█▆█▇████▅</td></tr><tr><td>Class_Positive_Precision</td><td>▃▁▆▅▅▆▄▇▇▇█▆▇▄</td></tr><tr><td>Class_Positive_Recall</td><td>▃█▄▆▆▆█▂▃▃▁▆▄▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁▅▇▇█▇█▄▇▇▇▇▅</td></tr><tr><td>Validation F1</td><td>▁▁▅▇▇█▇█▄▆▇▇▇▅</td></tr><tr><td>Validation Loss</td><td>▅▅▂▁▁▁▃▃▆▄▃▅▄█</td></tr><tr><td>Validation Precision</td><td>▁▂▄▆▇▇▆█▃▇▇▆▅▄</td></tr><tr><td>Validation Recall</td><td>▂▁▅▇▇█▇▆▅▅▆▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84949</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.79538</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.9115</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81777</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86543</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77509</td></tr><tr><td>Class_Negative_F1</td><td>0.8772</td></tr><tr><td>Class_Negative_Precision</td><td>0.92028</td></tr><tr><td>Class_Negative_Recall</td><td>0.83798</td></tr><tr><td>Class_Neutral_F1</td><td>0.82731</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8275</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82713</td></tr><tr><td>Class_Positive_F1</td><td>0.8653</td></tr><tr><td>Class_Positive_Precision</td><td>0.81205</td></tr><tr><td>Class_Positive_Recall</td><td>0.92604</td></tr><tr><td>Epoch</td><td>14</td></tr><tr><td>Train Accuracy</td><td>0.9503</td></tr><tr><td>Train Loss</td><td>0.16228</td></tr><tr><td>Validation Accuracy</td><td>0.84378</td></tr><tr><td>Validation F1</td><td>0.84742</td></tr><tr><td>Validation Loss</td><td>0.63384</td></tr><tr><td>Validation Precision</td><td>0.84413</td></tr><tr><td>Validation Recall</td><td>0.85555</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/aviv1clb' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/aviv1clb</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_171242-aviv1clb/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 17:58:46,302] Trial 13 finished with value: 0.8696550048590865 and parameters: {'learning_rate': 3.1094326027944724e-05, 'weight_decay': 3.505302260086934e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8732993197278912.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_175847-2mntydp2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/2mntydp2' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/2mntydp2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_4/runs/2mntydp2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6910, Val Acc: 0.8123, Val F1: 0.8180, Gap: -0.1214\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 4:\")\n","study4 = optuna.create_study(direction=\"maximize\")\n","study4.optimize(objective, n_trials=15)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study4.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model4.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WxaGlMA94HVH"},"source":["\n","#### PREPROCESSING STRATEGY: WHY WE CHOSE A LIGHTER CLEANING FUNCTION\n","\n","\n","Previously, we used an aggressive text cleaning function (`normalize_text`) designed to:\n"," - Remove emojis, repeated punctuation, and special characters\n"," - Normalize COVID-related hashtags (e.g., #covid2019 → #covid)\n"," - Split hashtags into multiple words (e.g., #StayHomeStaySafe → #Stay #Home #Stay #Safe)\n"," - Remove duplicate hashtags and gibberish tokens\n"," - Fix common HTML entities and encoding artifacts\n","\n"," While this helped create a very \"clean\" dataset, it may also have stripped away:\n"," - Hashtag structure that captures tweet-specific sentiment (e.g., #panicbuying, #heroes)\n"," - Informal Twitter conventions that are useful in real-world classification\n","\n"," Since the CardiffNLP RoBERTa model (`cardiffnlp/twitter-roberta-base-sentiment-latest`) was pretrained\n"," specifically on noisy Twitter data (with emojis, mentions, and slang), we now switch to a lighter\n"," preprocessing function: `clean_for_cardiffnlp`.\n","\n"," This new function performs minimal normalization:\n"," - Replaces mentions with \"@user\" and links with \"http\"\n"," - Normalizes common COVID spelling variants (e.g., corona → covid)\n"," - Leaves emojis, punctuation, and hashtags largely intact\n","\n"," Rationale for switching:\n","- Better alignment with the model's original pretraining data\n","- Preserves real-world phrasing as it appeared in social media\n","- Avoids over-sanitizing input that the model may already be robust to\n","\n","#### **In summary:** we believe this lighter cleaning approach will improve model generalization, especially on sentiment-heavy or emotionally nuanced tweets, and will better **leverage the strengths of the CardiffNLP pretrained tokenizer.**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DTNwDvT6caay"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQKuZLRT485O"},"outputs":[],"source":["def clean_for_cardiffnlp(text):\n","    if pd.isnull(text):\n","        return \"\"\n","\n","    tokens = []\n","    for t in text.split(\" \"):\n","        if t.startswith(\"@\") and len(t) > 1:\n","            tokens.append(\"@user\")\n","        elif t.startswith(\"http\"):\n","            tokens.append(\"http\")\n","        else:\n","            tokens.append(t)\n","    text = \" \".join(tokens)\n","\n","    # Normalize common COVID variants to \"covid\"\n","    text = re.sub(r\"\\b(coronaviruspandemic|covid[_\\s-]*2019|covid[_\\s-]*19|covid2019|coronavirus2019|coronavirus|corona)\\b\", \"covid\", text, flags=re.IGNORECASE)\n","\n","    # Decode HTML entities\n","    text = html.unescape(text)\n","\n","    # Normalize whitespace and repeated punctuation (optional)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    text = re.sub(r\"(\\.\\s*){2,}\", \". \", text)\n","    text = re.sub(r\"([!?]){2,}\", r\"\\1\", text)\n","    text = re.sub(r\"(\\?\\s+){2,}\", \"?\", text)\n","    text = re.sub(r\"(\\!\\s+){2,}\", \"!\", text)\n","\n","    return text\n"]},{"cell_type":"code","source":["# Apply to train and test\n","train_df['ProcessedTweet'] = train_df['OriginalTweet'].apply(clean_for_cardiffnlp)\n","eval_df['ProcessedTweet'] = eval_df['OriginalTweet'].apply(clean_for_cardiffnlp)"],"metadata":{"id":"QQ86v6JymPog"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":111,"status":"ok","timestamp":1754507959225,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"6v_JK7KHmz6s","outputId":"25c5e3e6-129e-465e-c16d-abe62443e567"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"sample\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"ProcessedTweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"? $CAG $GIS $K $KO Consumer Brands Association CEO on the state of global supply chains amid covid http http\",\n          \"Some #Costco stores say their prohibiting people from returning #toiletpaper. Who returns toilet paper? Probably the same people who think their rectums go into remission? #Trending #covid @user @user #JimmyKimmel #ForReal\",\n          \"I nominate the global covid Responders for the 2020 Time Magazine\\u00c3\\u0082\\u00c2\\u0092s Person of the Year: (including nurses, paramedics, doctors, hospital admin and cleaning staff, grocery store employees, etc) #CoronavirusHeroes #covid #covid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Neutral\",\n          \"Extremely Negative\",\n          \"Extremely Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"sample"},"text/html":["\n","  <div id=\"df-50044a45-c89d-40da-b911-4a0917c87cc7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ProcessedTweet</th>\n","      <th>Sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17977</th>\n","      <td>New survey by @user finds that only 2% of #consumers think #brands should pause all #advertising; 49% want #ads to make them feel informed and 37% want ads to make them feel warm/happy #digitalmarketing #covid #consumerbehavior http</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>31793</th>\n","      <td>Some #Costco stores say their prohibiting people from returning #toiletpaper. Who returns toilet paper? Probably the same people who think their rectums go into remission? #Trending #covid @user @user #JimmyKimmel #ForReal</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8808</th>\n","      <td>After increasing the prices of platform tickets, the Indian Railways withdrew most concessional ticket facilities in trains as a precautionary measure to contain the spread of #covid. https://t.co/PmUuJd3GI4</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>23027</th>\n","      <td>@user $Hdelacerda. Oil prices caused a massive slow down and now the covid has caused layoffs, I havenÃÂt worked since the beginning of February just trying to make sure my wife and 2 daughters are taken care of.</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6409</th>\n","      <td>My wife just messaged me to say the supermarket shelves were empty. I know what's for dinner tonight #covid #CoronavirusOutbreak http</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>28137</th>\n","      <td>I nominate the global covid Responders for the 2020 Time MagazineÃÂs Person of the Year: (including nurses, paramedics, doctors, hospital admin and cleaning staff, grocery store employees, etc) #CoronavirusHeroes #covid #covid</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>22277</th>\n","      <td>WeÃÂd like to take a moment to thank all of the grocery store personnel, cleaners, maintenance workers, truck drivers and warehouse workers for their perseverance and commitment. We are incredibly grateful to those who are making sacrifices to support the covid fight. http</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>21206</th>\n","      <td>This is too much! No fizzy san PelegrÃÂ­no water for my wine spritzer OR Houmous! What in gods name do you expect the middle classes to do! To die like dinosaurs! #covid #StayHome24in48 #stockpilingUK #toiletpaper #CoronaCrisis #covid #covid</td>\n","      <td>Extremely Negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15208</th>\n","      <td>? $CAG $GIS $K $KO Consumer Brands Association CEO on the state of global supply chains amid covid http http</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>28598</th>\n","      <td>BREAKING: Govt. has announced good news for shoppers who have been battling to buy essential products at inflated prices. Retailers on the naughty list could face hefty fines or even prison sentences. #Covid19SA #COVID19SouthAfrica #CoronaVirusUpdate http</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50044a45-c89d-40da-b911-4a0917c87cc7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-50044a45-c89d-40da-b911-4a0917c87cc7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-50044a45-c89d-40da-b911-4a0917c87cc7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-d6eec1ce-a604-437c-9620-9e641352fdd4\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6eec1ce-a604-437c-9620-9e641352fdd4')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-d6eec1ce-a604-437c-9620-9e641352fdd4 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_e2b032f5-c684-45e7-8c55-c2871bb91a24\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_e2b032f5-c684-45e7-8c55-c2871bb91a24 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('sample');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                                                                                                                                                                                                                                                            ProcessedTweet  \\\n","17977                                             New survey by @user finds that only 2% of #consumers think #brands should pause all #advertising; 49% want #ads to make them feel informed and 37% want ads to make them feel warm/happy #digitalmarketing #covid #consumerbehavior http   \n","31793                                                       Some #Costco stores say their prohibiting people from returning #toiletpaper. Who returns toilet paper? Probably the same people who think their rectums go into remission? #Trending #covid @user @user #JimmyKimmel #ForReal   \n","8808                                                                       After increasing the prices of platform tickets, the Indian Railways withdrew most concessional ticket facilities in trains as a precautionary measure to contain the spread of #covid. https://t.co/PmUuJd3GI4   \n","23027                                                               @user $Hdelacerda. Oil prices caused a massive slow down and now the covid has caused layoffs, I havenÃÂt worked since the beginning of February just trying to make sure my wife and 2 daughters are taken care of.   \n","6409                                                                                                                                                 My wife just messaged me to say the supermarket shelves were empty. I know what's for dinner tonight #covid #CoronavirusOutbreak http   \n","28137                                                 I nominate the global covid Responders for the 2020 Time MagazineÃÂs Person of the Year: (including nurses, paramedics, doctors, hospital admin and cleaning staff, grocery store employees, etc) #CoronavirusHeroes #covid #covid   \n","22277  WeÃÂd like to take a moment to thank all of the grocery store personnel, cleaners, maintenance workers, truck drivers and warehouse workers for their perseverance and commitment. We are incredibly grateful to those who are making sacrifices to support the covid fight. http   \n","21206                                   This is too much! No fizzy san PelegrÃÂ­no water for my wine spritzer OR Houmous! What in gods name do you expect the middle classes to do! To die like dinosaurs! #covid #StayHome24in48 #stockpilingUK #toiletpaper #CoronaCrisis #covid #covid   \n","15208                                                                                                                                                                         ? $CAG $GIS $K $KO Consumer Brands Association CEO on the state of global supply chains amid covid http http   \n","28598                      BREAKING: Govt. has announced good news for shoppers who have been battling to buy essential products at inflated prices. Retailers on the naughty list could face hefty fines or even prison sentences. #Covid19SA #COVID19SouthAfrica #CoronaVirusUpdate http   \n","\n","                Sentiment  label  \n","17977  Extremely Positive      4  \n","31793             Neutral      2  \n","8808              Neutral      2  \n","23027  Extremely Positive      4  \n","6409             Negative      1  \n","28137             Neutral      2  \n","22277  Extremely Positive      4  \n","21206  Extremely Negative      0  \n","15208             Neutral      2  \n","28598            Negative      1  "]},"metadata":{},"output_type":"display_data"}],"source":["# Display\n","pd.set_option('display.max_colwidth', None)  # so full text is shown\n","sample = train_df[['ProcessedTweet','Sentiment','label']].sample(10, random_state=24)\n","display(sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":372},"id":"jRznPRFu482K","outputId":"58c6c29d-a565-4417-c43b-03d048189b6f"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 19:06:16,430] A new study created in memory with name: no-name-08664731-cc2f-4a24-82e1-b5ce991c06d2\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 5:\n","Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Finishing previous runs because reinit is set to 'default'."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_5/runs/6jnsrn03' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_5/runs/6jnsrn03</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_5' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_5</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_190433-6jnsrn03/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_190617-ociof3ke</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ociof3ke' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ociof3ke' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ociof3ke</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4478, Val Acc: 0.4947, Val F1: 0.5031, Gap: -0.0469\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5019, Val Acc: 0.5228, Val F1: 0.5343, Gap: -0.0209\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.5301, Val Acc: 0.5511, Val F1: 0.5650, Gap: -0.0211\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.5489, Val Acc: 0.5702, Val F1: 0.5803, Gap: -0.0213\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.5653, Val Acc: 0.5825, Val F1: 0.5950, Gap: -0.0172\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.5780, Val Acc: 0.5848, Val F1: 0.5974, Gap: -0.0068\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.5886, Val Acc: 0.5771, Val F1: 0.5918, Gap: 0.0115\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.6038, Val Acc: 0.6023, Val F1: 0.6160, Gap: 0.0015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.6121, Val Acc: 0.5979, Val F1: 0.6121, Gap: 0.0141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.6282, Val Acc: 0.5996, Val F1: 0.6111, Gap: 0.0285\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.6390, Val Acc: 0.6011, Val F1: 0.6125, Gap: 0.0379\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.6504, Val Acc: 0.5966, Val F1: 0.6096, Gap: 0.0538\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.6628, Val Acc: 0.5968, Val F1: 0.6097, Gap: 0.0660\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.6759, Val Acc: 0.5828, Val F1: 0.5944, Gap: 0.0930\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.6862, Val Acc: 0.6016, Val F1: 0.6152, Gap: 0.0846\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▆▆▇▇▇██▇███▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▄▄▅▄▄▄▅▃▁▂▃▃▁█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▂▅▄▅▆▆▆▇██▇▇█▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▃▁▃▇▅▆▅█▇▅▆▄▇▆█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▄▆▅▇▆▅▇██▇▆▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▆▁▂█▄▆▃▇▇▃▃▁▅▅▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▅▆▆▆▆█████▆▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▂▂▁▂▄▇▇▆▆▅▅▅█▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▇█▇▄▄▇▇██▇▄▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▄▅▇█▅▇▆▇▇▇█▃█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▄▅▅▅▄▇█▇▇▅▅█▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▆▄▄▇█▄▅▄▆▅▇█▁█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▂▅▄▇▆▇███▆▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▄█▇▇▂▆▆▇▅▆▆▂▇</td></tr><tr><td>Class_Positive_Recall</td><td>▄▄▄▁▃▃█▄▄▅▆▅▄█▄</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▃▄▄▅▅▆▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▃▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▇▇▆██████▇█</td></tr><tr><td>Validation F1</td><td>▁▃▅▆▇▇▇██████▇█</td></tr><tr><td>Validation Loss</td><td>█▆▄▃▂▂▂▁▁▁▂▁▂▄▂</td></tr><tr><td>Validation Precision</td><td>▁▃▄▆▆▇▆▇▇▇▆▇▇▅█</td></tr><tr><td>Validation Recall</td><td>▁▂▅▅▆▆▇▇▇██▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.63888</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.68149</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.60128</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.55627</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.54471</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.56833</td></tr><tr><td>Class_Negative_F1</td><td>0.67012</td></tr><tr><td>Class_Negative_Precision</td><td>0.71746</td></tr><tr><td>Class_Negative_Recall</td><td>0.62865</td></tr><tr><td>Class_Neutral_F1</td><td>0.55576</td></tr><tr><td>Class_Neutral_Precision</td><td>0.51694</td></tr><tr><td>Class_Neutral_Recall</td><td>0.60088</td></tr><tr><td>Class_Positive_F1</td><td>0.65499</td></tr><tr><td>Class_Positive_Precision</td><td>0.69276</td></tr><tr><td>Class_Positive_Recall</td><td>0.62113</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.68617</td></tr><tr><td>Train Loss</td><td>0.76926</td></tr><tr><td>Validation Accuracy</td><td>0.60155</td></tr><tr><td>Validation F1</td><td>0.6152</td></tr><tr><td>Validation Loss</td><td>1.00033</td></tr><tr><td>Validation Precision</td><td>0.63067</td></tr><tr><td>Validation Recall</td><td>0.60405</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ociof3ke' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ociof3ke</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_190617-ociof3ke/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 19:27:07,501] Trial 0 finished with value: 0.6022837706511176 and parameters: {'learning_rate': 4.3003492183793905e-05, 'weight_decay': 2.2829089853660432e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 1, 'dropout_rate': 0.1, 'gradient_clip_val': 2.0, 'use_class_weights': False}. Best is trial 0 with value: 0.6022837706511176.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_192709-1jn60bx0</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/1jn60bx0' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/1jn60bx0' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/1jn60bx0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.3810, Val Acc: 0.4164, Val F1: 0.4153, Gap: -0.0354\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4225, Val Acc: 0.4356, Val F1: 0.4414, Gap: -0.0131\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4442, Val Acc: 0.4412, Val F1: 0.4438, Gap: 0.0030\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.4535, Val Acc: 0.4526, Val F1: 0.4525, Gap: 0.0008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.4636, Val Acc: 0.4679, Val F1: 0.4722, Gap: -0.0043\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.4720, Val Acc: 0.4704, Val F1: 0.4694, Gap: 0.0016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.4772, Val Acc: 0.4858, Val F1: 0.4912, Gap: -0.0086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.4826, Val Acc: 0.4877, Val F1: 0.4910, Gap: -0.0051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.4909, Val Acc: 0.4824, Val F1: 0.4822, Gap: 0.0085\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.4975, Val Acc: 0.4989, Val F1: 0.5008, Gap: -0.0014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.5012, Val Acc: 0.5029, Val F1: 0.5090, Gap: -0.0017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.5090, Val Acc: 0.5050, Val F1: 0.5098, Gap: 0.0041\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.5141, Val Acc: 0.5128, Val F1: 0.5178, Gap: 0.0013\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5169, Val Acc: 0.4945, Val F1: 0.4902, Gap: 0.0224\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.5220, Val Acc: 0.5296, Val F1: 0.5394, Gap: -0.0076\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▃▄▄▄▅▅▆▆▆▇▇▆█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▁▂▄▄▃▅▅▆▄▅▅▆▃█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▂▄▂▃▄▂▄▃▇▆▆▅█▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▃▃▂▃▄▁▅▄▄▃▆▅▅▄█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▃▄▅▆▆▇▇▇▇████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▄▃▄▄▁▄▄▃▂▅▅▅▃█</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▃▄▅▅▅▆▅▇▇▇███</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▄▂▅▁▃▄▂▅█▇▆▆▇</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▂▆▃█▆▆█▆▃▄▇▇▅</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▄▃▅▇▇▇▅█▇▇█▄█</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▁▁▂▂▄▄▅▅▆▅▅▆█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▄▃▆▇▇▇▅█▇▇█▃█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▃▄▅▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▃▃▄█▇▆▄█▆▆▇▅█</td></tr><tr><td>Class_Positive_Recall</td><td>▃▂▄▆▅▁▄▅▇▄▇▇▆█▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▃▃▄▄▅▅▅▆▆▆▇▆█</td></tr><tr><td>Validation F1</td><td>▁▂▃▃▄▄▅▅▅▆▆▆▇▅█</td></tr><tr><td>Validation Loss</td><td>█▇▆▅▅▄▄▃▃▃▂▂▂▂▁</td></tr><tr><td>Validation Precision</td><td>▁▂▂▃▄▄▅▅▅▆▇▇▇▆█</td></tr><tr><td>Validation Recall</td><td>▁▂▃▄▄▅▅▆▆▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.60779</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.5122</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.74726</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.45327</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.5</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.41452</td></tr><tr><td>Class_Negative_F1</td><td>0.61929</td></tr><tr><td>Class_Negative_Precision</td><td>0.60659</td></tr><tr><td>Class_Negative_Recall</td><td>0.63253</td></tr><tr><td>Class_Neutral_F1</td><td>0.40315</td></tr><tr><td>Class_Neutral_Precision</td><td>0.50261</td></tr><tr><td>Class_Neutral_Recall</td><td>0.33654</td></tr><tr><td>Class_Positive_F1</td><td>0.61354</td></tr><tr><td>Class_Positive_Precision</td><td>0.52649</td></tr><tr><td>Class_Positive_Recall</td><td>0.73509</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.522</td></tr><tr><td>Train Loss</td><td>1.04513</td></tr><tr><td>Validation Accuracy</td><td>0.52964</td></tr><tr><td>Validation F1</td><td>0.53941</td></tr><tr><td>Validation Loss</td><td>1.02684</td></tr><tr><td>Validation Precision</td><td>0.52958</td></tr><tr><td>Validation Recall</td><td>0.57319</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/1jn60bx0' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/1jn60bx0</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_192709-1jn60bx0/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 19:48:20,211] Trial 1 finished with value: 0.5296404275996113 and parameters: {'learning_rate': 6.836904286841391e-06, 'weight_decay': 1.1569056177561571e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 1, 'dropout_rate': 0.1, 'gradient_clip_val': 2.0, 'use_class_weights': True}. Best is trial 0 with value: 0.6022837706511176.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_194821-ewdm5o50</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ewdm5o50' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ewdm5o50' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ewdm5o50</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4425, Val Acc: 0.4991, Val F1: 0.5029, Gap: -0.0567\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5108, Val Acc: 0.5261, Val F1: 0.5325, Gap: -0.0154\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.5389, Val Acc: 0.5514, Val F1: 0.5619, Gap: -0.0125\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.5618, Val Acc: 0.5654, Val F1: 0.5734, Gap: -0.0035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.5847, Val Acc: 0.5714, Val F1: 0.5785, Gap: 0.0133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.5976, Val Acc: 0.5961, Val F1: 0.6051, Gap: 0.0015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.6146, Val Acc: 0.5782, Val F1: 0.5841, Gap: 0.0364\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.6355, Val Acc: 0.6018, Val F1: 0.6095, Gap: 0.0337\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.6444, Val Acc: 0.5968, Val F1: 0.6060, Gap: 0.0476\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.6586, Val Acc: 0.6112, Val F1: 0.6181, Gap: 0.0475\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.6709, Val Acc: 0.6269, Val F1: 0.6384, Gap: 0.0440\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.6785, Val Acc: 0.6130, Val F1: 0.6215, Gap: 0.0656\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.6932, Val Acc: 0.6305, Val F1: 0.6410, Gap: 0.0627\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.7037, Val Acc: 0.6141, Val F1: 0.6243, Gap: 0.0896\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.7137, Val Acc: 0.6184, Val F1: 0.6305, Gap: 0.0953\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▄▄▇▄▆▅▆█▅█▆▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▄▃▂▆▂▄▃▄█▃▆▄▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▁▁▅▇▄█▆▇▇▂█▄▇▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▅▅▄▅▄▆▅▅█▆█▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▄▅▆▇▆█▅██▇█▇▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▅▅▄▅▄▅▅▄█▅▇▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▄▅▆▆▇▇▇██████</td></tr><tr><td>Class_Negative_Precision</td><td>▂▁▅▅▆▄▅▄▆▅▇▆▇██</td></tr><tr><td>Class_Negative_Recall</td><td>▂▆▁▄▃█▆█▆▇▆▆▆▄▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▁▃▄▄▆▅▆▆▇▇██▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▂▄▆▆▇▆██▇█▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▁▄▄▄▆▄▆▆▇▇▇█▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▃▄▅▇▆▇▇█▇████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▆▂▄▃▆▅▇▇▇▆█▇▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▅▁▇▅█▅▇▆▅▆█▅▆▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▃▄▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▄▃▃▂▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▄▅▅▆▅▆▆▇█▇█▇▇</td></tr><tr><td>Validation F1</td><td>▁▂▄▅▅▆▅▆▆▇█▇█▇▇</td></tr><tr><td>Validation Loss</td><td>█▇▅▄▄▂▃▂▃▂▁▂▂▃▃</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▅▆▅▆▆▇█▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▂▄▅▅▆▆▇▇▇█▇█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.6669</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.54446</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8604</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.53795</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.54349</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.53253</td></tr><tr><td>Class_Negative_F1</td><td>0.71703</td></tr><tr><td>Class_Negative_Precision</td><td>0.7626</td></tr><tr><td>Class_Negative_Recall</td><td>0.6766</td></tr><tr><td>Class_Neutral_F1</td><td>0.53891</td></tr><tr><td>Class_Neutral_Precision</td><td>0.63464</td></tr><tr><td>Class_Neutral_Recall</td><td>0.46827</td></tr><tr><td>Class_Positive_F1</td><td>0.6919</td></tr><tr><td>Class_Positive_Precision</td><td>0.65113</td></tr><tr><td>Class_Positive_Recall</td><td>0.73811</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.71371</td></tr><tr><td>Train Loss</td><td>0.65643</td></tr><tr><td>Validation Accuracy</td><td>0.61844</td></tr><tr><td>Validation F1</td><td>0.63054</td></tr><tr><td>Validation Loss</td><td>0.90358</td></tr><tr><td>Validation Precision</td><td>0.62726</td></tr><tr><td>Validation Recall</td><td>0.65518</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ewdm5o50' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/ewdm5o50</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_194821-ewdm5o50/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 20:10:32,981] Trial 2 finished with value: 0.630466472303207 and parameters: {'learning_rate': 2.2561325915500794e-05, 'weight_decay': 5.2598281707010895e-06, 'patience': 5, 'batch_size': 64, 'num_layers': 2, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 2 with value: 0.630466472303207.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_201034-9cno3ic8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9cno3ic8' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9cno3ic8' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9cno3ic8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5391, Val Acc: 0.6601, Val F1: 0.6699, Gap: -0.1210\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6957, Val Acc: 0.7063, Val F1: 0.7165, Gap: -0.0106\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7525, Val Acc: 0.7580, Val F1: 0.7658, Gap: -0.0055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7919, Val Acc: 0.7775, Val F1: 0.7843, Gap: 0.0145\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8238, Val Acc: 0.7799, Val F1: 0.7850, Gap: 0.0440\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8489, Val Acc: 0.8113, Val F1: 0.8177, Gap: 0.0375\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8662, Val Acc: 0.8129, Val F1: 0.8190, Gap: 0.0533\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8807, Val Acc: 0.8262, Val F1: 0.8316, Gap: 0.0546\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8954, Val Acc: 0.8245, Val F1: 0.8291, Gap: 0.0709\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9058, Val Acc: 0.8336, Val F1: 0.8390, Gap: 0.0723\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9159, Val Acc: 0.8356, Val F1: 0.8403, Gap: 0.0802\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9237, Val Acc: 0.8390, Val F1: 0.8433, Gap: 0.0846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9327, Val Acc: 0.8405, Val F1: 0.8451, Gap: 0.0922\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9390, Val Acc: 0.8428, Val F1: 0.8475, Gap: 0.0962\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9445, Val Acc: 0.8517, Val F1: 0.8551, Gap: 0.0929\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▄▅▃▆▇▇▇█▇▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▃▄▂▅▆▆▆█▇▆▇██</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▁▆▅█▆▅▅▆▃▄▅▅▄▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▄▅▄▆▇▇▇██▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▅▅▅▆▇▇▇▇▆▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▄▅▄▇▇▇▇████▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▇▇▇█████████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆▆████▆▇█▇██▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▃▄▃▄▄▅▇▇▄▅▅▅█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▁▅▅▆▇▆▇▇▇▇█▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▆▆▆▆▇█▇▇█▇▆▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▁▅▄▆▆▅▆▆▆▇▇▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▁▅▅▆▇▆▇▇▇▇████</td></tr><tr><td>Class_Positive_Precision</td><td>▄▁▆▄▅▇▄▅▅▅▆▆▆▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▃▇▆▅████▇▇▇▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▅▅▇▇▇▇▇▇████</td></tr><tr><td>Validation F1</td><td>▁▃▅▅▅▇▇▇▇▇▇████</td></tr><tr><td>Validation Loss</td><td>█▆▄▃▃▂▂▁▁▁▁▁▂▃▂</td></tr><tr><td>Validation Precision</td><td>▁▃▅▅▅▇▆▇▇▇▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▆▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86219</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83562</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89051</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81802</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84043</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79677</td></tr><tr><td>Class_Negative_F1</td><td>0.86615</td></tr><tr><td>Class_Negative_Precision</td><td>0.86006</td></tr><tr><td>Class_Negative_Recall</td><td>0.87233</td></tr><tr><td>Class_Neutral_F1</td><td>0.85036</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8245</td></tr><tr><td>Class_Neutral_Recall</td><td>0.8779</td></tr><tr><td>Class_Positive_F1</td><td>0.87853</td></tr><tr><td>Class_Positive_Precision</td><td>0.93002</td></tr><tr><td>Class_Positive_Recall</td><td>0.83245</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.94454</td></tr><tr><td>Train Loss</td><td>0.15756</td></tr><tr><td>Validation Accuracy</td><td>0.85168</td></tr><tr><td>Validation F1</td><td>0.85505</td></tr><tr><td>Validation Loss</td><td>0.52513</td></tr><tr><td>Validation Precision</td><td>0.85812</td></tr><tr><td>Validation Recall</td><td>0.85399</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9cno3ic8' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9cno3ic8</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_201034-9cno3ic8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 20:54:58,815] Trial 3 finished with value: 0.8516763848396501 and parameters: {'learning_rate': 5.569600849974849e-06, 'weight_decay': 1.0567994278417412e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_205459-9imeczki</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9imeczki' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9imeczki' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9imeczki</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4577, Val Acc: 0.5185, Val F1: 0.5324, Gap: -0.0608\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5290, Val Acc: 0.5560, Val F1: 0.5679, Gap: -0.0270\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.5602, Val Acc: 0.5805, Val F1: 0.5932, Gap: -0.0203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.5805, Val Acc: 0.5948, Val F1: 0.6075, Gap: -0.0142\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.5973, Val Acc: 0.5883, Val F1: 0.6021, Gap: 0.0090\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.6149, Val Acc: 0.6131, Val F1: 0.6251, Gap: 0.0018\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.6268, Val Acc: 0.6206, Val F1: 0.6343, Gap: 0.0061\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.6426, Val Acc: 0.6127, Val F1: 0.6238, Gap: 0.0298\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.6500, Val Acc: 0.6350, Val F1: 0.6475, Gap: 0.0150\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.6599, Val Acc: 0.6266, Val F1: 0.6395, Gap: 0.0333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.6742, Val Acc: 0.6395, Val F1: 0.6523, Gap: 0.0348\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.6826, Val Acc: 0.6374, Val F1: 0.6497, Gap: 0.0452\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.6979, Val Acc: 0.6322, Val F1: 0.6449, Gap: 0.0658\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.7101, Val Acc: 0.6452, Val F1: 0.6570, Gap: 0.0650\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.7167, Val Acc: 0.6399, Val F1: 0.6515, Gap: 0.0767\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▅▆▆▇▇▆█▇█████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▆█▃▅█▁▆▄█▇▅▅▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▁▃▃▆▆▄█▆▇▅▆▇▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▅▃▄▆▃█▆█▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▅▆▇▇▆▆▆▇█▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▆▅▆▆▂▂▄▁█▅▇▄▇█▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▄▇▇██▇█████</td></tr><tr><td>Class_Negative_Precision</td><td>▂▁▁▂█▄▅▆▆▇▅▆▇▇▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▇█▂▇▇▇▇▅▇▇▆▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▄▄▅▆▆▆▇▇▇▇▆█▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▅▄▅▅▇█▇▇▇███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▁▃▃▅▆▇▆▆▆▆▇▅█▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▆▅▇▇▇▇██▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▅▄▁▅▅▇▇▅▆▄▄█▄</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▂▄▇▄▆▄▅▆▆▇█▄█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▅▆▇▆▇▇██▇██</td></tr><tr><td>Validation F1</td><td>▁▃▄▅▅▆▇▆▇▇██▇██</td></tr><tr><td>Validation Loss</td><td>█▆▅▃▄▂▂▃▂▂▁▁▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▅▆▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.68928</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.60177</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.80657</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.57582</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.60704</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.54766</td></tr><tr><td>Class_Negative_F1</td><td>0.71542</td></tr><tr><td>Class_Negative_Precision</td><td>0.769</td></tr><tr><td>Class_Negative_Recall</td><td>0.66883</td></tr><tr><td>Class_Neutral_F1</td><td>0.57744</td></tr><tr><td>Class_Neutral_Precision</td><td>0.60499</td></tr><tr><td>Class_Neutral_Recall</td><td>0.5523</td></tr><tr><td>Class_Positive_F1</td><td>0.69941</td></tr><tr><td>Class_Positive_Precision</td><td>0.64942</td></tr><tr><td>Class_Positive_Recall</td><td>0.75774</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.71669</td></tr><tr><td>Train Loss</td><td>0.70871</td></tr><tr><td>Validation Accuracy</td><td>0.63994</td></tr><tr><td>Validation F1</td><td>0.65148</td></tr><tr><td>Validation Loss</td><td>0.90841</td></tr><tr><td>Validation Precision</td><td>0.64644</td></tr><tr><td>Validation Recall</td><td>0.66662</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9imeczki' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/9imeczki</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_205459-9imeczki/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 21:17:13,003] Trial 4 finished with value: 0.6451652089407192 and parameters: {'learning_rate': 2.0156198010548755e-05, 'weight_decay': 1.2476254750479197e-06, 'patience': 7, 'batch_size': 64, 'num_layers': 2, 'dropout_rate': 0.1, 'gradient_clip_val': 2.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_211713-t4c2ij4a</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/t4c2ij4a' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/t4c2ij4a' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/t4c2ij4a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4083, Val Acc: 0.4608, Val F1: 0.4708, Gap: -0.0524\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4699, Val Acc: 0.4939, Val F1: 0.5064, Gap: -0.0241\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4997, Val Acc: 0.5170, Val F1: 0.5294, Gap: -0.0173\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.5146, Val Acc: 0.5318, Val F1: 0.5446, Gap: -0.0172\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.5274, Val Acc: 0.5380, Val F1: 0.5504, Gap: -0.0106\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.5388, Val Acc: 0.5500, Val F1: 0.5625, Gap: -0.0112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.5455, Val Acc: 0.5517, Val F1: 0.5653, Gap: -0.0063\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.5533, Val Acc: 0.5674, Val F1: 0.5812, Gap: -0.0141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.5596, Val Acc: 0.5560, Val F1: 0.5688, Gap: 0.0036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.5655, Val Acc: 0.5786, Val F1: 0.5922, Gap: -0.0131\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.5740, Val Acc: 0.5802, Val F1: 0.5940, Gap: -0.0062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.5774, Val Acc: 0.5826, Val F1: 0.5969, Gap: -0.0052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.5832, Val Acc: 0.5860, Val F1: 0.6004, Gap: -0.0028\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5902, Val Acc: 0.5899, Val F1: 0.6038, Gap: 0.0003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.5947, Val Acc: 0.5915, Val F1: 0.6059, Gap: 0.0032\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▅▆▆▇▇▇▇▇████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▃▇▄█▃▇▃▇▇█▇▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▄▄▃▆▄█▆█▆▇▇▇█▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▅▄▂▅▄▆▃▇▇█▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▂▅▆▅▅▆▆▆▆▅▆██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▂▆▃▁▄▃▆▂▆▆█▆▄▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▄▄▅▆▆▆▆▇█▇▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▄▄▃▂▅▆▆▅▅▆█▇▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▂▄▆█▅▄▅▇█▇▄▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▃▆▆▆▆▇▆█▇▆███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▃▄▅▆▆▅▇▇█▇▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▂▇▇▆▅█▆▇▆▄██▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▅▆▇▆▇▇▇████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▅▆▆▇▆▇▅███▇▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▂▂▂▂▁▂▅▃█▃▄▅▆▇█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▅▆▆▇▆▇▇████</td></tr><tr><td>Validation F1</td><td>▁▃▄▅▅▆▆▇▆▇▇████</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▅▆▆▇▆▇▇████</td></tr><tr><td>Validation Recall</td><td>▁▃▄▄▅▆▆▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.65926</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.60045</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.73084</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.54401</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.55381</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.53454</td></tr><tr><td>Class_Negative_F1</td><td>0.65893</td></tr><tr><td>Class_Negative_Precision</td><td>0.72022</td></tr><tr><td>Class_Negative_Recall</td><td>0.60726</td></tr><tr><td>Class_Neutral_F1</td><td>0.52238</td></tr><tr><td>Class_Neutral_Precision</td><td>0.52136</td></tr><tr><td>Class_Neutral_Recall</td><td>0.52341</td></tr><tr><td>Class_Positive_F1</td><td>0.6448</td></tr><tr><td>Class_Positive_Precision</td><td>0.62995</td></tr><tr><td>Class_Positive_Recall</td><td>0.66038</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.59468</td></tr><tr><td>Train Loss</td><td>0.96981</td></tr><tr><td>Validation Accuracy</td><td>0.59147</td></tr><tr><td>Validation F1</td><td>0.60588</td></tr><tr><td>Validation Loss</td><td>0.97424</td></tr><tr><td>Validation Precision</td><td>0.60516</td></tr><tr><td>Validation Recall</td><td>0.61129</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/t4c2ij4a' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/t4c2ij4a</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_211713-t4c2ij4a/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 21:40:30,509] Trial 5 finished with value: 0.5914723032069971 and parameters: {'learning_rate': 3.738721694490845e-06, 'weight_decay': 2.9756670361944843e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 2, 'dropout_rate': 0.1, 'gradient_clip_val': 2.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_214031-jqngc5cv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jqngc5cv' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jqngc5cv' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jqngc5cv</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4416, Val Acc: 0.5030, Val F1: 0.5151, Gap: -0.0614\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5070, Val Acc: 0.5270, Val F1: 0.5393, Gap: -0.0200\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.5329, Val Acc: 0.5533, Val F1: 0.5671, Gap: -0.0205\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.5578, Val Acc: 0.5722, Val F1: 0.5858, Gap: -0.0143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.5684, Val Acc: 0.5640, Val F1: 0.5778, Gap: 0.0044\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.5816, Val Acc: 0.5888, Val F1: 0.6024, Gap: -0.0072\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.5903, Val Acc: 0.5898, Val F1: 0.6031, Gap: 0.0005\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.6041, Val Acc: 0.5979, Val F1: 0.6115, Gap: 0.0062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.6121, Val Acc: 0.6078, Val F1: 0.6208, Gap: 0.0043\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.6239, Val Acc: 0.6122, Val F1: 0.6243, Gap: 0.0117\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.6325, Val Acc: 0.6099, Val F1: 0.6224, Gap: 0.0226\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.6378, Val Acc: 0.6220, Val F1: 0.6339, Gap: 0.0159\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.6489, Val Acc: 0.6156, Val F1: 0.6293, Gap: 0.0332\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.6558, Val Acc: 0.6199, Val F1: 0.6333, Gap: 0.0359\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.6626, Val Acc: 0.6251, Val F1: 0.6382, Gap: 0.0374\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▆▆▆▆▇█▇▇████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▅▁▆▆▅▆▄▆█▅▄▅▆▆█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▅▃▄▆▆▇▆▆▇█▇▇▇▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▂▁▄▅▃▆▅▆▆▆▅▇▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▃▃▇▅▆▅█▇▆▇▆▇▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▁▅▆▁▅▄▆▄▅▄▅▆▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▄▅▄▆▆▇▇▇▇█▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▂▃▇▅█▆▄▇▇▆██▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▆▁▆▃▆█▆▆█▅▅█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▁▁▃▄▅▅▅▆█▇▇▆▇▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▅▃▅▅▆▅▆▇█▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▄▂▁▂▆▄▅▃▆█▄▅▃▆▃</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▅▆▆▆▆▇▆█████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▂▅▁▅▄▄▆█▆▇▄▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▅▄█▄▆▆▅▄▇▆█▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▄▅▄▆▆▆▇▇▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▂▄▅▅▆▆▆▇▇▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▂▃▅▅▆▆▆▇█▇█▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▅▆▆▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.67497</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.61919</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.74179</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.57511</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.54545</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.60817</td></tr><tr><td>Class_Negative_F1</td><td>0.70702</td></tr><tr><td>Class_Negative_Precision</td><td>0.70634</td></tr><tr><td>Class_Negative_Recall</td><td>0.70771</td></tr><tr><td>Class_Neutral_F1</td><td>0.54576</td></tr><tr><td>Class_Neutral_Precision</td><td>0.60884</td></tr><tr><td>Class_Neutral_Recall</td><td>0.49453</td></tr><tr><td>Class_Positive_F1</td><td>0.68795</td></tr><tr><td>Class_Positive_Precision</td><td>0.69296</td></tr><tr><td>Class_Positive_Recall</td><td>0.68302</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.66257</td></tr><tr><td>Train Loss</td><td>0.8334</td></tr><tr><td>Validation Accuracy</td><td>0.62512</td></tr><tr><td>Validation F1</td><td>0.63816</td></tr><tr><td>Validation Loss</td><td>0.91753</td></tr><tr><td>Validation Precision</td><td>0.63456</td></tr><tr><td>Validation Recall</td><td>0.64704</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jqngc5cv' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jqngc5cv</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_214031-jqngc5cv/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 22:03:46,951] Trial 6 finished with value: 0.6251214771622935 and parameters: {'learning_rate': 8.94385994073447e-06, 'weight_decay': 2.5418440867063426e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 2, 'dropout_rate': 0.2, 'gradient_clip_val': 2.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_220347-37zksnd3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/37zksnd3' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/37zksnd3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/37zksnd3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4771, Val Acc: 0.5643, Val F1: 0.5776, Gap: -0.0872\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.6155, Val Acc: 0.6585, Val F1: 0.6722, Gap: -0.0430\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6771, Val Acc: 0.6685, Val F1: 0.6784, Gap: 0.0086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.7171, Val Acc: 0.7250, Val F1: 0.7351, Gap: -0.0079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7436, Val Acc: 0.7472, Val F1: 0.7561, Gap: -0.0036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7664, Val Acc: 0.7512, Val F1: 0.7597, Gap: 0.0152\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7916, Val Acc: 0.7651, Val F1: 0.7726, Gap: 0.0266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.8056, Val Acc: 0.7798, Val F1: 0.7871, Gap: 0.0258\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8199, Val Acc: 0.7898, Val F1: 0.7966, Gap: 0.0300\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8332, Val Acc: 0.7946, Val F1: 0.8008, Gap: 0.0386\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8437, Val Acc: 0.8072, Val F1: 0.8132, Gap: 0.0365\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8547, Val Acc: 0.8128, Val F1: 0.8190, Gap: 0.0419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8620, Val Acc: 0.8098, Val F1: 0.8152, Gap: 0.0522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8729, Val Acc: 0.8197, Val F1: 0.8256, Gap: 0.0532\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8803, Val Acc: 0.8282, Val F1: 0.8335, Gap: 0.0521\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▃▅▆▆▆▇▇▇▇█▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▂▆▇▆▆▇▇▆▇▇▇██</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▁█▄▃▇▆▆▆█▇▇▇▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▃▅▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▄▆▆▆▇▇█▇█████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▂▅▆▅▆▆▆▆▇▇▇██</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▅▆▆▆▆▇▇██████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▅▅▅▆▇▇▇▇▇▇███</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▆▇▆▆▆▇████▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▅▆▆▆▇▇▇▇█▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▄▅▆▆▆▆▇█▇███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▄▅▆▆▆▇▇▇▇█▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▅▆▆▆▇▇▇█▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▄▄▇▅▅▆▆▇▇▇▆▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▃▄▄▂▆▆▆▇▅▇▆██▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>Validation F1</td><td>▁▄▄▅▆▆▆▇▇▇▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▄▄▅▆▆▆▇▇▇▇█▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▆▆▆▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83291</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.7816</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89142</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.78267</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.77723</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.7882</td></tr><tr><td>Class_Negative_F1</td><td>0.86459</td></tr><tr><td>Class_Negative_Precision</td><td>0.91776</td></tr><tr><td>Class_Negative_Recall</td><td>0.81724</td></tr><tr><td>Class_Neutral_F1</td><td>0.82107</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81005</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83239</td></tr><tr><td>Class_Positive_F1</td><td>0.86636</td></tr><tr><td>Class_Positive_Precision</td><td>0.89271</td></tr><tr><td>Class_Positive_Recall</td><td>0.84151</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.88033</td></tr><tr><td>Train Loss</td><td>0.35248</td></tr><tr><td>Validation Accuracy</td><td>0.82823</td></tr><tr><td>Validation F1</td><td>0.83352</td></tr><tr><td>Validation Loss</td><td>0.50274</td></tr><tr><td>Validation Precision</td><td>0.83587</td></tr><tr><td>Validation Recall</td><td>0.83415</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/37zksnd3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/37zksnd3</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_220347-37zksnd3/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 22:44:13,702] Trial 7 finished with value: 0.8282312925170068 and parameters: {'learning_rate': 5.034180645902828e-06, 'weight_decay': 7.233285319732022e-05, 'patience': 5, 'batch_size': 128, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_224414-24cajkya</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/24cajkya' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/24cajkya' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/24cajkya</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.3568, Val Acc: 0.3958, Val F1: 0.3933, Gap: -0.0390\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4145, Val Acc: 0.4223, Val F1: 0.4213, Gap: -0.0078\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4417, Val Acc: 0.4424, Val F1: 0.4422, Gap: -0.0007\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.4583, Val Acc: 0.4513, Val F1: 0.4510, Gap: 0.0070\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.4738, Val Acc: 0.4704, Val F1: 0.4708, Gap: 0.0035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.4827, Val Acc: 0.4902, Val F1: 0.4963, Gap: -0.0075\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.4907, Val Acc: 0.4945, Val F1: 0.4991, Gap: -0.0038\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.5001, Val Acc: 0.5030, Val F1: 0.5089, Gap: -0.0029\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.5056, Val Acc: 0.4956, Val F1: 0.5000, Gap: 0.0099\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.5129, Val Acc: 0.5191, Val F1: 0.5252, Gap: -0.0062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.5179, Val Acc: 0.5168, Val F1: 0.5217, Gap: 0.0011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.5219, Val Acc: 0.5249, Val F1: 0.5304, Gap: -0.0031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.5243, Val Acc: 0.5228, Val F1: 0.5282, Gap: 0.0015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5309, Val Acc: 0.5375, Val F1: 0.5457, Gap: -0.0066\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.5372, Val Acc: 0.5408, Val F1: 0.5494, Gap: -0.0037\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▄▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▃▃▄▆▅▆▄▇▆▇▆█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▁▃▆▅▄▆▅█▅▇▆▇▅▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▂▁▃▅▅▅▄▇▅▇▆██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▃▃▅▆▆▆▅▇▇█▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▂▁▃▅▄▄▄▆▄▆▅█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▄▅▅▆▆▇▆▇█████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▂▅▄▅▅▆█▇▇▇█▆█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▅▄▆▆▆▆▄▆▇▇▆█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▃▄▄▅▅▆▆▆▇▇▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▂▃▄▄▅▅▆▇▇▇▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▃▃▃▅▅▆▅▆▇▆▆▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▃▄▅▅▆▆▇▇▇▇▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▃▄▅▅▆▆▆▆▇▆▆██</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▂▄▅▄▅▅▆█▅██▅▆</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▃▄▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▂▃▄▄▆▆▆▆▇▇▇▇██</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▄▃▃▂▃▂▂▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▂▃▄▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▂▃▄▅▆▆▆▆▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.61416</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.49552</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.80748</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.44534</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.51664</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.39133</td></tr><tr><td>Class_Negative_F1</td><td>0.62934</td></tr><tr><td>Class_Negative_Precision</td><td>0.59323</td></tr><tr><td>Class_Negative_Recall</td><td>0.67012</td></tr><tr><td>Class_Neutral_F1</td><td>0.42003</td></tr><tr><td>Class_Neutral_Precision</td><td>0.52387</td></tr><tr><td>Class_Neutral_Recall</td><td>0.35055</td></tr><tr><td>Class_Positive_F1</td><td>0.63797</td></tr><tr><td>Class_Positive_Precision</td><td>0.57177</td></tr><tr><td>Class_Positive_Recall</td><td>0.72151</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.53716</td></tr><tr><td>Train Loss</td><td>1.00955</td></tr><tr><td>Validation Accuracy</td><td>0.54082</td></tr><tr><td>Validation F1</td><td>0.54937</td></tr><tr><td>Validation Loss</td><td>1.00043</td></tr><tr><td>Validation Precision</td><td>0.54021</td></tr><tr><td>Validation Recall</td><td>0.5882</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/24cajkya' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/24cajkya</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_224414-24cajkya/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 23:06:20,681] Trial 8 finished with value: 0.5408163265306123 and parameters: {'learning_rate': 2.7395640591791997e-06, 'weight_decay': 2.0312194351073092e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 2, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_230621-izh7j5ji</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/izh7j5ji' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/izh7j5ji' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/izh7j5ji</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4000, Val Acc: 0.4377, Val F1: 0.4363, Gap: -0.0377\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.4447, Val Acc: 0.4626, Val F1: 0.4716, Gap: -0.0179\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.4577, Val Acc: 0.4746, Val F1: 0.4845, Gap: -0.0169\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.4698, Val Acc: 0.4841, Val F1: 0.4912, Gap: -0.0143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.4801, Val Acc: 0.4834, Val F1: 0.4925, Gap: -0.0032\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.4903, Val Acc: 0.4976, Val F1: 0.5097, Gap: -0.0073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.4981, Val Acc: 0.4996, Val F1: 0.5110, Gap: -0.0015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.5019, Val Acc: 0.5024, Val F1: 0.5131, Gap: -0.0006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.5093, Val Acc: 0.5131, Val F1: 0.5254, Gap: -0.0038\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.5128, Val Acc: 0.5188, Val F1: 0.5308, Gap: -0.0060\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.5165, Val Acc: 0.5180, Val F1: 0.5301, Gap: -0.0015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.5222, Val Acc: 0.5276, Val F1: 0.5411, Gap: -0.0054\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.5261, Val Acc: 0.5300, Val F1: 0.5431, Gap: -0.0039\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.5328, Val Acc: 0.5338, Val F1: 0.5472, Gap: -0.0009\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.5366, Val Acc: 0.5425, Val F1: 0.5559, Gap: -0.0060\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▅▄▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▆▃▅▇▁▅▇▇▆██▇▇▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▄▄▃▇▆▅▅▆▅▆▇▇██</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▆▄▆▇▁▆▆▅▇█▇▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▅▆▆▆▇▆▅▆▇███</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>█▄▆▇▁▅▅▄▅▇▆▅▅▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▄▄▅▆▆▆▇▇▇▇█▆█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▁▂▅▃▃▅▃▄▅▃▅▅█▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▂▆▆▅▇▇▆█▇▇▄▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▃▅▆▅▅▄▆▆▄▇▇▆█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▁▂▂▂▄▃▄▆▇▇▇▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▃▇█▆▆▅▆▅▃▆▇▅█</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▃▃▄▅▆▇▆▆▇▇▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▃▅▄▄▃▂▆▇▄▇▆▄█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▁▂▁▃▃▆█▃▃▇▄▅█▄</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▃▄▄▅▅▅▆▆▆▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▃▄▄▄▅▅▅▆▇▆▇▇▇█</td></tr><tr><td>Validation Loss</td><td>█▆▆▅▅▄▄▄▃▃▂▂▂▂▁</td></tr><tr><td>Validation Precision</td><td>▁▂▃▅▃▄▅▄▆▇▅▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.59821</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.5405</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.66971</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.47367</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.48771</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.46041</td></tr><tr><td>Class_Negative_F1</td><td>0.60743</td></tr><tr><td>Class_Negative_Precision</td><td>0.63444</td></tr><tr><td>Class_Negative_Recall</td><td>0.58263</td></tr><tr><td>Class_Neutral_F1</td><td>0.49595</td></tr><tr><td>Class_Neutral_Precision</td><td>0.48358</td></tr><tr><td>Class_Neutral_Recall</td><td>0.50897</td></tr><tr><td>Class_Positive_F1</td><td>0.60439</td></tr><tr><td>Class_Positive_Precision</td><td>0.64153</td></tr><tr><td>Class_Positive_Recall</td><td>0.57132</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.53655</td></tr><tr><td>Train Loss</td><td>1.09166</td></tr><tr><td>Validation Accuracy</td><td>0.54252</td></tr><tr><td>Validation F1</td><td>0.55593</td></tr><tr><td>Validation Loss</td><td>1.0755</td></tr><tr><td>Validation Precision</td><td>0.55755</td></tr><tr><td>Validation Recall</td><td>0.55861</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/izh7j5ji' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/izh7j5ji</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_230621-izh7j5ji/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-05 23:26:34,232] Trial 9 finished with value: 0.5425170068027211 and parameters: {'learning_rate': 8.601711190939581e-06, 'weight_decay': 1.992554929762721e-06, 'patience': 5, 'batch_size': 64, 'num_layers': 1, 'dropout_rate': 0.1, 'gradient_clip_val': 2.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_232635-o1l4hmnc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/o1l4hmnc' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/o1l4hmnc' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/o1l4hmnc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4006, Val Acc: 0.4825, Val F1: 0.4793, Gap: -0.0819\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5152, Val Acc: 0.5453, Val F1: 0.5503, Gap: -0.0301\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.5627, Val Acc: 0.5854, Val F1: 0.5941, Gap: -0.0227\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.6036, Val Acc: 0.6143, Val F1: 0.6233, Gap: -0.0107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.6364, Val Acc: 0.6356, Val F1: 0.6460, Gap: 0.0008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.6603, Val Acc: 0.6602, Val F1: 0.6710, Gap: 0.0000\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.6790, Val Acc: 0.6808, Val F1: 0.6908, Gap: -0.0017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.6993, Val Acc: 0.6681, Val F1: 0.6785, Gap: 0.0312\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.7106, Val Acc: 0.7038, Val F1: 0.7146, Gap: 0.0067\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.7269, Val Acc: 0.7114, Val F1: 0.7208, Gap: 0.0155\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.7409, Val Acc: 0.7083, Val F1: 0.7174, Gap: 0.0325\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.7475, Val Acc: 0.7397, Val F1: 0.7485, Gap: 0.0078\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.7592, Val Acc: 0.7398, Val F1: 0.7484, Gap: 0.0194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.7688, Val Acc: 0.7199, Val F1: 0.7280, Gap: 0.0489\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.7763, Val Acc: 0.7422, Val F1: 0.7502, Gap: 0.0341\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▄▅▆▇▆▇▇▇██▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▃▄▅▅▆▅▇▇▆█▇▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▃▄▅▅▅▃▆▃▅█▃▇█▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▄▅▆▇▆▇▇▇██▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▄▅▆▇▆▇█▇████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▄▄▅▆▆▆▇▇▇██▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▃▄▅▆▆▆▇▇▇████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▃▄▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▅▅▃▅▇▄▅▇▇████</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▅▅▆▆▆▇▇▇██▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▅▅▆▆▆▆▇▇▇███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▅▅▆▆▆▇▇▇██▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▅▆▆▆▇▇▇██▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▄▅▅▆▆▅▆▆▇██▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▃▃▁▃▅▄▅▇▆▆▆▆▅█▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇██▇█</td></tr><tr><td>Validation F1</td><td>▁▃▄▅▅▆▆▆▇▇▇██▇█</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▄▃▃▃▂▂▂▁▁▂▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▅▆▆▆▇▇▇██▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▄▄▅▆▆▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.76486</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.65983</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90967</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.6752</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.70065</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.65154</td></tr><tr><td>Class_Negative_F1</td><td>0.80773</td></tr><tr><td>Class_Negative_Precision</td><td>0.84708</td></tr><tr><td>Class_Negative_Recall</td><td>0.77187</td></tr><tr><td>Class_Neutral_F1</td><td>0.70488</td></tr><tr><td>Class_Neutral_Precision</td><td>0.77187</td></tr><tr><td>Class_Neutral_Recall</td><td>0.64858</td></tr><tr><td>Class_Positive_F1</td><td>0.79833</td></tr><tr><td>Class_Positive_Precision</td><td>0.74017</td></tr><tr><td>Class_Positive_Recall</td><td>0.86642</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.77628</td></tr><tr><td>Train Loss</td><td>0.56391</td></tr><tr><td>Validation Accuracy</td><td>0.74223</td></tr><tr><td>Validation F1</td><td>0.7502</td></tr><tr><td>Validation Loss</td><td>0.62432</td></tr><tr><td>Validation Precision</td><td>0.74392</td></tr><tr><td>Validation Recall</td><td>0.76962</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/o1l4hmnc' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/o1l4hmnc</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250805_232635-o1l4hmnc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 00:06:59,184] Trial 10 finished with value: 0.7422254616132167 and parameters: {'learning_rate': 2.0977659162237138e-06, 'weight_decay': 8.443279580892883e-06, 'patience': 5, 'batch_size': 128, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_000700-bqjm9nzg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/bqjm9nzg' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/bqjm9nzg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/bqjm9nzg</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4581, Val Acc: 0.5417, Val F1: 0.5474, Gap: -0.0835\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5832, Val Acc: 0.6131, Val F1: 0.6247, Gap: -0.0299\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6538, Val Acc: 0.6769, Val F1: 0.6884, Gap: -0.0231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.6895, Val Acc: 0.6938, Val F1: 0.7046, Gap: -0.0042\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7267, Val Acc: 0.7134, Val F1: 0.7224, Gap: 0.0133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7526, Val Acc: 0.7470, Val F1: 0.7555, Gap: 0.0056\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7741, Val Acc: 0.7340, Val F1: 0.7407, Gap: 0.0401\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.7912, Val Acc: 0.7332, Val F1: 0.7406, Gap: 0.0580\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.8061, Val Acc: 0.7779, Val F1: 0.7852, Gap: 0.0281\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8175, Val Acc: 0.7975, Val F1: 0.8041, Gap: 0.0200\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8285, Val Acc: 0.7926, Val F1: 0.7996, Gap: 0.0358\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8384, Val Acc: 0.7886, Val F1: 0.7947, Gap: 0.0497\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8514, Val Acc: 0.7877, Val F1: 0.7944, Gap: 0.0637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8566, Val Acc: 0.8111, Val F1: 0.8168, Gap: 0.0455\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8638, Val Acc: 0.8178, Val F1: 0.8240, Gap: 0.0460\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▅▆▅▆▅▄██▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▅▆▅▆▄▃██▇▇▇██</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▆▁▁▆▃▇█▃▂▅▅▅▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▆▅▆▅▅██▇▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▅▅▅▅▅▇▆▆▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▆▅▅▆▅▅▇█▇▇▇██</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▅▆▇▆▇▇▇▇▇████</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▃▃▃▆▅▅▇▇█▇▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▄▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▄▄▆▆▇▇▇▇██▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▄▅▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▄▅▆▆▇▆▇▇▇▆██</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▃▂▄▆▄▅▄▆▇▅▄▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▁▄▆▅▄▆▅▇▆▅▇█▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▃▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▄▃▃▃▂▁▁▁▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.82295</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.75132</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90967</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.76288</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.75295</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77307</td></tr><tr><td>Class_Negative_F1</td><td>0.8595</td></tr><tr><td>Class_Negative_Precision</td><td>0.91447</td></tr><tr><td>Class_Negative_Recall</td><td>0.81076</td></tr><tr><td>Class_Neutral_F1</td><td>0.81082</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81513</td></tr><tr><td>Class_Neutral_Recall</td><td>0.80656</td></tr><tr><td>Class_Positive_F1</td><td>0.86394</td></tr><tr><td>Class_Positive_Precision</td><td>0.89355</td></tr><tr><td>Class_Positive_Recall</td><td>0.83623</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.86378</td></tr><tr><td>Train Loss</td><td>0.36115</td></tr><tr><td>Validation Accuracy</td><td>0.81778</td></tr><tr><td>Validation F1</td><td>0.82402</td></tr><tr><td>Validation Loss</td><td>0.49707</td></tr><tr><td>Validation Precision</td><td>0.82548</td></tr><tr><td>Validation Recall</td><td>0.82726</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/bqjm9nzg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/bqjm9nzg</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_000700-bqjm9nzg/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 00:47:27,259] Trial 11 finished with value: 0.8177842565597667 and parameters: {'learning_rate': 5.055849158972561e-06, 'weight_decay': 9.950327200118423e-05, 'patience': 5, 'batch_size': 128, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_004728-z2cc89go</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/z2cc89go' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/z2cc89go' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/z2cc89go</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.4401, Val Acc: 0.5414, Val F1: 0.5455, Gap: -0.1014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.5781, Val Acc: 0.6069, Val F1: 0.6180, Gap: -0.0288\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.6487, Val Acc: 0.6572, Val F1: 0.6672, Gap: -0.0085\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.6896, Val Acc: 0.6690, Val F1: 0.6783, Gap: 0.0207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.7209, Val Acc: 0.7293, Val F1: 0.7394, Gap: -0.0084\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.7479, Val Acc: 0.7224, Val F1: 0.7313, Gap: 0.0255\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.7651, Val Acc: 0.7371, Val F1: 0.7444, Gap: 0.0280\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.7843, Val Acc: 0.7483, Val F1: 0.7553, Gap: 0.0360\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.7974, Val Acc: 0.7690, Val F1: 0.7772, Gap: 0.0285\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.8112, Val Acc: 0.7880, Val F1: 0.7951, Gap: 0.0232\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.8291, Val Acc: 0.8058, Val F1: 0.8120, Gap: 0.0233\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.8371, Val Acc: 0.7761, Val F1: 0.7829, Gap: 0.0609\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.8424, Val Acc: 0.7957, Val F1: 0.8019, Gap: 0.0468\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.8555, Val Acc: 0.8065, Val F1: 0.8122, Gap: 0.0490\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.8618, Val Acc: 0.7968, Val F1: 0.8026, Gap: 0.0650\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▄▅▆▆▅█▇█▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▃▃▄▅▄▄█▆▇▅▅▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▃▄▆▆▆▇█▁▆▅█▇▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▄▆▆▆▆█▇█▇▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▄▄▆▆▆▇▇█▇▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▃▅▆▆▆▅███▇▇██</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▄▅▆▆▇▇▇▇█████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▄▆▆▆▆▇▇▇▇███▇</td></tr><tr><td>Class_Negative_Recall</td><td>▃▁▅▄▅▆▆▆▇█▇▆▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▄▇▆▆▇▇██▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▅▆▆▆▇▆▇▇▇███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▄▇▅▆▇▆▇█▇██▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▂▄▄▆▅▆▇▆██▇██▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▄▃█▄▅▆▅▇█▅█▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▃▅▅▆▁▇▆▆█▅▅█▆▇█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▄▆▆▆▆▇██▇███</td></tr><tr><td>Validation F1</td><td>▁▃▄▄▆▆▆▇▇██▇███</td></tr><tr><td>Validation Loss</td><td>█▆▅▅▄▃▃▃▂▂▁▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▄▆▆▆▆▇▇█▇███</td></tr><tr><td>Validation Recall</td><td>▁▃▄▄▆▆▆▆▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.81222</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.73363</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90967</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.7591</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.77778</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.7413</td></tr><tr><td>Class_Negative_F1</td><td>0.8559</td></tr><tr><td>Class_Negative_Precision</td><td>0.88842</td></tr><tr><td>Class_Negative_Recall</td><td>0.82566</td></tr><tr><td>Class_Neutral_F1</td><td>0.75943</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83517</td></tr><tr><td>Class_Neutral_Recall</td><td>0.69628</td></tr><tr><td>Class_Positive_F1</td><td>0.82654</td></tr><tr><td>Class_Positive_Precision</td><td>0.74635</td></tr><tr><td>Class_Positive_Recall</td><td>0.92604</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.86178</td></tr><tr><td>Train Loss</td><td>0.37066</td></tr><tr><td>Validation Accuracy</td><td>0.79677</td></tr><tr><td>Validation F1</td><td>0.80264</td></tr><tr><td>Validation Loss</td><td>0.51265</td></tr><tr><td>Validation Precision</td><td>0.79627</td></tr><tr><td>Validation Recall</td><td>0.81979</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/z2cc89go' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/z2cc89go</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_004728-z2cc89go/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 01:28:01,087] Trial 12 finished with value: 0.8064868804664723 and parameters: {'learning_rate': 4.844545807590211e-06, 'weight_decay': 9.638575162952966e-05, 'patience': 5, 'batch_size': 128, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_012802-nyy6vo4p</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/nyy6vo4p' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/nyy6vo4p' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/nyy6vo4p</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5594, Val Acc: 0.6410, Val F1: 0.6539, Gap: -0.0816\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7113, Val Acc: 0.7539, Val F1: 0.7633, Gap: -0.0426\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7752, Val Acc: 0.7845, Val F1: 0.7925, Gap: -0.0093\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8157, Val Acc: 0.7952, Val F1: 0.8011, Gap: 0.0205\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8471, Val Acc: 0.7975, Val F1: 0.8036, Gap: 0.0496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8691, Val Acc: 0.8297, Val F1: 0.8354, Gap: 0.0394\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8850, Val Acc: 0.8252, Val F1: 0.8307, Gap: 0.0598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9011, Val Acc: 0.8110, Val F1: 0.8161, Gap: 0.0901\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9132, Val Acc: 0.8372, Val F1: 0.8423, Gap: 0.0760\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9232, Val Acc: 0.8516, Val F1: 0.8559, Gap: 0.0716\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9337, Val Acc: 0.8360, Val F1: 0.8401, Gap: 0.0977\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9395, Val Acc: 0.8397, Val F1: 0.8434, Gap: 0.0998\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9484, Val Acc: 0.8324, Val F1: 0.8369, Gap: 0.1161\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9519, Val Acc: 0.8409, Val F1: 0.8446, Gap: 0.1110\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9557, Val Acc: 0.8501, Val F1: 0.8543, Gap: 0.1056\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▆▅▅▇▇▆▇█▇▇█▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▅▃▄▇▅▄▇▇▅▇▇▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▁▅▇▇▅▇█▅▆█▇▆▆▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▅▆▇▇▆██▇▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▅▆▆▆▇▆▇▇████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▇▅▄▅█▆▅█▇▆▆▆▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇▇█████▇▇▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▅▅▇▆▇▇▅▄█▄▃▃▄</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▅▆▅▆▇▇▇█▇████</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▆▇▇▇▇███▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▆▇▇▇▇███▇▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▆▇▆█▇▆▇█▇█▇██</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▆▆▇▇▆▇█▇▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁█▆█▅█▆▄▆█▆▆▅▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▄▁▅▄▇▅▇█▇▆▇▇█▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▆▇▇▇██▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▆▇▇▇██▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▄▃▃▃▁▂▃▂▁▂▂▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▅▆▆▆█▇▇██▇▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▆▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8621</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84115</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88412</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81855</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8322</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80535</td></tr><tr><td>Class_Negative_F1</td><td>0.87333</td></tr><tr><td>Class_Negative_Precision</td><td>0.87762</td></tr><tr><td>Class_Negative_Recall</td><td>0.86909</td></tr><tr><td>Class_Neutral_F1</td><td>0.83581</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85979</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81313</td></tr><tr><td>Class_Positive_F1</td><td>0.88166</td></tr><tr><td>Class_Positive_Precision</td><td>0.83764</td></tr><tr><td>Class_Positive_Recall</td><td>0.93057</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95566</td></tr><tr><td>Train Loss</td><td>0.13527</td></tr><tr><td>Validation Accuracy</td><td>0.8501</td></tr><tr><td>Validation F1</td><td>0.85429</td></tr><tr><td>Validation Loss</td><td>0.53973</td></tr><tr><td>Validation Precision</td><td>0.84968</td></tr><tr><td>Validation Recall</td><td>0.86045</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/nyy6vo4p' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/nyy6vo4p</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_012802-nyy6vo4p/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 02:08:31,420] Trial 13 finished with value: 0.8515549076773566 and parameters: {'learning_rate': 1.3840536005324577e-05, 'weight_decay': 3.822031377171922e-05, 'patience': 5, 'batch_size': 128, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8516763848396501.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_020832-b8vweba7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/b8vweba7' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/b8vweba7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/b8vweba7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.5615, Val Acc: 0.6860, Val F1: 0.6914, Gap: -0.1244\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7199, Val Acc: 0.7499, Val F1: 0.7599, Gap: -0.0299\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.7834, Val Acc: 0.7930, Val F1: 0.8004, Gap: -0.0096\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8204, Val Acc: 0.8109, Val F1: 0.8154, Gap: 0.0096\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8532, Val Acc: 0.8228, Val F1: 0.8278, Gap: 0.0304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.8757, Val Acc: 0.8235, Val F1: 0.8292, Gap: 0.0522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.8943, Val Acc: 0.8382, Val F1: 0.8434, Gap: 0.0561\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9089, Val Acc: 0.8370, Val F1: 0.8414, Gap: 0.0719\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9172, Val Acc: 0.8387, Val F1: 0.8444, Gap: 0.0785\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9269, Val Acc: 0.8202, Val F1: 0.8261, Gap: 0.1067\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9373, Val Acc: 0.8361, Val F1: 0.8393, Gap: 0.1012\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9455, Val Acc: 0.8313, Val F1: 0.8361, Gap: 0.1142\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9503, Val Acc: 0.8375, Val F1: 0.8412, Gap: 0.1128\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9550, Val Acc: 0.8554, Val F1: 0.8588, Gap: 0.0995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9592, Val Acc: 0.8503, Val F1: 0.8545, Gap: 0.1089\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▅▇▇█▇█▇▆▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▅▅▄█▂▄▆▃▆▃▁▄▄▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▄▆▄▇▇▇▇▇▇██▇▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▆▆▇▇▇▇▇▆▇▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅▅▇▇▇▇█▇████▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▁▅▇▄▆▇▆▆▅▃▄▅█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▇███▇██▇▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆▇▇▇▇███▇▇▆▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▃▂▃▆▆▅▃▅▆▆██▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▄▆▇▆▇▇▇▆█▆▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▆▅▆▇▇▇▆▇▇▇██▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▁▂█▆▃▅▅█▃▇▅▅▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▇▇▆▇▇█▆█▇▇██</td></tr><tr><td>Class_Positive_Precision</td><td>█▁▂█▆▁▄▅▆▁▆▃▄▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▇▆▇███▇█▇██▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>Validation Loss</td><td>█▅▃▂▂▂▁▁▁▃▂▃▃▂▃</td></tr><tr><td>Validation Precision</td><td>▁▃▅▇▆▆▇▇█▆▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▇▇▇█▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86093</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83405</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8896</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81687</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8336</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80081</td></tr><tr><td>Class_Negative_F1</td><td>0.86706</td></tr><tr><td>Class_Negative_Precision</td><td>0.88521</td></tr><tr><td>Class_Negative_Recall</td><td>0.84964</td></tr><tr><td>Class_Neutral_F1</td><td>0.84245</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83219</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85295</td></tr><tr><td>Class_Positive_F1</td><td>0.88496</td></tr><tr><td>Class_Positive_Precision</td><td>0.88165</td></tr><tr><td>Class_Positive_Recall</td><td>0.8883</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95924</td></tr><tr><td>Train Loss</td><td>0.12379</td></tr><tr><td>Validation Accuracy</td><td>0.85034</td></tr><tr><td>Validation F1</td><td>0.85445</td></tr><tr><td>Validation Loss</td><td>0.56599</td></tr><tr><td>Validation Precision</td><td>0.85334</td></tr><tr><td>Validation Recall</td><td>0.85626</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_14</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/b8vweba7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/b8vweba7</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_020832-b8vweba7/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 02:49:05,581] Trial 14 finished with value: 0.8554421768707483 and parameters: {'learning_rate': 1.4790519588547381e-05, 'weight_decay': 1.4535186211372884e-05, 'patience': 5, 'batch_size': 128, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 14 with value: 0.8554421768707483.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_024906-sl5hlkfr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/sl5hlkfr' target=\"_blank\">trial_15</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/sl5hlkfr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/sl5hlkfr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6077, Val Acc: 0.6760, Val F1: 0.6841, Gap: -0.0684\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7731, Val Acc: 0.7821, Val F1: 0.7882, Gap: -0.0090\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8357, Val Acc: 0.8200, Val F1: 0.8266, Gap: 0.0157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8700, Val Acc: 0.8373, Val F1: 0.8431, Gap: 0.0327\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8931, Val Acc: 0.8379, Val F1: 0.8437, Gap: 0.0551\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9115, Val Acc: 0.8245, Val F1: 0.8284, Gap: 0.0871\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9280, Val Acc: 0.8401, Val F1: 0.8438, Gap: 0.0878\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9375, Val Acc: 0.8497, Val F1: 0.8535, Gap: 0.0878\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9465, Val Acc: 0.8409, Val F1: 0.8439, Gap: 0.1056\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9517, Val Acc: 0.8672, Val F1: 0.8707, Gap: 0.0845\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9543, Val Acc: 0.8614, Val F1: 0.8650, Gap: 0.0929\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9604, Val Acc: 0.8570, Val F1: 0.8614, Gap: 0.1034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9628, Val Acc: 0.8595, Val F1: 0.8641, Gap: 0.1033\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9691, Val Acc: 0.8542, Val F1: 0.8575, Gap: 0.1148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9719, Val Acc: 0.8537, Val F1: 0.8571, Gap: 0.1182\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▇▇▇▆▆▇▆██████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▆▆▆▄▅▆▅█▇█▇▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▆▃▃▄██▇▇▂▂▁▃▅▂</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▇▇▇▆▇▇▇██████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▆▅▆▆▆▆█▇▇▆▇▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▇█▇▅▆▇▆████▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇▆▇█▇█▇▆▇▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▇██▆▆▇▄▅▃▄▅▄▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▃▄▄▄▄▆▇▇▆▆▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▇▇▇█▇█████▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▆▆▆▇▆▇▇█▇▆▄█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▆▇▆▆▇▇▆▇▇▇▇█▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▇▇▇▇█▇████▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▄▆▅▅▆▇▅▆▆▆▆█▅</td></tr><tr><td>Class_Positive_Recall</td><td>▅▅▇▅▇▆▆▄▇▇▇▇▆▁█</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇▆▇▇▇██████</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▇▆▇▇▇█████▇</td></tr><tr><td>Validation Loss</td><td>█▃▁▁▁▂▃▂▄▂▃▄▅█▇</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇▆▇▇▇█████▇</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▇▆▇▇▇████▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8705</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85816</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88321</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84104</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86267</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82047</td></tr><tr><td>Class_Negative_F1</td><td>0.87563</td></tr><tr><td>Class_Negative_Precision</td><td>0.85354</td></tr><tr><td>Class_Negative_Recall</td><td>0.8989</td></tr><tr><td>Class_Neutral_F1</td><td>0.83087</td></tr><tr><td>Class_Neutral_Precision</td><td>0.89535</td></tr><tr><td>Class_Neutral_Recall</td><td>0.77505</td></tr><tr><td>Class_Positive_F1</td><td>0.86735</td></tr><tr><td>Class_Positive_Precision</td><td>0.78947</td></tr><tr><td>Class_Positive_Recall</td><td>0.96226</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97191</td></tr><tr><td>Train Loss</td><td>0.09702</td></tr><tr><td>Validation Accuracy</td><td>0.85374</td></tr><tr><td>Validation F1</td><td>0.85708</td></tr><tr><td>Validation Loss</td><td>0.70011</td></tr><tr><td>Validation Precision</td><td>0.85184</td></tr><tr><td>Validation Recall</td><td>0.86798</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_15</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/sl5hlkfr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/sl5hlkfr</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_024906-sl5hlkfr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 03:33:32,095] Trial 15 finished with value: 0.8672254616132167 and parameters: {'learning_rate': 1.4197883401156393e-05, 'weight_decay': 8.35291387420277e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 15 with value: 0.8672254616132167.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_033333-jc2rkn4h</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jc2rkn4h' target=\"_blank\">trial_16</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jc2rkn4h' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jc2rkn4h</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6072, Val Acc: 0.7244, Val F1: 0.7334, Gap: -0.1171\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7764, Val Acc: 0.8033, Val F1: 0.8091, Gap: -0.0270\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8375, Val Acc: 0.7926, Val F1: 0.7972, Gap: 0.0449\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8733, Val Acc: 0.8292, Val F1: 0.8341, Gap: 0.0441\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8983, Val Acc: 0.8512, Val F1: 0.8560, Gap: 0.0471\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9167, Val Acc: 0.8466, Val F1: 0.8502, Gap: 0.0701\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9296, Val Acc: 0.8508, Val F1: 0.8543, Gap: 0.0788\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9394, Val Acc: 0.8641, Val F1: 0.8677, Gap: 0.0753\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9465, Val Acc: 0.8365, Val F1: 0.8405, Gap: 0.1100\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9529, Val Acc: 0.8477, Val F1: 0.8511, Gap: 0.1052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9578, Val Acc: 0.8512, Val F1: 0.8539, Gap: 0.1066\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9627, Val Acc: 0.8449, Val F1: 0.8487, Gap: 0.1179\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9675, Val Acc: 0.8479, Val F1: 0.8515, Gap: 0.1196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9696, Val Acc: 0.8595, Val F1: 0.8628, Gap: 0.1102\n","Early stopping at epoch 14\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▂▆▇▇▇█▆▆▇▇▆▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▄▁▄▆▅▆█▅▅▅▇▅▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▃█▅▄▄▅▁▄▆▅▂▆▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▃▆▇▇▇█▆▆▇▇▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▄▆▅▇█▇▇▆█▇▆▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▁▅▇▆▅█▅▅▅▆▅▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▇█▇▆█▇█▇▅▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▃▅▇██▄▂▆▅▅▁▁▄▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▅▅▇▇▇▆▇█▇▇▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▅▆▇▇██▇▇█▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▇▆▆▇▆▆▆█▇▆█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▄▆▇▇▇█▆▆▇▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▅▆▇▇██▆█████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▄▅▇▆▇▇▄▆▇▆▇█</td></tr><tr><td>Class_Positive_Recall</td><td>▃▅▇▆▃▅▃▅█▇▂▆▅▁</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▄▆▇▇▇█▇▇▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▄▆▇▇▇█▇▇▇▇▇█</td></tr><tr><td>Validation Loss</td><td>▇▃▃▁▁▁▂▂▅▄▅▇██</td></tr><tr><td>Validation Precision</td><td>▁▅▄▆▇▇▇█▆▇▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▅▇▇▇██▇██▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86097</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81721</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90967</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81983</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83109</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80888</td></tr><tr><td>Class_Negative_F1</td><td>0.88478</td></tr><tr><td>Class_Negative_Precision</td><td>0.88622</td></tr><tr><td>Class_Negative_Recall</td><td>0.88334</td></tr><tr><td>Class_Neutral_F1</td><td>0.85826</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85399</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86258</td></tr><tr><td>Class_Positive_F1</td><td>0.89028</td></tr><tr><td>Class_Positive_Precision</td><td>0.92233</td></tr><tr><td>Class_Positive_Recall</td><td>0.86038</td></tr><tr><td>Epoch</td><td>14</td></tr><tr><td>Train Accuracy</td><td>0.96963</td></tr><tr><td>Train Loss</td><td>0.0991</td></tr><tr><td>Validation Accuracy</td><td>0.85945</td></tr><tr><td>Validation F1</td><td>0.86282</td></tr><tr><td>Validation Loss</td><td>0.68363</td></tr><tr><td>Validation Precision</td><td>0.86217</td></tr><tr><td>Validation Recall</td><td>0.86497</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_16</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jc2rkn4h' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/jc2rkn4h</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_033333-jc2rkn4h/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 04:14:59,803] Trial 16 finished with value: 0.864067055393586 and parameters: {'learning_rate': 1.4532601014507231e-05, 'weight_decay': 1.2377529921930222e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 15 with value: 0.8672254616132167.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_041500-kbkr4it5</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/kbkr4it5' target=\"_blank\">trial_17</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/kbkr4it5' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/kbkr4it5</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6710, Val Acc: 0.7587, Val F1: 0.7619, Gap: -0.0878\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8179, Val Acc: 0.8111, Val F1: 0.8158, Gap: 0.0068\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8703, Val Acc: 0.8354, Val F1: 0.8399, Gap: 0.0349\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8972, Val Acc: 0.8533, Val F1: 0.8556, Gap: 0.0440\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9194, Val Acc: 0.8489, Val F1: 0.8517, Gap: 0.0705\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9336, Val Acc: 0.8526, Val F1: 0.8563, Gap: 0.0810\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9435, Val Acc: 0.8496, Val F1: 0.8524, Gap: 0.0939\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9497, Val Acc: 0.8474, Val F1: 0.8511, Gap: 0.1023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9551, Val Acc: 0.8562, Val F1: 0.8588, Gap: 0.0989\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9596, Val Acc: 0.8615, Val F1: 0.8649, Gap: 0.0981\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9637, Val Acc: 0.8562, Val F1: 0.8597, Gap: 0.1075\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9670, Val Acc: 0.8523, Val F1: 0.8563, Gap: 0.1147\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9705, Val Acc: 0.8598, Val F1: 0.8626, Gap: 0.1107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9727, Val Acc: 0.8620, Val F1: 0.8643, Gap: 0.1107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9745, Val Acc: 0.8586, Val F1: 0.8616, Gap: 0.1159\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▇▇▆▇▇▇▇▇██▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▅█▅▆▅▇▆▇▆▇▇▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>██▇▁▇▆▇▅▆▄▆▆▄▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆█▇▇▇▇▇██████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▆▄▅▄▆▄█▄▇▅▄▆▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▅█▆▇▆█▆█▇▇█▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▅▆█▆▅▅▅▇▇▄▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▂▇█▇▆▆▃▃▁▆▅▅▇▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▂▁▃▅▄▆▅█▅▆▃▄▅▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▇▇█▇▆██▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▁▂▇▄▆█▄▃▅▂▄▃▂</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▆▇▅▇▆▃▇█▅▇▇██</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▇▇█▇▆██▇▆▇▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▄▆▄█▅▃▇█▄█▇▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▄▇▆▅▇▃▆█▄▃▇▁▃▃▃</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇▇▇▇███▇███</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▇▇▇▇███▇███</td></tr><tr><td>Validation Loss</td><td>▄▂▁▂▁▂▃▃▃▃▅▆▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▄▆█▆▇▆▇▇█▇▇███</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆█▇▇▇█▇█▇▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86019</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83751</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88412</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83075</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86597</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79829</td></tr><tr><td>Class_Negative_F1</td><td>0.89035</td></tr><tr><td>Class_Negative_Precision</td><td>0.9022</td></tr><tr><td>Class_Negative_Recall</td><td>0.87881</td></tr><tr><td>Class_Neutral_F1</td><td>0.85031</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8161</td></tr><tr><td>Class_Neutral_Recall</td><td>0.88753</td></tr><tr><td>Class_Positive_F1</td><td>0.87616</td></tr><tr><td>Class_Positive_Precision</td><td>0.89913</td></tr><tr><td>Class_Positive_Recall</td><td>0.85434</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.97455</td></tr><tr><td>Train Loss</td><td>0.09143</td></tr><tr><td>Validation Accuracy</td><td>0.8586</td></tr><tr><td>Validation F1</td><td>0.86155</td></tr><tr><td>Validation Loss</td><td>0.80666</td></tr><tr><td>Validation Precision</td><td>0.86418</td></tr><tr><td>Validation Recall</td><td>0.86062</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_17</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/kbkr4it5' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/kbkr4it5</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_041500-kbkr4it5/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 04:59:24,479] Trial 17 finished with value: 0.8620019436345967 and parameters: {'learning_rate': 3.627095231260252e-05, 'weight_decay': 5.135762740036434e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 15 with value: 0.8672254616132167.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_045925-4dxyle5v</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/4dxyle5v' target=\"_blank\">trial_18</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/4dxyle5v' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/4dxyle5v</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6492, Val Acc: 0.7733, Val F1: 0.7807, Gap: -0.1241\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.8096, Val Acc: 0.8147, Val F1: 0.8187, Gap: -0.0052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8647, Val Acc: 0.8354, Val F1: 0.8384, Gap: 0.0293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8981, Val Acc: 0.7994, Val F1: 0.8046, Gap: 0.0987\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.9191, Val Acc: 0.8370, Val F1: 0.8401, Gap: 0.0821\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9329, Val Acc: 0.8610, Val F1: 0.8645, Gap: 0.0718\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9439, Val Acc: 0.8553, Val F1: 0.8587, Gap: 0.0886\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9511, Val Acc: 0.8533, Val F1: 0.8564, Gap: 0.0979\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9587, Val Acc: 0.8478, Val F1: 0.8518, Gap: 0.1109\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9629, Val Acc: 0.8423, Val F1: 0.8460, Gap: 0.1206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9665, Val Acc: 0.8376, Val F1: 0.8416, Gap: 0.1289\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9701, Val Acc: 0.8576, Val F1: 0.8605, Gap: 0.1124\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9745, Val Acc: 0.8595, Val F1: 0.8634, Gap: 0.1150\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9770, Val Acc: 0.8471, Val F1: 0.8501, Gap: 0.1300\n","Early stopping at epoch 14\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▅▃▅██▇█▇▆██▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▁▃▁▃▇▆▅█▆▄▇▇▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂█▆█▆▂▄▅▁▃▅▄▃▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▅▃▅█▇▇█▆▆▇▇▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃█▅▆▅▅▅▄▂▄█▃▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▃▂▄▇▆▆█▇▅▅█▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆█▆▇▆▆█▄▆▄█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▁▇▄▇▄▆▆▆█▅▆▁█▅</td></tr><tr><td>Class_Negative_Recall</td><td>▂▂▅▃▆▅▂▃▃▁▃█▂▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▂▆▇▇█▆▇▆██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▄▇█▇▆▆▇▅▇▇▇▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▅█▁▄▆▇█▄█▄█▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▂▅▅▁▆█▇▇▄▅▅█▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▄▄▇▁▄▅▆▇▃█▄▇▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▃▆▂█▇▇▅▄█▁▇▅▅▅</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▃▆██▇▇▇▆██▇</td></tr><tr><td>Validation F1</td><td>▁▄▆▃▆██▇▇▆▆██▇</td></tr><tr><td>Validation Loss</td><td>▄▁▁▃▂▁▃▄▅██▆█▇</td></tr><tr><td>Validation Precision</td><td>▁▄▆▃▅█▇▇▇▇▆▇█▆</td></tr><tr><td>Validation Recall</td><td>▁▅▆▅▇█▇▇▇▆▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84379</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.78342</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91423</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80199</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83315</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77307</td></tr><tr><td>Class_Negative_F1</td><td>0.87125</td></tr><tr><td>Class_Negative_Precision</td><td>0.88554</td></tr><tr><td>Class_Negative_Recall</td><td>0.85742</td></tr><tr><td>Class_Neutral_F1</td><td>0.84789</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84807</td></tr><tr><td>Class_Neutral_Recall</td><td>0.8477</td></tr><tr><td>Class_Positive_F1</td><td>0.88571</td></tr><tr><td>Class_Positive_Precision</td><td>0.8824</td></tr><tr><td>Class_Positive_Recall</td><td>0.88906</td></tr><tr><td>Epoch</td><td>14</td></tr><tr><td>Train Accuracy</td><td>0.97704</td></tr><tr><td>Train Loss</td><td>0.08648</td></tr><tr><td>Validation Accuracy</td><td>0.84706</td></tr><tr><td>Validation F1</td><td>0.85013</td></tr><tr><td>Validation Loss</td><td>0.70325</td></tr><tr><td>Validation Precision</td><td>0.84652</td></tr><tr><td>Validation Recall</td><td>0.8563</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_18</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/4dxyle5v' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/4dxyle5v</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_045925-4dxyle5v/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 05:40:50,424] Trial 18 finished with value: 0.8610301263362488 and parameters: {'learning_rate': 2.616532625598506e-05, 'weight_decay': 5.744571289414682e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 15 with value: 0.8672254616132167.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 32925 samples\n","Label distribution: [4385 7934 6170 9137 5299]\n","Class weights computed:\n","Extremely Negative (0): 1.502\n","Extremely Positive (1): 0.830\n","Negative (2): 1.067\n","Neutral (3): 0.721\n","Positive (4): 1.243\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_054051-tke0jgin</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/tke0jgin' target=\"_blank\">trial_19</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/tke0jgin' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/tke0jgin</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/15: Train Acc: 0.6034, Val Acc: 0.6836, Val F1: 0.6959, Gap: -0.0801\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/15: Train Acc: 0.7673, Val Acc: 0.7587, Val F1: 0.7645, Gap: 0.0086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/15: Train Acc: 0.8249, Val Acc: 0.8181, Val F1: 0.8235, Gap: 0.0068\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/15: Train Acc: 0.8644, Val Acc: 0.8372, Val F1: 0.8419, Gap: 0.0272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/15: Train Acc: 0.8862, Val Acc: 0.8345, Val F1: 0.8391, Gap: 0.0517\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/15: Train Acc: 0.9017, Val Acc: 0.8522, Val F1: 0.8565, Gap: 0.0496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/15: Train Acc: 0.9135, Val Acc: 0.8494, Val F1: 0.8538, Gap: 0.0642\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/15: Train Acc: 0.9218, Val Acc: 0.8575, Val F1: 0.8618, Gap: 0.0643\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/15: Train Acc: 0.9290, Val Acc: 0.8444, Val F1: 0.8484, Gap: 0.0846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/15: Train Acc: 0.9378, Val Acc: 0.8410, Val F1: 0.8443, Gap: 0.0968\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/15: Train Acc: 0.9389, Val Acc: 0.8620, Val F1: 0.8654, Gap: 0.0769\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/15: Train Acc: 0.9456, Val Acc: 0.8557, Val F1: 0.8593, Gap: 0.0899\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/15: Train Acc: 0.9464, Val Acc: 0.8587, Val F1: 0.8625, Gap: 0.0876\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/15: Train Acc: 0.9506, Val Acc: 0.8593, Val F1: 0.8628, Gap: 0.0913\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/15: Train Acc: 0.9533, Val Acc: 0.8625, Val F1: 0.8656, Gap: 0.0909\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▁▅▆▅▇▇▇▆▅▇▇█▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁▄▄▃▇▆▆▅▃▆█▇▆█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▇▄▆█▃▅▆▇█▅▁▄▅▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▅▆▅█▇█▇▆█████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▄▅▅▆▆▆▇▆▇▇█▆▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▁▅▆▅█▇▇▆▅▇▇▆▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇▇█▇██▇██▇▆▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▅▄▇▇█▂▇▇▄█▅▃▁▄▃</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▆▆▆█▆▇▇▆▇██▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▇▇▇▇▇█▇██████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▅▇▇█▇▇▇▇▇▇▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▇▇▇▇▇▇▇██████</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▇█▇▇█▇██▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▇█▇▆▆▇▆██▆▇██</td></tr><tr><td>Class_Positive_Recall</td><td>▆▇▁▃▆█▇▆█▄▆██▅▅</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▇▇█▇█▇▇█████</td></tr><tr><td>Validation F1</td><td>▁▄▆▇▇███▇▇█████</td></tr><tr><td>Validation Loss</td><td>█▅▃▂▂▁▁▁▂▄▂▄▂▃▃</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇▇▇▇█▇▇█████</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇████▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86426</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.89061</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.83942</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83608</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82863</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84367</td></tr><tr><td>Class_Negative_F1</td><td>0.86671</td></tr><tr><td>Class_Negative_Precision</td><td>0.85311</td></tr><tr><td>Class_Negative_Recall</td><td>0.88075</td></tr><tr><td>Class_Neutral_F1</td><td>0.85989</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85764</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86214</td></tr><tr><td>Class_Positive_F1</td><td>0.90096</td></tr><tr><td>Class_Positive_Precision</td><td>0.91318</td></tr><tr><td>Class_Positive_Recall</td><td>0.88906</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Train Accuracy</td><td>0.95335</td></tr><tr><td>Train Loss</td><td>0.13859</td></tr><tr><td>Validation Accuracy</td><td>0.86249</td></tr><tr><td>Validation F1</td><td>0.86558</td></tr><tr><td>Validation Loss</td><td>0.48855</td></tr><tr><td>Validation Precision</td><td>0.86863</td></tr><tr><td>Validation Recall</td><td>0.86301</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_19</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/tke0jgin' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555/runs/tke0jgin</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_555</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_054051-tke0jgin/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 06:25:14,479] Trial 19 finished with value: 0.8624878522837707 and parameters: {'learning_rate': 1.2719263243273816e-05, 'weight_decay': 4.624614331332635e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 15 with value: 0.8672254616132167.\n"]},{"name":"stdout","output_type":"stream","text":["\n"," Best Results:\n","Validation Accuracy: 0.8672\n","Best hyperparameters:\n","  learning_rate: 1.4197883401156393e-05\n","  weight_decay: 8.35291387420277e-06\n","  patience: 5\n","  batch_size: 32\n","  num_layers: 0\n","  dropout_rate: 0.4\n","  gradient_clip_val: 0.5\n","  use_class_weights: True\n","\n","Best model saved: best_model_trial_15.pt\n"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 5:\")\n","study5 = optuna.create_study(direction=\"maximize\")\n","study5.optimize(objective, n_trials=20)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study5.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model5.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"fosZ8SfGwRzx"},"source":["## **Study 5 – Evaluation of Dirty Data**\n","\n","**Objective:**\n","To assess whether training on uncleaned (dirty) text data improves recall performance, particularly in the weaker sentiment classes.\n","\n","### General Performance Summary:\n","\n","| Metric               | Study 0 (Clean) | Study 5 (Dirty) | Change     |\n","| -------------------- | --------------- | --------------- | ---------- |\n","| Validation F1        | 86.79%          | 86.71%          | −0.08%     |\n","| Validation Precision | 87.85%          | 89.72%          | +1.87%     |\n","| Validation Recall    | 85.98%          | 83.97%          | −2.01%     |\n","| Validation Loss      | 0.8504          | 0.7374          | Improved   |\n","| Overfitting Gap      | 11.35%          | 11.57%          | Slightly ↑ |\n","\n","**Per-Class Impact (Recall):**\n","\n","* Neutral: 0.893 → 0.858 (−0.035)\n","* Extremely Positive: 0.845 → 0.827 (−0.018)\n","* Extremely Negative: 0.894 → 0.853 (−0.041)\n","\n","**Interpretation:**\n","While precision improved across all classes, recall decreased significantly in most. Overall F1 remained nearly unchanged, indicating that using noisy input data shifted the model toward conservative predictions, with fewer false positives but more false negatives. Dirty data did not significantly improve overall performance and introduced a trade-off that may not be beneficial for minority class detection.\n","\n","---\n","\n","## **Rationale for Continued Augmentation**\n","\n","Previous experiments (notably Study 3) showed that class-specific augmentation:\n","\n","* Improved recall in underperforming classes (e.g., Neutral, Extremely Positive)\n","* Reduced variation across trials\n","* Did not outperform the best-case result from Study 0, but improved generalization\n","\n","**Conclusion:**\n","While augmentation does not always lead to a new best score, it **consistently enhances model robustness** and recall for weaker classes. Therefore, it remains a valuable component, especially when applied selectively and proportionally to targeted classes.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1024,"status":"ok","timestamp":1754831651539,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"ENwyphVX48ws","outputId":"655deb56-444d-4307-e966-e5830496c959"},"outputs":[{"output_type":"stream","name":"stdout","text":["Label counts BEFORE augmentation:\n","Sentiment\n","Positive              9137\n","Neutral               8173\n","Negative              7934\n","Extremely Positive    6392\n","Extremely Negative    5694\n","Name: count, dtype: int64\n","\n","Removed 0 duplicate rows from augmented data.\n","\n","Number of augmented samples added per class:\n","Sentiment\n","Extremely Negative    579\n","Extremely Positive    578\n","Neutral               543\n","Name: count, dtype: int64\n","\n","Label counts AFTER augmentation:\n","Sentiment\n","Positive              9137\n","Neutral               8716\n","Negative              7934\n","Extremely Positive    6970\n","Extremely Negative    6273\n","Name: count, dtype: int64\n"]}],"source":["# Count and print label distribution before augmentation\n","print(\"Label counts BEFORE augmentation:\")\n","original_counts = train_df[\"Sentiment\"].value_counts()\n","print(original_counts)\n","\n","# Load full augmented data\n","augmented_df = pd.read_csv('/content/drive/MyDrive/deep_learning/augmented_light333.csv', encoding='latin1')\n","\n","# Filter only the weak classes\n","target_classes = ['Extremely Positive', 'Neutral','Extremely Negative']\n","augmented_df = augmented_df[augmented_df['Sentiment'].isin(target_classes)]\n","\n","# Map labels to numeric (assuming label2id is defined)\n","augmented_df[\"label\"] = augmented_df[\"Sentiment\"].map(label2id)\n","\n","# Optional: Drop duplicates (based on ProcessedTweet) before merge\n","before_merge_aug_size = len(augmented_df)\n","augmented_df = augmented_df.drop_duplicates(subset='ProcessedTweet')\n","after_merge_aug_size = len(augmented_df)\n","\n","print(f\"\\nRemoved {before_merge_aug_size - after_merge_aug_size} duplicate rows from augmented data.\")\n","\n","# Track how many samples were added per class\n","added_counts = augmented_df[\"Sentiment\"].value_counts()\n","print(\"\\nNumber of augmented samples added per class:\")\n","print(added_counts)\n","\n","# Combine datasets\n","train_df = pd.concat([train_df, augmented_df], ignore_index=True)\n","\n","# Shuffle the dataset\n","train_df = train_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n","\n","# Final label counts after augmentation\n","print(\"\\nLabel counts AFTER augmentation:\")\n","final_counts = train_df[\"Sentiment\"].value_counts()\n","print(final_counts)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1754508033151,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"h3oviw_748uW","outputId":"0dda1c15-0920-4b74-c970-c57e6277eacf"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"sample\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"ProcessedTweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Do you currently have hand sanitizer\",\n          \"you know you #needtogetoutmore when you bump into your sister-in-law at the supermarket and you're so #thankful that you skip home on cloud 9. #StayHomeSaveLives #isolationblues\",\n          \"Yoda fights R2 to get TOILET PAPER! Funny edit/dub http <---CLICK HERE #covid #toiletpaper #Yoda #R2D2 #brawl #fight #toiletpaperwars #ToiletPaperPanic #ToiletPaperApocalypse #funny #starwars #COVIDIDIOTS #COVIDIOTS #covid #COVID?19 #lol #haha #stock http\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Neutral\",\n          \"Extremely Negative\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"sample"},"text/html":["\n","  <div id=\"df-0c6abd62-32e0-48de-a07f-994e31fde074\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ProcessedTweet</th>\n","      <th>Sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25970</th>\n","      <td>Cheryl Idell Chief Research Officer at Entertainment amp Direct to Consumer shares how social distancing in the wake of covid is affecting usage of digital platforms</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15144</th>\n","      <td>you know you #needtogetoutmore when you bump into your sister-in-law at the supermarket and you're so #thankful that you skip home on cloud 9. #StayHomeSaveLives #isolationblues</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6198</th>\n","      <td>To keep our consumer-members &amp; employees safe, weÃÂre taking additional precautions to ensure the co-op is prepared to keep the lights on. In response to #covid, weÃÂve activated our emergency response plan. Learn about operational changes &amp; plans: http http</td>\n","      <td>Positive</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>13627</th>\n","      <td>Companies, Trade Organizations, Movie Industry and Newspapers seek to postpone date for the #California Consumer Privacy Act (#CCPA) due to the new #covid and a lack of clarity on the enforcement rules http http</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1967</th>\n","      <td>Dutch prime minister visits supermarket and tries to set hoarders at ease there is so much toilet paper available in the country that we can shit for 10 years</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>27581</th>\n","      <td>Yoda fights R2 to get TOILET PAPER! Funny edit/dub http &lt;---CLICK HERE #covid #toiletpaper #Yoda #R2D2 #brawl #fight #toiletpaperwars #ToiletPaperPanic #ToiletPaperApocalypse #funny #starwars #COVIDIDIOTS #COVIDIOTS #covid #COVID?19 #lol #haha #stock http</td>\n","      <td>Positive</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2386</th>\n","      <td>I just hope that in this panic to buy all of the toilet paper/sanitizer/food, you take care of your animals as well as you plan to take care of yourselves and your families. :( #itsnottheendoftheworld #covid</td>\n","      <td>Extremely Positive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>11231</th>\n","      <td>Healthcare workers need N95 masks to protect themselves from covid. It makes me sick to see people try to sell these on various websites for crazy high prices. Donate them to a hospital, you assholes!</td>\n","      <td>Extremely Negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29064</th>\n","      <td>Do you currently have hand sanitizer</td>\n","      <td>Positive</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>37617</th>\n","      <td>#covid could halt the rise in house prices ? #covid #housingmarket @user https://t.co/iTecbrnvrg</td>\n","      <td>Neutral</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c6abd62-32e0-48de-a07f-994e31fde074')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0c6abd62-32e0-48de-a07f-994e31fde074 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0c6abd62-32e0-48de-a07f-994e31fde074');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-4e6f4f20-cf00-4aaf-92ef-d829be1e66f7\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e6f4f20-cf00-4aaf-92ef-d829be1e66f7')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-4e6f4f20-cf00-4aaf-92ef-d829be1e66f7 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_e9812364-4e34-4364-887a-907591671882\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_e9812364-4e34-4364-887a-907591671882 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('sample');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                                                                                                                                                                                                                                               ProcessedTweet  \\\n","25970                                                                                                   Cheryl Idell Chief Research Officer at Entertainment amp Direct to Consumer shares how social distancing in the wake of covid is affecting usage of digital platforms   \n","15144                                                                                       you know you #needtogetoutmore when you bump into your sister-in-law at the supermarket and you're so #thankful that you skip home on cloud 9. #StayHomeSaveLives #isolationblues   \n","6198   To keep our consumer-members & employees safe, weÃÂre taking additional precautions to ensure the co-op is prepared to keep the lights on. In response to #covid, weÃÂve activated our emergency response plan. Learn about operational changes & plans: http http   \n","13627                                                     Companies, Trade Organizations, Movie Industry and Newspapers seek to postpone date for the #California Consumer Privacy Act (#CCPA) due to the new #covid and a lack of clarity on the enforcement rules http http   \n","1967                                                                                                           Dutch prime minister visits supermarket and tries to set hoarders at ease there is so much toilet paper available in the country that we can shit for 10 years   \n","27581         Yoda fights R2 to get TOILET PAPER! Funny edit/dub http <---CLICK HERE #covid #toiletpaper #Yoda #R2D2 #brawl #fight #toiletpaperwars #ToiletPaperPanic #ToiletPaperApocalypse #funny #starwars #COVIDIDIOTS #COVIDIOTS #covid #COVID?19 #lol #haha #stock http   \n","2386                                                          I just hope that in this panic to buy all of the toilet paper/sanitizer/food, you take care of your animals as well as you plan to take care of yourselves and your families. :( #itsnottheendoftheworld #covid   \n","11231                                                                Healthcare workers need N95 masks to protect themselves from covid. It makes me sick to see people try to sell these on various websites for crazy high prices. Donate them to a hospital, you assholes!   \n","29064                                                                                                                                                                                                                                    Do you currently have hand sanitizer   \n","37617                                                                                                                                                                        #covid could halt the rise in house prices ? #covid #housingmarket @user https://t.co/iTecbrnvrg   \n","\n","                Sentiment  label  \n","25970  Extremely Positive      4  \n","15144             Neutral      2  \n","6198             Positive      3  \n","13627            Negative      1  \n","1967             Negative      1  \n","27581            Positive      3  \n","2386   Extremely Positive      4  \n","11231  Extremely Negative      0  \n","29064            Positive      3  \n","37617             Neutral      2  "]},"metadata":{},"output_type":"display_data"}],"source":["# Display\n","pd.set_option('display.max_colwidth', None)  # so full text is shown\n","sample = train_df[['ProcessedTweet','Sentiment','label']].sample(10, random_state=24)\n","display(sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1fed3dd5dcce47d5880985b37274e326","ace3d620091f4c68930f2bb473fe92f2","e2b14fd81169483f9018364518cf7c9e","2f93590d95af46b5aa269ffc97b5b5e9","b6d435ccbf6e4b59be8df6a7a3287cee","f3a837165cfa41139ec9206ee2f02a59","12695d407ed5430c88baf20ed959f166","834b16fcef1b416a9d924465fe3ca5a3","cfbb940492014becb9a69a69352772e5","0a95338ce99e4dc0a77996949caee2d3","5821809aafc140529d0d2762370ab705","1d2b14c8c2fd46bf92ee5bb12a0ba54b","d1e5347f5e5144eb9228ba73877ed8cb","52c952a3f1b543e095f0a93d31f2b460","d9be2e5ef396465a8e7ab0309dbe07b4","dce829ac8582421a9b3f0aa94cbe6eda","ed31faa94e284f839c4fc5aa0dd427f3","80f9a69033fb483dafad4205a1522b31","2968bfadfd10433f830471b0fb03e3ce","a6907f3604564578ac7af0dfc7bf2db8","b7119493b85c44b79fb913c7af82d4db","3e817f64314845578f32f8eb992d4363","40c39840d6d34b3b8123b6f16c9a0c9f","db8c270765ef4365b29040fc015ef8e4","7c1a1da55e0d4c78b9c2f4de2cec231c","94136b082b224ed1b9a3edd8d341b807","e3f73063f6a64fa0a64ca3b61280a631","1bbb8a9cde71442db9729c09917465f2","fc5c718df6c24d04aac42241539cf99b","5bf341947c4d4b398b031418e25336ca","7901646085674b61b7dc220ff74df2b2","a08249c6a6174f20bc04d482180597d2","27c0e6b10d124ef58cad459ee4dfa944","1466877b92be4f98b7121edbb110f8ee","51bbe88d4b5945328d67b860b2566724","48c6b416dbff4514a9eed4c2b3c137ff","8a28070c383c415a89c5980b38a53877","85e0b5f025ed47a79ca9c1b492e252aa","bb3d1dfb73974f56a82fd0601d136b58","b8fadbb248ea46798ae565cb7f2546a2","8e848afb738b465aa6bf8dcc15b924d0","8404354b03b949afb17be7ea59fa466f","dc9e9728e7df496c839d078b4d3951ff","535f2a3d8bc249cd8ddc0de7e59cc602","6ba9beb1c69c4c799e56f7ef57a9c1f6","682361786687425181abd36e3534094d","9ae3337a7fc24d329d31a3b09da927ed","190d37c386a24f8cab59a2f29ef89aca","d2c19f9bfdfd412f9fd2b85cd089e9c5","1d4b073383e0476c867fb14bd161db06","15dad39514274f82a5794215d3bd48c4","9791d4e213a94e5d9f67faf4e8234468","489a262bc666462bbd3ffd0316fe9438","87efe0ed8046428191ffdd223a16db8d","f75d69fd415347c6a7fd40abb95002e9","3b88faaca1f74a6ba14ef067ad65e7aa","2d24a98d67794f42a43bf5f83357a512","6559806323e1431985757064ae58d8ce","d9fd993d20414e9aa44b0ad9b0fd7fd5","8291f2f253544bdcbb770d7552ac8989","344ca8403271494f81827e22d7c8cc5c","f087a9445b9149fda56b23499967b06c","3df03553cdba445ebf0a35f4fd675b0b","614676d031c640dd8c2061f7b199c2cc","4a1120808a994f5597d1bc72eee1ba06","c406ea9a9d4c4c6fb1c806110f390f3c"]},"executionInfo":{"elapsed":14100,"status":"error","timestamp":1754557743393,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"},"user_tz":-180},"id":"4TAFuMiu48kL","outputId":"a3f502f3-fd2f-4f65-9d3e-4f43a80e748e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 19:20:53,577] A new study created in memory with name: no-name-44a5ef35-fc05-42c6-a6b1-44a81c820512\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 6:\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fed3dd5dcce47d5880985b37274e326","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d2b14c8c2fd46bf92ee5bb12a0ba54b","version_major":2,"version_minor":0},"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40c39840d6d34b3b8123b6f16c9a0c9f","version_major":2,"version_minor":0},"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1466877b92be4f98b7121edbb110f8ee","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ba9beb1c69c4c799e56f7ef57a9c1f6","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b88faaca1f74a6ba14ef067ad65e7aa","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_192100-7zagp57k</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/7zagp57k' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/7zagp57k' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/7zagp57k</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6724, Val Acc: 0.7325, Val F1: 0.7394, Gap: -0.0601\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8204, Val Acc: 0.8302, Val F1: 0.8356, Gap: -0.0097\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8681, Val Acc: 0.8451, Val F1: 0.8497, Gap: 0.0230\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.9006, Val Acc: 0.8328, Val F1: 0.8367, Gap: 0.0677\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9174, Val Acc: 0.8533, Val F1: 0.8582, Gap: 0.0642\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9351, Val Acc: 0.8614, Val F1: 0.8658, Gap: 0.0737\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9426, Val Acc: 0.8519, Val F1: 0.8556, Gap: 0.0907\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9515, Val Acc: 0.8488, Val F1: 0.8535, Gap: 0.1027\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9546, Val Acc: 0.8409, Val F1: 0.8450, Gap: 0.1137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9603, Val Acc: 0.8642, Val F1: 0.8679, Gap: 0.0961\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9641, Val Acc: 0.8522, Val F1: 0.8541, Gap: 0.1119\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9683, Val Acc: 0.8497, Val F1: 0.8543, Gap: 0.1186\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9702, Val Acc: 0.8664, Val F1: 0.8700, Gap: 0.1038\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9721, Val Acc: 0.8533, Val F1: 0.8570, Gap: 0.1189\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.9733, Val Acc: 0.8575, Val F1: 0.8615, Gap: 0.1158\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.9771, Val Acc: 0.8650, Val F1: 0.8683, Gap: 0.1121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.9774, Val Acc: 0.8584, Val F1: 0.8626, Gap: 0.1190\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9803, Val Acc: 0.8655, Val F1: 0.8697, Gap: 0.1148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9810, Val Acc: 0.8608, Val F1: 0.8649, Gap: 0.1203\n","Early stopping at epoch 19\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▇▅▇▇█▇▇█▆▇█▇████▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▆▄▆▆▇▄▆▇█▇▇▅▆▆▆▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▅▄█▆▅▄█▅▆▁▅▄▇▆▆▆▆▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▇▆▇██▆▇██▇█▇█████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▅▅▆▄▃▇▇▅▇▅▆▆█▇▅▄</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▇▅▇▇█▆▆▇▇▆█▆▇▆▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆▇▆█▇▇▄▇▅▇█▇▇█▆██</td></tr><tr><td>Class_Negative_Precision</td><td>▆▅▄▆▄▇█▇▁▃▁▅▄▆▄▄▂▆▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▆▅▆▅▄▅▇██▆▇▆▇██▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇▆▇█▇▇▆██▇█▇▇█▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▇▆▅▃█▆▆▆▆▆▆▅▆▆▆▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▆▅▆▇█▅▅▇▆▅▇▆▇▇▆▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▆▇█▅▇▆▇▇▇▇▇▆█▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▁▆▆▄▇▇█▅▄▇▆▄▇▅▇▆▇▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▇▅▅▇▅▆▁▇▇▄▆█▅▆▃▆▅▅▅</td></tr><tr><td>Epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇▇██████████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▆▇█▇▇▇█▇▇█▇█████</td></tr><tr><td>Validation F1</td><td>▁▆▇▆▇█▇▇▇█▇▇█▇█████</td></tr><tr><td>Validation Loss</td><td>▅▂▁▂▁▂▃▃▄▄▆▆▆▆▇▆███</td></tr><tr><td>Validation Precision</td><td>▁▆▇▆▇██▇▆█▇▇█▇▇▇▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▆▆▇▇▇▆▇▇█▆▇██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86658</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84803</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88595</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82649</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.8018</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.85275</td></tr><tr><td>Class_Negative_F1</td><td>0.88284</td></tr><tr><td>Class_Negative_Precision</td><td>0.90476</td></tr><tr><td>Class_Negative_Recall</td><td>0.86196</td></tr><tr><td>Class_Neutral_F1</td><td>0.85549</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86941</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84201</td></tr><tr><td>Class_Positive_F1</td><td>0.89313</td></tr><tr><td>Class_Positive_Precision</td><td>0.90347</td></tr><tr><td>Class_Positive_Recall</td><td>0.88302</td></tr><tr><td>Epoch</td><td>19</td></tr><tr><td>Train Accuracy</td><td>0.98104</td></tr><tr><td>Train Loss</td><td>0.08189</td></tr><tr><td>Validation Accuracy</td><td>0.86079</td></tr><tr><td>Validation F1</td><td>0.86491</td></tr><tr><td>Validation Loss</td><td>0.79355</td></tr><tr><td>Validation Precision</td><td>0.8655</td></tr><tr><td>Validation Recall</td><td>0.86514</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/7zagp57k' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/7zagp57k</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_192100-7zagp57k/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 20:28:10,457] Trial 0 finished with value: 0.8663751214771623 and parameters: {'learning_rate': 2.159332620686905e-05, 'weight_decay': 1.2239783871125564e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 0 with value: 0.8663751214771623.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["creating run (10s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_202811-j44jpi5h</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/j44jpi5h' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/j44jpi5h' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/j44jpi5h</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n","\u001b[34m\u001b[1mwandb\u001b[0m: 500 encountered ({\"errors\":[{\"message\":\"context deadline exceeded\",\"path\":[\"project\",\"run\"]}],\"data\":{\"project\":{\"run\":null}}}), retrying request\n","\u001b[34m\u001b[1mwandb\u001b[0m: 500 encountered ({\"errors\":[{\"message\":\"context deadline exceeded\",\"path\":[\"project\",\"run\"]}],\"data\":{\"project\":{\"run\":null}}}), retrying request\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.5347, Val Acc: 0.5990, Val F1: 0.6123, Gap: -0.0643\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.6615, Val Acc: 0.6823, Val F1: 0.6946, Gap: -0.0208\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.7176, Val Acc: 0.7173, Val F1: 0.7280, Gap: 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.7531, Val Acc: 0.7403, Val F1: 0.7498, Gap: 0.0129\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.7781, Val Acc: 0.7606, Val F1: 0.7693, Gap: 0.0175\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.8001, Val Acc: 0.7454, Val F1: 0.7535, Gap: 0.0547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.8172, Val Acc: 0.7850, Val F1: 0.7921, Gap: 0.0322\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.8310, Val Acc: 0.7719, Val F1: 0.7780, Gap: 0.0592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.8423, Val Acc: 0.7838, Val F1: 0.7902, Gap: 0.0585\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.8551, Val Acc: 0.7931, Val F1: 0.7996, Gap: 0.0619\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.8655, Val Acc: 0.7985, Val F1: 0.8046, Gap: 0.0670\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.8760, Val Acc: 0.8130, Val F1: 0.8192, Gap: 0.0630\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.8845, Val Acc: 0.8157, Val F1: 0.8227, Gap: 0.0688\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.8905, Val Acc: 0.8056, Val F1: 0.8102, Gap: 0.0848\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.8996, Val Acc: 0.8280, Val F1: 0.8332, Gap: 0.0717\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.9025, Val Acc: 0.8269, Val F1: 0.8320, Gap: 0.0756\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.9094, Val Acc: 0.8309, Val F1: 0.8359, Gap: 0.0785\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9162, Val Acc: 0.8298, Val F1: 0.8347, Gap: 0.0864\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9214, Val Acc: 0.8356, Val F1: 0.8406, Gap: 0.0857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20: Train Acc: 0.9290, Val Acc: 0.8377, Val F1: 0.8432, Gap: 0.0913\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▅▅▅▆▅▆▆▆▇▇▆▇▇▇▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▄▄▄▃▅▃▄▅▄▅█▄▆▆▆▆▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▁▃▄▅▆▄█▇▆█▆▁█▆▆▅▅▆▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▄▅▅▅▆▆▆▆▆▇█▆▇▇████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▅▅▆▆▇▇▇▆█▇███████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▄▅▅▄▆▄▅▆▆▆█▅▇▇▇▇▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▆▆▇▇▇▇▇█████████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▃▅▅▆▇▇▇██▇███▇▆▆▇▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▆▆▆▆▇▇▇▆▇▇▇▇▇█████</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▄▅▆▅▆▆▆▇▇▇▇▇██████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▆▇▇██▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▄▅▆▄▆▆▆▆▇▇▇▇█████▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▅▅▆▆▆▇▇▇▇▇██████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▅▅▇▃▆▄▅▆▇▆▆▆▇▇▇▇██</td></tr><tr><td>Class_Positive_Recall</td><td>▃▁▄▅▃█▆██▇▆▇██▇██▇▇▇</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▆▅▆▆▆▇▇▇▇▇██████</td></tr><tr><td>Validation F1</td><td>▁▃▅▅▆▅▆▆▆▇▇▇▇▇██████</td></tr><tr><td>Validation Loss</td><td>█▆▄▄▃▃▂▃▂▂▂▂▁▂▁▁▁▂▁▂</td></tr><tr><td>Validation Precision</td><td>▁▄▄▅▆▅▆▆▆▇▇▇█▇██████</td></tr><tr><td>Validation Recall</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85161</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.82298</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.8823</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80245</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.78155</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82451</td></tr><tr><td>Class_Negative_F1</td><td>0.85705</td></tr><tr><td>Class_Negative_Precision</td><td>0.88422</td></tr><tr><td>Class_Negative_Recall</td><td>0.8315</td></tr><tr><td>Class_Neutral_F1</td><td>0.82469</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84316</td></tr><tr><td>Class_Neutral_Recall</td><td>0.807</td></tr><tr><td>Class_Positive_F1</td><td>0.88009</td></tr><tr><td>Class_Positive_Precision</td><td>0.87943</td></tr><tr><td>Class_Positive_Recall</td><td>0.88075</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.92903</td></tr><tr><td>Train Loss</td><td>0.21984</td></tr><tr><td>Validation Accuracy</td><td>0.83771</td></tr><tr><td>Validation F1</td><td>0.84318</td></tr><tr><td>Validation Loss</td><td>0.55391</td></tr><tr><td>Validation Precision</td><td>0.84227</td></tr><tr><td>Validation Recall</td><td>0.84521</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/j44jpi5h' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/j44jpi5h</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_202811-j44jpi5h/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 21:38:05,216] Trial 1 finished with value: 0.8377065111758989 and parameters: {'learning_rate': 2.677090132913426e-06, 'weight_decay': 1.2781682913209393e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 0 with value: 0.8663751214771623.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_213806-w2opmz52</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w2opmz52' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w2opmz52' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w2opmz52</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6574, Val Acc: 0.7474, Val F1: 0.7554, Gap: -0.0900\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8024, Val Acc: 0.8132, Val F1: 0.8193, Gap: -0.0107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8525, Val Acc: 0.8294, Val F1: 0.8353, Gap: 0.0230\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.8846, Val Acc: 0.8328, Val F1: 0.8383, Gap: 0.0517\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9093, Val Acc: 0.8489, Val F1: 0.8530, Gap: 0.0604\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9266, Val Acc: 0.8507, Val F1: 0.8553, Gap: 0.0759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9397, Val Acc: 0.8475, Val F1: 0.8516, Gap: 0.0921\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9506, Val Acc: 0.8418, Val F1: 0.8461, Gap: 0.1087\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9576, Val Acc: 0.8542, Val F1: 0.8582, Gap: 0.1034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9632, Val Acc: 0.8500, Val F1: 0.8540, Gap: 0.1132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9658, Val Acc: 0.8424, Val F1: 0.8465, Gap: 0.1234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9705, Val Acc: 0.8571, Val F1: 0.8615, Gap: 0.1133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9749, Val Acc: 0.8556, Val F1: 0.8604, Gap: 0.1194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9794, Val Acc: 0.8539, Val F1: 0.8576, Gap: 0.1255\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.9813, Val Acc: 0.8518, Val F1: 0.8554, Gap: 0.1295\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.9817, Val Acc: 0.8574, Val F1: 0.8621, Gap: 0.1243\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.9846, Val Acc: 0.8554, Val F1: 0.8600, Gap: 0.1292\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9867, Val Acc: 0.8593, Val F1: 0.8635, Gap: 0.1274\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9863, Val Acc: 0.8573, Val F1: 0.8614, Gap: 0.1290\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20: Train Acc: 0.9877, Val Acc: 0.8650, Val F1: 0.8690, Gap: 0.1226\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▆▇▇▇▆▇▇▇▇▇▇▇██▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▇▆▅▆▇▇▅▆▆▅█▆▆▅█▆█▅█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▁▅▇▇▄▃▇▇██▃▇▆▇▅▇▃█▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▇▆▇▇▇▇▇▇▇█▇▇▇███▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▆▆█▇▇▆▇█▇█▆█▇██▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▇▆▆▆▇▇▆▇▆▆▇▇▆▆▇▇█▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆▆▇▆▆▇▆▅▇▇▆▇▇▇▇██</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▇█▄▆▃▅▅▄▁▆▆▃▆▅▄▇█▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▄▃▆▅▇▅▆▇█▆▆▇▆▆█▄▅▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▇▇▇▇▇▇▇▇███▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▅▆▆▅▇██▇▇▅▇▇█▇█▆▆▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▄▅▆▇▅▅▅▆▆▇▆▆▆▆▅▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▇▇▇▇█▇▇▇██▇▇▇██▇</td></tr><tr><td>Class_Positive_Precision</td><td>▃▁▁▃▆▆▅▄▅▆█▆▇▆▅▅▅▇▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇██▅▅▇██▆▃▆▅▆▇▇▇▅▆▃</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇▇██████████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇▇▇▇▇▇█▇▇▇█▇███</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇▇▇▇▇▇█▇▇▇█▇███</td></tr><tr><td>Validation Loss</td><td>▄▂▁▁▁▁▂▃▄▃▄▅▅▆▆▆▇███</td></tr><tr><td>Validation Precision</td><td>▁▅▆▆▇▇▇▆▇▇▆▇▇▇▇▇▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆▇▇▇▇██▇▇█████▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87703</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86918</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88504</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83321</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84156</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82501</td></tr><tr><td>Class_Negative_F1</td><td>0.89297</td></tr><tr><td>Class_Negative_Precision</td><td>0.90486</td></tr><tr><td>Class_Negative_Recall</td><td>0.8814</td></tr><tr><td>Class_Neutral_F1</td><td>0.85798</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82505</td></tr><tr><td>Class_Neutral_Recall</td><td>0.89365</td></tr><tr><td>Class_Positive_F1</td><td>0.88368</td></tr><tr><td>Class_Positive_Precision</td><td>0.93216</td></tr><tr><td>Class_Positive_Recall</td><td>0.84</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.98765</td></tr><tr><td>Train Loss</td><td>0.04999</td></tr><tr><td>Validation Accuracy</td><td>0.86504</td></tr><tr><td>Validation F1</td><td>0.86898</td></tr><tr><td>Validation Loss</td><td>0.91948</td></tr><tr><td>Validation Precision</td><td>0.87456</td></tr><tr><td>Validation Recall</td><td>0.86502</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w2opmz52' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w2opmz52</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_213806-w2opmz52/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 22:47:45,206] Trial 2 finished with value: 0.8650388726919339 and parameters: {'learning_rate': 1.5221248619547827e-05, 'weight_decay': 4.489234513096729e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 0 with value: 0.8663751214771623.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_224746-fo06i7e1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/fo06i7e1' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/fo06i7e1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/fo06i7e1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6965, Val Acc: 0.7885, Val F1: 0.7971, Gap: -0.0920\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8342, Val Acc: 0.8313, Val F1: 0.8376, Gap: 0.0029\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8738, Val Acc: 0.8288, Val F1: 0.8326, Gap: 0.0450\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.8949, Val Acc: 0.8327, Val F1: 0.8377, Gap: 0.0622\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9040, Val Acc: 0.8296, Val F1: 0.8311, Gap: 0.0745\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9158, Val Acc: 0.8631, Val F1: 0.8672, Gap: 0.0527\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9219, Val Acc: 0.8676, Val F1: 0.8711, Gap: 0.0543\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9295, Val Acc: 0.8593, Val F1: 0.8604, Gap: 0.0702\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9369, Val Acc: 0.8646, Val F1: 0.8689, Gap: 0.0723\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9370, Val Acc: 0.8586, Val F1: 0.8629, Gap: 0.0784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9429, Val Acc: 0.8576, Val F1: 0.8612, Gap: 0.0853\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9427, Val Acc: 0.8672, Val F1: 0.8701, Gap: 0.0755\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9469, Val Acc: 0.8631, Val F1: 0.8670, Gap: 0.0838\n","Early stopping at epoch 13\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▃▆▃▅▁▇▇▄█▇▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▄▄▁▃▇▅▇█▅▅▆▆▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▆██▁▇▄▂▇▆▅▅▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▁▃▆▇█▇▇▇██▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅█▅▃▆▃▂▆▇▇▆▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▄▁▃▇▆██▆▅▅▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▅█▄▆▅█▇▇▇▇▆▅</td></tr><tr><td>Class_Negative_Precision</td><td>▆▆██▇▆▇▅▇▆▂▃▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▄▂▄▄▅▆▅▅█▇▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▅▅████▇▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▆▄▅▅▅▆▅███</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▅▄▄███▇▇▅▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▅▅▅██▇▇▆▆█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▃▃▂▇█▇▅▅▄▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▅▅▆██▃▁▂▅▆▇▆▅</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▅▅▅██▇█▇▇██</td></tr><tr><td>Validation F1</td><td>▁▅▄▅▄██▇█▇▇██</td></tr><tr><td>Validation Loss</td><td>█▃▆▆▅▂▃▂▄▁▄▃▅</td></tr><tr><td>Validation Precision</td><td>▁▄▄▄▅▇██▇▆▆▇▆</td></tr><tr><td>Validation Recall</td><td>▁▅▅▆▄▇▇▆█▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87688</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85198</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90328</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83622</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85866</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81493</td></tr><tr><td>Class_Negative_F1</td><td>0.87539</td></tr><tr><td>Class_Negative_Precision</td><td>0.84676</td></tr><tr><td>Class_Negative_Recall</td><td>0.90603</td></tr><tr><td>Class_Neutral_F1</td><td>0.8508</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87293</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82976</td></tr><tr><td>Class_Positive_F1</td><td>0.89591</td></tr><tr><td>Class_Positive_Precision</td><td>0.88278</td></tr><tr><td>Class_Positive_Recall</td><td>0.90943</td></tr><tr><td>Epoch</td><td>13</td></tr><tr><td>Train Accuracy</td><td>0.94691</td></tr><tr><td>Train Loss</td><td>0.17216</td></tr><tr><td>Validation Accuracy</td><td>0.8631</td></tr><tr><td>Validation F1</td><td>0.86704</td></tr><tr><td>Validation Loss</td><td>0.50376</td></tr><tr><td>Validation Precision</td><td>0.86262</td></tr><tr><td>Validation Recall</td><td>0.87269</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/fo06i7e1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/fo06i7e1</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_224746-fo06i7e1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-06 23:33:00,889] Trial 3 finished with value: 0.8675898931000972 and parameters: {'learning_rate': 4.325435642954663e-05, 'weight_decay': 6.40042337179331e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250806_233301-a9849c4e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/a9849c4e' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/a9849c4e' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/a9849c4e</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.5243, Val Acc: 0.6045, Val F1: 0.6181, Gap: -0.0802\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.6511, Val Acc: 0.6614, Val F1: 0.6738, Gap: -0.0104\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.6991, Val Acc: 0.7111, Val F1: 0.7221, Gap: -0.0120\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.7368, Val Acc: 0.7334, Val F1: 0.7437, Gap: 0.0034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.7627, Val Acc: 0.7557, Val F1: 0.7653, Gap: 0.0070\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.7846, Val Acc: 0.7704, Val F1: 0.7789, Gap: 0.0141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.7995, Val Acc: 0.7768, Val F1: 0.7853, Gap: 0.0226\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.8151, Val Acc: 0.7787, Val F1: 0.7852, Gap: 0.0364\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.8275, Val Acc: 0.7973, Val F1: 0.8045, Gap: 0.0303\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.8411, Val Acc: 0.8056, Val F1: 0.8122, Gap: 0.0355\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.8507, Val Acc: 0.8127, Val F1: 0.8187, Gap: 0.0380\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.8587, Val Acc: 0.8058, Val F1: 0.8126, Gap: 0.0530\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.8697, Val Acc: 0.8141, Val F1: 0.8208, Gap: 0.0556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.8772, Val Acc: 0.8167, Val F1: 0.8225, Gap: 0.0605\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.8837, Val Acc: 0.8254, Val F1: 0.8308, Gap: 0.0582\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.8916, Val Acc: 0.8120, Val F1: 0.8177, Gap: 0.0797\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.8961, Val Acc: 0.8141, Val F1: 0.8194, Gap: 0.0820\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9035, Val Acc: 0.8179, Val F1: 0.8231, Gap: 0.0856\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9083, Val Acc: 0.8303, Val F1: 0.8364, Gap: 0.0780\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20: Train Acc: 0.9131, Val Acc: 0.8294, Val F1: 0.8343, Gap: 0.0837\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▅▅▆▇▆▇▇▇▇▇▇█▇▇▇█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▄▆▇▆▇▄▆▆▇▇▇▅█▅▅▆█▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▃▄▃▃▄▅▇▆▆▆▆▆█▆███▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▅▆▆▇▆▇▇▇▇▇▇█▇▇▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▄▄▅▆▆▆▇▇▇▇▇▇█▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▄▅▆▆▆▅▆▇▇▆▇▆█▆▆▆█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▅▅▆▆▇▇▇▇▇▇███▇████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▄▆▆▆▇▇▇▇▇█▇█▇██▇█▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▃▅▅▅▅▆▆▇▅▆▇▇▆▆▇▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▂▄▅▆▆▆▇▇▇█▇▇██▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▃▅▅▆▅▆▇▇█▇▇▇█▇▇▇▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▆▆▆▆▇▇▇▇▇█▇█████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▁▃▄▅▆▃▄▆▇█▅▅▆█▄▆▄▅▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▄▄▅▄▇▆▆▅▅▇▇▇▅█▇██▇</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▆▆▆▆▇▇▇▇▇██▇▇███</td></tr><tr><td>Validation F1</td><td>▁▃▄▅▆▆▆▆▇▇▇▇███▇▇███</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▃▂▂▁▁▁▁▁▁▁▁▂▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▆▆▆▆▇▇█▇▇▇█▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇█▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83684</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.77613</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90785</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.78691</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.7797</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79425</td></tr><tr><td>Class_Negative_F1</td><td>0.85896</td></tr><tr><td>Class_Negative_Precision</td><td>0.88682</td></tr><tr><td>Class_Negative_Recall</td><td>0.83279</td></tr><tr><td>Class_Neutral_F1</td><td>0.81984</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85362</td></tr><tr><td>Class_Neutral_Recall</td><td>0.78862</td></tr><tr><td>Class_Positive_F1</td><td>0.86902</td></tr><tr><td>Class_Positive_Precision</td><td>0.85474</td></tr><tr><td>Class_Positive_Recall</td><td>0.88377</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.91314</td></tr><tr><td>Train Loss</td><td>0.25769</td></tr><tr><td>Validation Accuracy</td><td>0.82945</td></tr><tr><td>Validation F1</td><td>0.83431</td></tr><tr><td>Validation Loss</td><td>0.55026</td></tr><tr><td>Validation Precision</td><td>0.8302</td></tr><tr><td>Validation Recall</td><td>0.84146</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/a9849c4e' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/a9849c4e</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250806_233301-a9849c4e/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 00:42:25,924] Trial 4 finished with value: 0.8302964042759962 and parameters: {'learning_rate': 2.2653438462546594e-06, 'weight_decay': 1.4278399975659279e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_004227-mwmebilk</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/mwmebilk' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/mwmebilk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/mwmebilk</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6831, Val Acc: 0.7468, Val F1: 0.7542, Gap: -0.0637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8279, Val Acc: 0.8237, Val F1: 0.8296, Gap: 0.0041\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8753, Val Acc: 0.8175, Val F1: 0.8237, Gap: 0.0577\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.9043, Val Acc: 0.8262, Val F1: 0.8332, Gap: 0.0781\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9236, Val Acc: 0.8198, Val F1: 0.8239, Gap: 0.1037\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9380, Val Acc: 0.8525, Val F1: 0.8570, Gap: 0.0855\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9479, Val Acc: 0.8495, Val F1: 0.8533, Gap: 0.0984\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9532, Val Acc: 0.8528, Val F1: 0.8561, Gap: 0.1004\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9580, Val Acc: 0.8547, Val F1: 0.8560, Gap: 0.1033\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9628, Val Acc: 0.8579, Val F1: 0.8620, Gap: 0.1050\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9680, Val Acc: 0.8432, Val F1: 0.8462, Gap: 0.1248\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9700, Val Acc: 0.8517, Val F1: 0.8546, Gap: 0.1184\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9730, Val Acc: 0.8622, Val F1: 0.8661, Gap: 0.1108\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9767, Val Acc: 0.8539, Val F1: 0.8580, Gap: 0.1228\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.9768, Val Acc: 0.8581, Val F1: 0.8619, Gap: 0.1187\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.9777, Val Acc: 0.8565, Val F1: 0.8616, Gap: 0.1212\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.9787, Val Acc: 0.8349, Val F1: 0.8386, Gap: 0.1438\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9803, Val Acc: 0.8641, Val F1: 0.8675, Gap: 0.1162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9822, Val Acc: 0.8578, Val F1: 0.8623, Gap: 0.1244\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20: Train Acc: 0.9828, Val Acc: 0.8526, Val F1: 0.8577, Gap: 0.1302\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▆▇▅▇▇▇▆█▇▇████▆███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▄▆▄▇▇▆█▅▅▅▆▆▆▆▄▇▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▅▇▆█▄▄▆▁▇▇▇▆▆▅▆█▄▆▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▇▆▇▆█████▇▇█▇██▆███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▅▇▇▆▇▇▆▇███▆▇▆▆▆█▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▇▆▆▄▇▇▇█▇▅▅▆▇▇▇▅█▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▆▆▇▆▆▇▇▃▅█▇▇█▆▇█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄▇█▇▇▆▅▄▄▄▁▄▅▅▅▇▄▄▇▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▂▃▄▅▆▆▇▇█▆▇▆▆▅▆█▅▄</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▃▃▄▇▆▇▇▇▇▇█▇▇▇▆█▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▆▂▆▃▆▇▅▇█▆▅▇▅▆██▅▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▁▃▂█▆▅▇▆▅▇█▅▇▆▃▆▇▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▄▄▄▆▆▆▇▇▇▇█▇▇▇▇█▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>█▃▁▁▁▆▄▄▆▇▅▆▇▅▆▆▄▇▄▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇███▆▇▇▆▆▇▆▆▇▆▆▇▆▇▅</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇▇███████████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▅▆▅▇▇▇▇█▇▇█▇██▆██▇</td></tr><tr><td>Validation F1</td><td>▁▆▅▆▅▇▇▇▇█▇▇█▇██▆██▇</td></tr><tr><td>Validation Loss</td><td>▄▁▁▁▃▁▂▂▃▂▅▄▅▅▅▅█▇▇▆</td></tr><tr><td>Validation Precision</td><td>▁▅▅▅▅█▇▇█▇▆▇█▇▇▇▅█▇▇</td></tr><tr><td>Validation Recall</td><td>▁▆▆▆▆▇▇█▇█▇█████▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87173</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84875</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89599</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82467</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.79229</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.85981</td></tr><tr><td>Class_Negative_F1</td><td>0.87437</td></tr><tr><td>Class_Negative_Precision</td><td>0.91024</td></tr><tr><td>Class_Negative_Recall</td><td>0.84122</td></tr><tr><td>Class_Neutral_F1</td><td>0.83953</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85417</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82538</td></tr><tr><td>Class_Positive_F1</td><td>0.87835</td></tr><tr><td>Class_Positive_Precision</td><td>0.89061</td></tr><tr><td>Class_Positive_Recall</td><td>0.86642</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.98283</td></tr><tr><td>Train Loss</td><td>0.06863</td></tr><tr><td>Validation Accuracy</td><td>0.85265</td></tr><tr><td>Validation F1</td><td>0.85773</td></tr><tr><td>Validation Loss</td><td>0.85422</td></tr><tr><td>Validation Precision</td><td>0.85921</td></tr><tr><td>Validation Recall</td><td>0.85776</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/mwmebilk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/mwmebilk</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_004227-mwmebilk/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 01:52:05,644] Trial 5 finished with value: 0.864067055393586 and parameters: {'learning_rate': 2.4592267186491672e-05, 'weight_decay': 9.372808558511085e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_015206-0lsi91ka</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/0lsi91ka' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/0lsi91ka' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/0lsi91ka</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6720, Val Acc: 0.7615, Val F1: 0.7698, Gap: -0.0895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8204, Val Acc: 0.7953, Val F1: 0.8026, Gap: 0.0251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8688, Val Acc: 0.8423, Val F1: 0.8470, Gap: 0.0265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.9025, Val Acc: 0.8491, Val F1: 0.8552, Gap: 0.0534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9249, Val Acc: 0.8529, Val F1: 0.8568, Gap: 0.0720\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9382, Val Acc: 0.8479, Val F1: 0.8520, Gap: 0.0903\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9502, Val Acc: 0.8445, Val F1: 0.8489, Gap: 0.1057\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9568, Val Acc: 0.8524, Val F1: 0.8562, Gap: 0.1043\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9626, Val Acc: 0.8564, Val F1: 0.8602, Gap: 0.1062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9682, Val Acc: 0.8526, Val F1: 0.8559, Gap: 0.1155\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9710, Val Acc: 0.8475, Val F1: 0.8519, Gap: 0.1235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9753, Val Acc: 0.8526, Val F1: 0.8556, Gap: 0.1227\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9792, Val Acc: 0.8395, Val F1: 0.8439, Gap: 0.1397\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9804, Val Acc: 0.8535, Val F1: 0.8571, Gap: 0.1269\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.9822, Val Acc: 0.8558, Val F1: 0.8592, Gap: 0.1264\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.9841, Val Acc: 0.8569, Val F1: 0.8618, Gap: 0.1272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.9839, Val Acc: 0.8560, Val F1: 0.8605, Gap: 0.1279\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9853, Val Acc: 0.8545, Val F1: 0.8566, Gap: 0.1308\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9860, Val Acc: 0.8588, Val F1: 0.8635, Gap: 0.1272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20: Train Acc: 0.9875, Val Acc: 0.8582, Val F1: 0.8620, Gap: 0.1293\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▁▆█▇▇▇▇▇▇█▆▇▇███▆█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁█▆▅▅▇▅▆▆▇█▆█▆▆▆█▆▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅█▁▆▆▆▃▅▅▅▄▂▄▂▆▆▆▁▅▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▁▇▇▇▇█▇█▇█▇▇█▇▇▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▄▁▄▄▆▆▇▆▆██▆▆▆█▆▆▅▅▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂██▆▆▆▆▆▅▆▆▆▇▅▇▇█▇▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇▇▆▇▇▆▆▆▆▇▅▇▇▆██</td></tr><tr><td>Class_Negative_Precision</td><td>▄▅▆▇█▆▃▆▅▂▂▃▅▆▁▇▆▃█▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▅▅▅▆▆▅▇▇▇▇▆▆█▆▆▇▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▇▇█▇▆███▇█▆▇██████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁█▅▇▇▇▆▇▇▇▇▆▇▇█▇▇▇▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▆▅▇▅▅▆▇▇▅█▄▆▆▇▇▇▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▆▇▇▆▆▇▇▇▆█▅▆█▇▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▆▆▇▇▅▃▆▇▆▃▇▃▄▇▇▇▇█▇</td></tr><tr><td>Class_Positive_Recall</td><td>▂▃▂▁▂▅█▆▂▄█▄▆▇▅▃▃▂▁▃</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇▇███████████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▇▇█▇▇███▇█▇███████</td></tr><tr><td>Validation F1</td><td>▁▃▇▇▇▇▇▇█▇▇▇▇████▇██</td></tr><tr><td>Validation Loss</td><td>▄▃▁▁▂▃▄▄▄▅▅▆▆▆▆█▆▇██</td></tr><tr><td>Validation Precision</td><td>▁▃▇▇▇▇▇▇▇▇▇█▆█▇█▇███</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇▇███▇▇▇▇███▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85494</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.80713</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.90876</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81893</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83083</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80736</td></tr><tr><td>Class_Negative_F1</td><td>0.89295</td></tr><tr><td>Class_Negative_Precision</td><td>0.91672</td></tr><tr><td>Class_Negative_Recall</td><td>0.87038</td></tr><tr><td>Class_Neutral_F1</td><td>0.85122</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84863</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85383</td></tr><tr><td>Class_Positive_F1</td><td>0.8921</td></tr><tr><td>Class_Positive_Precision</td><td>0.89824</td></tr><tr><td>Class_Positive_Recall</td><td>0.88604</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.98752</td></tr><tr><td>Train Loss</td><td>0.04954</td></tr><tr><td>Validation Accuracy</td><td>0.85824</td></tr><tr><td>Validation F1</td><td>0.86203</td></tr><tr><td>Validation Loss</td><td>0.90949</td></tr><tr><td>Validation Precision</td><td>0.86031</td></tr><tr><td>Validation Recall</td><td>0.86527</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/0lsi91ka' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/0lsi91ka</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_015206-0lsi91ka/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 03:01:51,628] Trial 6 finished with value: 0.858843537414966 and parameters: {'learning_rate': 2.2720580273049086e-05, 'weight_decay': 6.951105507286418e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_030152-wrtnz1rv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/wrtnz1rv' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/wrtnz1rv' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/wrtnz1rv</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6834, Val Acc: 0.7828, Val F1: 0.7895, Gap: -0.0994\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8265, Val Acc: 0.8352, Val F1: 0.8407, Gap: -0.0086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8728, Val Acc: 0.8460, Val F1: 0.8519, Gap: 0.0269\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.9009, Val Acc: 0.8489, Val F1: 0.8533, Gap: 0.0520\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9209, Val Acc: 0.8607, Val F1: 0.8652, Gap: 0.0602\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9354, Val Acc: 0.8389, Val F1: 0.8442, Gap: 0.0964\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9427, Val Acc: 0.8563, Val F1: 0.8614, Gap: 0.0864\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9483, Val Acc: 0.8637, Val F1: 0.8678, Gap: 0.0846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9556, Val Acc: 0.8421, Val F1: 0.8444, Gap: 0.1135\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9594, Val Acc: 0.8472, Val F1: 0.8510, Gap: 0.1122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9628, Val Acc: 0.8335, Val F1: 0.8373, Gap: 0.1293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9642, Val Acc: 0.8631, Val F1: 0.8659, Gap: 0.1011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9690, Val Acc: 0.8626, Val F1: 0.8658, Gap: 0.1064\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9707, Val Acc: 0.8570, Val F1: 0.8612, Gap: 0.1136\n","Early stopping at epoch 14\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▇▇▆█▇▇█▄▆▆▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▆▆▆▃▅▅██▁▃▄▃▅▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▅▆█▇▆▄▄██▆▇▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▅▇▆▇█▃▅▅▆▇▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▅▅▆▅▅▇▇█▇▆▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▇▇▄▇▅▇█▁▃▂▄▆▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆▆▅▆▇▇▆▅█▇▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄██▅▇▆█▆▆▃▁▇▅▄</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▄▇▅▄▅▆▆▇█▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▇▅▆▇▇▆▅██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▆█▇▇▆▇▇▇▇█▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▄▇▄▄▆▂▆▆▇▄▁▆█▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▇█▅██▇▇▄███</td></tr><tr><td>Class_Positive_Precision</td><td>▅█▄▆▆▂▅▅▆▄▁▅█▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▁▆▆▅█▇▆▆▇█▇▄▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▇█▆▇█▆▇▅██▇</td></tr><tr><td>Validation F1</td><td>▁▆▇▇█▆▇█▆▆▅██▇</td></tr><tr><td>Validation Loss</td><td>▅▂▁▁▁▆▃▂▄▆█▄▇▆</td></tr><tr><td>Validation Precision</td><td>▁▆▆▅▇▄██▅▅▄▇▇▆</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▇▆▇▇▇▇▆█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87184</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.82215</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92792</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82446</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86789</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78517</td></tr><tr><td>Class_Negative_F1</td><td>0.88164</td></tr><tr><td>Class_Negative_Precision</td><td>0.88714</td></tr><tr><td>Class_Negative_Recall</td><td>0.87622</td></tr><tr><td>Class_Neutral_F1</td><td>0.84215</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85215</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83239</td></tr><tr><td>Class_Positive_F1</td><td>0.88592</td></tr><tr><td>Class_Positive_Precision</td><td>0.84913</td></tr><tr><td>Class_Positive_Recall</td><td>0.92604</td></tr><tr><td>Epoch</td><td>14</td></tr><tr><td>Train Accuracy</td><td>0.97066</td></tr><tr><td>Train Loss</td><td>0.10288</td></tr><tr><td>Validation Accuracy</td><td>0.85702</td></tr><tr><td>Validation F1</td><td>0.8612</td></tr><tr><td>Validation Loss</td><td>0.64689</td></tr><tr><td>Validation Precision</td><td>0.85569</td></tr><tr><td>Validation Recall</td><td>0.86955</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/wrtnz1rv' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/wrtnz1rv</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_030152-wrtnz1rv/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 03:50:31,561] Trial 7 finished with value: 0.8637026239067055 and parameters: {'learning_rate': 2.4697746311960993e-05, 'weight_decay': 3.565533526984863e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_035032-vwty2oyr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/vwty2oyr' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/vwty2oyr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/vwty2oyr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.7015, Val Acc: 0.7802, Val F1: 0.7882, Gap: -0.0787\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8352, Val Acc: 0.8281, Val F1: 0.8339, Gap: 0.0071\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8840, Val Acc: 0.8147, Val F1: 0.8212, Gap: 0.0693\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.9117, Val Acc: 0.8506, Val F1: 0.8551, Gap: 0.0611\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9290, Val Acc: 0.8596, Val F1: 0.8629, Gap: 0.0694\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9410, Val Acc: 0.8553, Val F1: 0.8590, Gap: 0.0857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9506, Val Acc: 0.8667, Val F1: 0.8706, Gap: 0.0838\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9572, Val Acc: 0.8491, Val F1: 0.8530, Gap: 0.1081\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9634, Val Acc: 0.8613, Val F1: 0.8659, Gap: 0.1022\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9676, Val Acc: 0.8543, Val F1: 0.8585, Gap: 0.1133\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9719, Val Acc: 0.8488, Val F1: 0.8513, Gap: 0.1231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9738, Val Acc: 0.8576, Val F1: 0.8623, Gap: 0.1161\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9770, Val Acc: 0.8652, Val F1: 0.8688, Gap: 0.1119\n","Early stopping at epoch 13\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▅▇▇▇█▆█▇▅▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▆▄▇█▇█▇█▆▄▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▁▇▄▁▄▂▂▃▄▇▄▂</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▆▇▇▇█▇▇▇▆▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▆▅▇█▇▆█▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▄█▇▅█▇▆▆▄▅▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▅▄▇▅▆█▆██</td></tr><tr><td>Class_Negative_Precision</td><td>▅▆█▇▃▂▆▁▄▆▃▅▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▄▇▆▆█▆▆▇▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▃▃▁▇█▇█▆▇▆█▆█</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▄▃▁▄▄▃█▂▃▅▃▃</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▃▁█▇▇█▃█▆▆▇█</td></tr><tr><td>Class_Positive_F1</td><td>▃▄▁▅██▇▇▇▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▆▃▁█▆▆▆▅▆▅▇▅▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇█▁▅▆▅▆▅▆▃▆▄</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▄▇▇▇█▇█▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▄▇▇▇█▇█▇▆▇█</td></tr><tr><td>Validation Loss</td><td>▄▂▃▃▁▃▃▃▄▆█▇▆</td></tr><tr><td>Validation Precision</td><td>▁▄▃▇▇▇█▆▇▆▆▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▅▆▇██▇██▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86949</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.86673</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.87226</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83564</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83417</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.83712</td></tr><tr><td>Class_Negative_F1</td><td>0.89628</td></tr><tr><td>Class_Negative_Precision</td><td>0.90217</td></tr><tr><td>Class_Negative_Recall</td><td>0.89047</td></tr><tr><td>Class_Neutral_F1</td><td>0.85567</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8426</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86915</td></tr><tr><td>Class_Positive_F1</td><td>0.887</td></tr><tr><td>Class_Positive_Precision</td><td>0.91025</td></tr><tr><td>Class_Positive_Recall</td><td>0.86491</td></tr><tr><td>Epoch</td><td>13</td></tr><tr><td>Train Accuracy</td><td>0.97704</td></tr><tr><td>Train Loss</td><td>0.09095</td></tr><tr><td>Validation Accuracy</td><td>0.86516</td></tr><tr><td>Validation F1</td><td>0.86881</td></tr><tr><td>Validation Loss</td><td>0.69193</td></tr><tr><td>Validation Precision</td><td>0.87118</td></tr><tr><td>Validation Recall</td><td>0.86678</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/vwty2oyr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/vwty2oyr</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_035032-vwty2oyr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 04:35:50,868] Trial 8 finished with value: 0.8667395529640428 and parameters: {'learning_rate': 4.073039112389461e-05, 'weight_decay': 2.9371873319203173e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_043551-m6a5p06z</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/m6a5p06z' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/m6a5p06z' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/m6a5p06z</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6695, Val Acc: 0.7699, Val F1: 0.7768, Gap: -0.1004\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8110, Val Acc: 0.8256, Val F1: 0.8321, Gap: -0.0145\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8624, Val Acc: 0.8175, Val F1: 0.8239, Gap: 0.0449\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.8940, Val Acc: 0.8332, Val F1: 0.8374, Gap: 0.0608\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9176, Val Acc: 0.8534, Val F1: 0.8584, Gap: 0.0642\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9282, Val Acc: 0.8631, Val F1: 0.8668, Gap: 0.0651\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9424, Val Acc: 0.8573, Val F1: 0.8617, Gap: 0.0851\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9497, Val Acc: 0.8384, Val F1: 0.8421, Gap: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9559, Val Acc: 0.8581, Val F1: 0.8623, Gap: 0.0977\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9620, Val Acc: 0.8548, Val F1: 0.8584, Gap: 0.1072\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9664, Val Acc: 0.8494, Val F1: 0.8537, Gap: 0.1170\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9695, Val Acc: 0.8569, Val F1: 0.8604, Gap: 0.1126\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9737, Val Acc: 0.8593, Val F1: 0.8628, Gap: 0.1143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9764, Val Acc: 0.8573, Val F1: 0.8617, Gap: 0.1191\n","Early stopping at epoch 14\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▅▅▇▇▇▅█▇▇▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▇▄▂▅▅▅▂▆█▇▆▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▁▆█▆▆▆█▅▃▄▄▃▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▆▅▇█▇▆███▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▅█▆▇▅▆▇▇▅▇▅▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁█▅▃▆▇█▅▇██▆█▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆▇▇█▇▇▆▅▅▇▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▂█▇▇█▅▅▅▅▁▄▅▅▅</td></tr><tr><td>Class_Negative_Recall</td><td>▃▁▃▅▃▆▆▅▅█▅▆▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▃▅▇█▇▆█▇▇██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▆▆▆███▇█▇▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▆▁▄█▇▆▄▇▆▅█▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▃▆███▆▇▇▇██▇</td></tr><tr><td>Class_Positive_Precision</td><td>▅▇▁▄███▅▇▇▆▇▇▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▃██▅▅▅▇▅▅▆▆▆▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▅▆▇██▆█▇▇███</td></tr><tr><td>Validation F1</td><td>▁▅▅▆▇██▆█▇▇▇██</td></tr><tr><td>Validation Loss</td><td>▅▂▃▂▁▂▃▅▃▅▆▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▆▄▅███▆██▇███</td></tr><tr><td>Validation Recall</td><td>▁▄▅▇▇██▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87563</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.87443</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.87682</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82678</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83791</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81594</td></tr><tr><td>Class_Negative_F1</td><td>0.87693</td></tr><tr><td>Class_Negative_Precision</td><td>0.87188</td></tr><tr><td>Class_Negative_Recall</td><td>0.88205</td></tr><tr><td>Class_Neutral_F1</td><td>0.84498</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85156</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83851</td></tr><tr><td>Class_Positive_F1</td><td>0.88439</td></tr><tr><td>Class_Positive_Precision</td><td>0.86341</td></tr><tr><td>Class_Positive_Recall</td><td>0.90642</td></tr><tr><td>Epoch</td><td>14</td></tr><tr><td>Train Accuracy</td><td>0.97635</td></tr><tr><td>Train Loss</td><td>0.09065</td></tr><tr><td>Validation Accuracy</td><td>0.85726</td></tr><tr><td>Validation F1</td><td>0.86174</td></tr><tr><td>Validation Loss</td><td>0.74043</td></tr><tr><td>Validation Precision</td><td>0.85984</td></tr><tr><td>Validation Recall</td><td>0.86395</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/m6a5p06z' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/m6a5p06z</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_043551-m6a5p06z/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 05:24:30,977] Trial 9 finished with value: 0.8630952380952381 and parameters: {'learning_rate': 1.797087273971205e-05, 'weight_decay': 1.9952496987782997e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_052432-w9wv20so</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w9wv20so' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w9wv20so' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w9wv20so</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.5717, Val Acc: 0.6708, Val F1: 0.6826, Gap: -0.0991\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.7121, Val Acc: 0.7421, Val F1: 0.7525, Gap: -0.0300\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.7689, Val Acc: 0.7705, Val F1: 0.7774, Gap: -0.0016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.8063, Val Acc: 0.8015, Val F1: 0.8085, Gap: 0.0048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.8321, Val Acc: 0.8203, Val F1: 0.8266, Gap: 0.0118\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.8516, Val Acc: 0.8147, Val F1: 0.8203, Gap: 0.0368\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.8644, Val Acc: 0.8145, Val F1: 0.8200, Gap: 0.0499\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.8786, Val Acc: 0.8320, Val F1: 0.8377, Gap: 0.0466\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.8880, Val Acc: 0.8458, Val F1: 0.8515, Gap: 0.0422\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.8962, Val Acc: 0.8401, Val F1: 0.8457, Gap: 0.0561\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9005, Val Acc: 0.8455, Val F1: 0.8504, Gap: 0.0550\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9099, Val Acc: 0.8277, Val F1: 0.8318, Gap: 0.0822\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9122, Val Acc: 0.8522, Val F1: 0.8571, Gap: 0.0601\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9183, Val Acc: 0.8460, Val F1: 0.8503, Gap: 0.0723\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.9216, Val Acc: 0.8530, Val F1: 0.8571, Gap: 0.0686\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.9252, Val Acc: 0.8406, Val F1: 0.8452, Gap: 0.0846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.9276, Val Acc: 0.8482, Val F1: 0.8525, Gap: 0.0794\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9285, Val Acc: 0.8602, Val F1: 0.8642, Gap: 0.0683\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9325, Val Acc: 0.8505, Val F1: 0.8548, Gap: 0.0821\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20: Train Acc: 0.9334, Val Acc: 0.8491, Val F1: 0.8545, Gap: 0.0843\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▄▆▆▆▆▇█▇▇▆█▇█▇████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▃▆▆▅▄▆▆▅▅▃▆▅▆▅██▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▁▆▃▃▆▇▆▆▇▇█▆▇▅▇▂▃▇▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▄▆▇▆▆▇▇▇▇▆█▇█▇██▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▅▆▇▆▇▇▆▇▇▇█▇▇█▇▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▃▆▇▅▅▆▇▇▇▅█▆▇▆▇█▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▆▇▇▇███▇█▇█▇███▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▃▄▆▇▆█▇▇▇█▇█▆▇█▆▇██</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▆▆▆▇▅▇▇▇▇▆▇█▇▆██▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▅▆▆▆▇▇▇▇▇▇███▇▇██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▄▅▆▇▇▆▇▇██▇▇▇▇▇▇▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▂▅▇▇▅▆▆▇▇▆▆█▇▇▇▇█▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▄▆▇▆▇▇█▇▇▇████▇█▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▇▆▆▂▅▃▇▆▅▅█▆▆▅▄▇▅▅</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▃▄▆█▇█▇▇██▆█▇██▇▇█</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▇▆▆▇▇▇▇▇█▇█▇████</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▇▆▆▇█▇▇▇█▇█▇████</td></tr><tr><td>Validation Loss</td><td>█▅▄▃▂▂▂▂▁▂▂▃▁▁▁▂▂▁▂▂</td></tr><tr><td>Validation Precision</td><td>▁▄▅▆▇▆▆▇▇▇▇▆█▇█▇▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇▇███▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8673</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85537</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.87956</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8258</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83171</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81997</td></tr><tr><td>Class_Negative_F1</td><td>0.86582</td></tr><tr><td>Class_Negative_Precision</td><td>0.92552</td></tr><tr><td>Class_Negative_Recall</td><td>0.81335</td></tr><tr><td>Class_Neutral_F1</td><td>0.82788</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81919</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83676</td></tr><tr><td>Class_Positive_F1</td><td>0.88546</td></tr><tr><td>Class_Positive_Precision</td><td>0.84452</td></tr><tr><td>Class_Positive_Recall</td><td>0.93057</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.93338</td></tr><tr><td>Train Loss</td><td>0.20782</td></tr><tr><td>Validation Accuracy</td><td>0.84913</td></tr><tr><td>Validation F1</td><td>0.85445</td></tr><tr><td>Validation Loss</td><td>0.50988</td></tr><tr><td>Validation Precision</td><td>0.85526</td></tr><tr><td>Validation Recall</td><td>0.85604</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w9wv20so' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/w9wv20so</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_052432-w9wv20so/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 06:34:19,111] Trial 10 finished with value: 0.8601797862001944 and parameters: {'learning_rate': 5.116354577923487e-06, 'weight_decay': 8.537018034454701e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_063420-2hl4l9pe</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/2hl4l9pe' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/2hl4l9pe' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/2hl4l9pe</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6987, Val Acc: 0.7888, Val F1: 0.7894, Gap: -0.0900\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8347, Val Acc: 0.8237, Val F1: 0.8285, Gap: 0.0110\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8804, Val Acc: 0.8516, Val F1: 0.8550, Gap: 0.0289\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.9094, Val Acc: 0.8417, Val F1: 0.8460, Gap: 0.0676\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9273, Val Acc: 0.8486, Val F1: 0.8529, Gap: 0.0787\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9406, Val Acc: 0.8627, Val F1: 0.8655, Gap: 0.0779\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9489, Val Acc: 0.8424, Val F1: 0.8466, Gap: 0.1065\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9559, Val Acc: 0.8598, Val F1: 0.8637, Gap: 0.0961\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9601, Val Acc: 0.8547, Val F1: 0.8578, Gap: 0.1054\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9651, Val Acc: 0.8492, Val F1: 0.8534, Gap: 0.1158\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9685, Val Acc: 0.8620, Val F1: 0.8661, Gap: 0.1065\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9722, Val Acc: 0.8533, Val F1: 0.8564, Gap: 0.1189\n","Early stopping at epoch 12\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▇▇▇▇███▇█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>█▁█▃▄█▆▆█▄▇▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁█▅█▇▅▆▇▅▇▆█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▇▅▆█▇▇▇▆█▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▆█▆▇█▇▇███</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>█▁▇▂▅▇▅▆▆▃▅▃</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▅▄▇▁▇▄▆█▆</td></tr><tr><td>Class_Negative_Precision</td><td>▅▇██▅█▁▇▄▆█▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▃▁▃▃█▄▆▅▄▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▆▇█▄▇▇▆▇▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▆▃▁▇▃█▆▅▅▅▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▂▆▇▄█▁▅▅▅▅▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▆▆█▇▆█▇▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▄▃▆█▆█▁▄▆▃▂█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▄▃▆▄▇▇▅▇█▄</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▆▇█▆█▇▇█▇</td></tr><tr><td>Validation F1</td><td>▁▅▇▆▇█▆█▇▇█▇</td></tr><tr><td>Validation Loss</td><td>▄▂▁▁▃▃▄▃▅▇▅█</td></tr><tr><td>Validation Precision</td><td>▁▁▆▅▄█▄▆▆▄▆▅</td></tr><tr><td>Validation Recall</td><td>▁▆▆▆▇▇▇█▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85762</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.79455</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.93157</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81707</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84409</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79173</td></tr><tr><td>Class_Negative_F1</td><td>0.88448</td></tr><tr><td>Class_Negative_Precision</td><td>0.87358</td></tr><tr><td>Class_Negative_Recall</td><td>0.89566</td></tr><tr><td>Class_Neutral_F1</td><td>0.84837</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84469</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85208</td></tr><tr><td>Class_Positive_F1</td><td>0.87446</td></tr><tr><td>Class_Positive_Precision</td><td>0.92</td></tr><tr><td>Class_Positive_Recall</td><td>0.83321</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97218</td></tr><tr><td>Train Loss</td><td>0.10209</td></tr><tr><td>Validation Accuracy</td><td>0.85326</td></tr><tr><td>Validation F1</td><td>0.8564</td></tr><tr><td>Validation Loss</td><td>0.7025</td></tr><tr><td>Validation Precision</td><td>0.85538</td></tr><tr><td>Validation Recall</td><td>0.86085</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/2hl4l9pe' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/2hl4l9pe</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_063420-2hl4l9pe/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 07:16:14,392] Trial 11 finished with value: 0.8627308066083577 and parameters: {'learning_rate': 4.6020228116311725e-05, 'weight_decay': 2.0384748978461647e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_071615-zxowh2vg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/zxowh2vg' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/zxowh2vg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/zxowh2vg</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6974, Val Acc: 0.7824, Val F1: 0.7869, Gap: -0.0850\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.8355, Val Acc: 0.8079, Val F1: 0.8148, Gap: 0.0275\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8810, Val Acc: 0.8426, Val F1: 0.8466, Gap: 0.0385\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.9091, Val Acc: 0.8506, Val F1: 0.8553, Gap: 0.0585\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.9279, Val Acc: 0.8073, Val F1: 0.8115, Gap: 0.1206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.9388, Val Acc: 0.8316, Val F1: 0.8349, Gap: 0.1072\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9461, Val Acc: 0.8543, Val F1: 0.8581, Gap: 0.0918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9534, Val Acc: 0.8537, Val F1: 0.8584, Gap: 0.0997\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9597, Val Acc: 0.8622, Val F1: 0.8657, Gap: 0.0975\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9653, Val Acc: 0.8403, Val F1: 0.8440, Gap: 0.1251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9669, Val Acc: 0.8533, Val F1: 0.8558, Gap: 0.1136\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9700, Val Acc: 0.8541, Val F1: 0.8574, Gap: 0.1159\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20: Train Acc: 0.9722, Val Acc: 0.8427, Val F1: 0.8464, Gap: 0.1295\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20: Train Acc: 0.9747, Val Acc: 0.8632, Val F1: 0.8671, Gap: 0.1114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20: Train Acc: 0.9760, Val Acc: 0.8482, Val F1: 0.8516, Gap: 0.1279\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20: Train Acc: 0.9788, Val Acc: 0.8607, Val F1: 0.8648, Gap: 0.1181\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20: Train Acc: 0.9789, Val Acc: 0.8646, Val F1: 0.8683, Gap: 0.1144\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20: Train Acc: 0.9808, Val Acc: 0.8602, Val F1: 0.8631, Gap: 0.1206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20: Train Acc: 0.9818, Val Acc: 0.8574, Val F1: 0.8612, Gap: 0.1244\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20: Train Acc: 0.9819, Val Acc: 0.8633, Val F1: 0.8661, Gap: 0.1185\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▆▇▃▆▇█▇▇█▇▇█▆▇█▇▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▄▆▂▅▆▇▇▇█▅▅▇▄▇▇▆▇█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▆▆▄█▆▅▃▂▂▂▆▆▄▇▃▄▄▃▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▆▇▄▆▇▇█▆█▇▆█▆██▇██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆█▃▄▄▇▇▄▇▆█▅▆▅▆▆▇▆▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▅▇▃▆▆▇█▅▇▆▆█▅▇█▆▇█</td></tr><tr><td>Class_Negative_F1</td><td>▂▄▆▅▄▄▆▆▆▁▆▅▄▅█▇▆▇▅█</td></tr><tr><td>Class_Negative_Precision</td><td>▅▇▇▇█▆▅▅▇▁▅▄▆▅▇▇▅▆▃▆</td></tr><tr><td>Class_Negative_Recall</td><td>▃▂▄▃▁▄▇▆▄█▇█▄▇▆▄▇▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▃▁▆▇▄▆▇▆█▇▇█▇█▇▇██▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▆▆▁▄▆▅▃▂▇▃▆▆▄██▇▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▁▅▅▂▆▇▅▇▇█▆▇▆▆▇▆▆▅▇</td></tr><tr><td>Class_Positive_F1</td><td>▃▁▆▆▃▂▆▆█▆▃█▄▇▆▇██▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>▅▁▄▆▂█▇▄▇▇█▇▇▇▇▆▆▅▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>▄██▅█▁▄█▅▄▂▆▃▅▄▆▆▇▆▄</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇▇▇███████████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▇▃▅▇▇█▆▇▇▆█▇███▇█</td></tr><tr><td>Validation F1</td><td>▁▃▆▇▃▅▇▇█▆▇▇▆█▇███▇█</td></tr><tr><td>Validation Loss</td><td>▃▂▁▁▅▄▂▃▃▅▅▄▅▆█▆▆▇▆▆</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▃▅▇▆█▆█▆▆▇▆▇▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▇▇▄▄▇▇▇▅▅▇▆█▇▇██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85851</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.90161</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.81934</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.84309</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82655</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.86031</td></tr><tr><td>Class_Negative_F1</td><td>0.90261</td></tr><tr><td>Class_Negative_Precision</td><td>0.91035</td></tr><tr><td>Class_Negative_Recall</td><td>0.89501</td></tr><tr><td>Class_Neutral_F1</td><td>0.85129</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8153</td></tr><tr><td>Class_Neutral_Recall</td><td>0.89059</td></tr><tr><td>Class_Positive_F1</td><td>0.8752</td></tr><tr><td>Class_Positive_Precision</td><td>0.93788</td></tr><tr><td>Class_Positive_Recall</td><td>0.82038</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.98186</td></tr><tr><td>Train Loss</td><td>0.07249</td></tr><tr><td>Validation Accuracy</td><td>0.86334</td></tr><tr><td>Validation F1</td><td>0.86614</td></tr><tr><td>Validation Loss</td><td>0.77498</td></tr><tr><td>Validation Precision</td><td>0.87834</td></tr><tr><td>Validation Recall</td><td>0.85713</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/zxowh2vg' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/zxowh2vg</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_071615-zxowh2vg/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 08:25:57,214] Trial 12 finished with value: 0.8645529640427599 and parameters: {'learning_rate': 4.879765030253772e-05, 'weight_decay': 3.0302255919226006e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 3 with value: 0.8675898931000972.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_082558-u1tkbfy3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/u1tkbfy3' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/u1tkbfy3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_666/runs/u1tkbfy3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/20: Train Acc: 0.6291, Val Acc: 0.7274, Val F1: 0.7382, Gap: -0.0983\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/20: Train Acc: 0.7687, Val Acc: 0.7761, Val F1: 0.7828, Gap: -0.0074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/20: Train Acc: 0.8260, Val Acc: 0.8257, Val F1: 0.8316, Gap: 0.0003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/20: Train Acc: 0.8569, Val Acc: 0.8253, Val F1: 0.8320, Gap: 0.0316\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/20: Train Acc: 0.8786, Val Acc: 0.8112, Val F1: 0.8149, Gap: 0.0674\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/20: Train Acc: 0.8953, Val Acc: 0.8454, Val F1: 0.8501, Gap: 0.0500\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/20: Train Acc: 0.9089, Val Acc: 0.8305, Val F1: 0.8353, Gap: 0.0784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/20: Train Acc: 0.9191, Val Acc: 0.8426, Val F1: 0.8484, Gap: 0.0766\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/20: Train Acc: 0.9267, Val Acc: 0.8467, Val F1: 0.8510, Gap: 0.0801\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20: Train Acc: 0.9329, Val Acc: 0.8553, Val F1: 0.8596, Gap: 0.0776\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20: Train Acc: 0.9378, Val Acc: 0.8581, Val F1: 0.8625, Gap: 0.0797\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20: Train Acc: 0.9429, Val Acc: 0.8595, Val F1: 0.8634, Gap: 0.0835\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n","[W 2025-08-07 09:09:02,760] Trial 13 failed with parameters: {'learning_rate': 9.369850790707184e-06, 'weight_decay': 9.072604585299779e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False} because of the following error: KeyboardInterrupt().\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"/tmp/ipython-input-2760107258.py\", line 93, in objective\n","    best_val_accuracy = train_model_with_hyperparams(\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/tmp/ipython-input-748624337.py\", line 37, in train_model_with_hyperparams\n","    train_loss += loss.item() * input_ids.size(0)\n","                  ^^^^^^^^^^^\n","KeyboardInterrupt\n","[W 2025-08-07 09:09:02,762] Trial 13 failed with value None.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3053599032.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Study 6:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstudy6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m--> 489\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     ):\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2760107258.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, learning_rate_from, learning_rate_to, weight_decay_from, weight_decay_to, patience_choices, batch_size_choices, num_layers_choices, dropout_rate_choices, gradient_clip_val_choices, use_class_weights_choices, enable_gradient_clipping, enable_class_weights)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Train with optional gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     best_val_accuracy = train_model_with_hyperparams(\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-748624337.py\u001b[0m in \u001b[0;36mtrain_model_with_hyperparams\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial, gradient_clip_val)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Accumulate training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mtotal_train_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mcorrect_train_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 6:\")\n","study6 = optuna.create_study(direction=\"maximize\")\n","study6.optimize(objective, n_trials=25)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study6.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model6.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"pcw8Fsynxdxs","outputId":"d9b6be83-26cc-4bb2-8290-8e14c459fb54"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 09:15:59,219] A new study created in memory with name: no-name-0ca1a817-c9f0-487c-8428-61fdd6763a31\n"]},{"name":"stdout","output_type":"stream","text":["Starting Study 6.1:\n","Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Finishing previous runs because reinit is set to 'default'."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/ivugc6wc' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/ivugc6wc</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_091503-ivugc6wc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_091600-lkjknufr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/lkjknufr' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/lkjknufr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/lkjknufr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6950, Val Acc: 0.7235, Val F1: 0.7295, Gap: -0.0286\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8308, Val Acc: 0.8338, Val F1: 0.8405, Gap: -0.0030\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8777, Val Acc: 0.8551, Val F1: 0.8607, Gap: 0.0226\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.9097, Val Acc: 0.8511, Val F1: 0.8554, Gap: 0.0586\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9267, Val Acc: 0.8273, Val F1: 0.8301, Gap: 0.0995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9404, Val Acc: 0.8422, Val F1: 0.8469, Gap: 0.0982\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9480, Val Acc: 0.8540, Val F1: 0.8574, Gap: 0.0940\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9559, Val Acc: 0.8421, Val F1: 0.8454, Gap: 0.1138\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9602, Val Acc: 0.8497, Val F1: 0.8538, Gap: 0.1105\n","Early stopping at epoch 9\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▇█▇▄██▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▇██▃▆▇▅▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▃▃▁█▆▄▆▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▇██▅▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▇▄▅█▆█▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▇█▄▆▇▅▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▆█▇▇█▇▆▆</td></tr><tr><td>Class_Negative_Precision</td><td>▅▆▇█▄▄▃▁▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▅▄▇█▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇██▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▁▂▄▇▇▄▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇█▇▇▆█▆▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▇███▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▆▇▇█▅█▆▇</td></tr><tr><td>Class_Positive_Recall</td><td>█▅▄▄▃█▁▆▅</td></tr><tr><td>Epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▇██▇▇█▇█</td></tr><tr><td>Validation F1</td><td>▁▇██▆▇█▇█</td></tr><tr><td>Validation Loss</td><td>█▂▁▁▅▄▅▇▅</td></tr><tr><td>Validation Precision</td><td>▁▇██▆▇█▆▇</td></tr><tr><td>Validation Recall</td><td>▁▆█▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85911</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81169</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91241</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81352</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82665</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80081</td></tr><tr><td>Class_Negative_F1</td><td>0.87415</td></tr><tr><td>Class_Negative_Precision</td><td>0.87728</td></tr><tr><td>Class_Negative_Recall</td><td>0.87103</td></tr><tr><td>Class_Neutral_F1</td><td>0.84072</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85995</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82232</td></tr><tr><td>Class_Positive_F1</td><td>0.88128</td></tr><tr><td>Class_Positive_Precision</td><td>0.86931</td></tr><tr><td>Class_Positive_Recall</td><td>0.89358</td></tr><tr><td>Epoch</td><td>9</td></tr><tr><td>Train Accuracy</td><td>0.96021</td></tr><tr><td>Train Loss</td><td>0.13675</td></tr><tr><td>Validation Accuracy</td><td>0.84973</td></tr><tr><td>Validation F1</td><td>0.85375</td></tr><tr><td>Validation Loss</td><td>0.5526</td></tr><tr><td>Validation Precision</td><td>0.84898</td></tr><tr><td>Validation Recall</td><td>0.86003</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/lkjknufr' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/lkjknufr</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_091600-lkjknufr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 09:47:19,492] Trial 0 finished with value: 0.8550777453838678 and parameters: {'learning_rate': 3.740288718227735e-05, 'weight_decay': 3.881366780412982e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 0 with value: 0.8550777453838678.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_094720-7vjrl6js</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7vjrl6js' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7vjrl6js' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7vjrl6js</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6876, Val Acc: 0.7768, Val F1: 0.7833, Gap: -0.0892\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8280, Val Acc: 0.8149, Val F1: 0.8218, Gap: 0.0132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8791, Val Acc: 0.8457, Val F1: 0.8513, Gap: 0.0334\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.9078, Val Acc: 0.8501, Val F1: 0.8550, Gap: 0.0577\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9297, Val Acc: 0.8486, Val F1: 0.8526, Gap: 0.0811\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9416, Val Acc: 0.8460, Val F1: 0.8498, Gap: 0.0956\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9508, Val Acc: 0.8605, Val F1: 0.8645, Gap: 0.0903\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9573, Val Acc: 0.8488, Val F1: 0.8540, Gap: 0.1086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9624, Val Acc: 0.8531, Val F1: 0.8573, Gap: 0.1093\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9661, Val Acc: 0.8322, Val F1: 0.8360, Gap: 0.1339\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9716, Val Acc: 0.8601, Val F1: 0.8636, Gap: 0.1115\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9752, Val Acc: 0.8451, Val F1: 0.8489, Gap: 0.1301\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅█▇▇▇██▇▆█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▆▅▅█▆▆▆▄▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▄▆█▇▁▆▆▆▇▆▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▇▇▇▇█▇█▆█▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▅▅▇█▆▃▆▇▆█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▇▇▆▆██▇▄▇▅</td></tr><tr><td>Class_Negative_F1</td><td>▂▁▇█▅▃▇▅▆▄█▄</td></tr><tr><td>Class_Negative_Precision</td><td>▄▇▇▆▃▁▅█▄▂▆▃</td></tr><tr><td>Class_Negative_Recall</td><td>▄▁▅▅▇█▆▂▆▇▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▇▇▆█▇▇▆█▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▂▁▆▇█▇▆▅▆█▄▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▄▅▅▅▇▆▆▄█▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆██▇█▇▇▅▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▃▅▅▄▇▅▆▃█▄</td></tr><tr><td>Class_Positive_Recall</td><td>▆▆█▇▇▇▃▅▅▇▁▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▇▇▇█▇▇▆█▇</td></tr><tr><td>Validation F1</td><td>▁▄▇▇▇▇█▇▇▆█▇</td></tr><tr><td>Validation Loss</td><td>▄▂▁▂▂▄▃▅▅▇▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▆▇█▇▇▅█▆</td></tr><tr><td>Validation Recall</td><td>▁▃▇██▇█▇█▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85883</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85456</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.86314</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80276</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84628</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.76349</td></tr><tr><td>Class_Negative_F1</td><td>0.86078</td></tr><tr><td>Class_Negative_Precision</td><td>0.84649</td></tr><tr><td>Class_Negative_Recall</td><td>0.87557</td></tr><tr><td>Class_Neutral_F1</td><td>0.84124</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83614</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84639</td></tr><tr><td>Class_Positive_F1</td><td>0.88081</td></tr><tr><td>Class_Positive_Precision</td><td>0.84933</td></tr><tr><td>Class_Positive_Recall</td><td>0.91472</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97517</td></tr><tr><td>Train Loss</td><td>0.08831</td></tr><tr><td>Validation Accuracy</td><td>0.84512</td></tr><tr><td>Validation F1</td><td>0.84888</td></tr><tr><td>Validation Loss</td><td>0.7818</td></tr><tr><td>Validation Precision</td><td>0.84656</td></tr><tr><td>Validation Recall</td><td>0.85266</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7vjrl6js' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7vjrl6js</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_094720-7vjrl6js/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 10:29:34,743] Trial 1 finished with value: 0.8605442176870748 and parameters: {'learning_rate': 2.6841946207860913e-05, 'weight_decay': 1.3714716603653429e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_102935-s7k8t63q</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/s7k8t63q' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/s7k8t63q' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/s7k8t63q</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.5676, Val Acc: 0.6441, Val F1: 0.6566, Gap: -0.0765\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.7101, Val Acc: 0.7293, Val F1: 0.7400, Gap: -0.0192\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.7654, Val Acc: 0.7676, Val F1: 0.7757, Gap: -0.0022\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8013, Val Acc: 0.8013, Val F1: 0.8080, Gap: 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.8298, Val Acc: 0.7952, Val F1: 0.8027, Gap: 0.0346\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.8466, Val Acc: 0.8211, Val F1: 0.8274, Gap: 0.0255\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.8667, Val Acc: 0.8245, Val F1: 0.8307, Gap: 0.0422\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.8761, Val Acc: 0.8371, Val F1: 0.8434, Gap: 0.0390\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.8900, Val Acc: 0.8344, Val F1: 0.8396, Gap: 0.0556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9009, Val Acc: 0.8467, Val F1: 0.8519, Gap: 0.0542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9105, Val Acc: 0.8477, Val F1: 0.8535, Gap: 0.0628\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9169, Val Acc: 0.8469, Val F1: 0.8518, Gap: 0.0699\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▄▅▆▇▇█▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▃▅▅▆▇█▅▇█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▃▆▅▆▆▅▆█▇▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▆▆▇▇█▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▅▆▇▇▆▇▇▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▃▆▅▆██▆█▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇▇▇▇████</td></tr><tr><td>Class_Negative_Precision</td><td>▂▁▃▄▆▆▇█▇▆▇▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▆▇▇▇▇▇████</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆▇▆▇▇▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▆▆▇█▇█▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▅▆▅▆▆▇▇███</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▆▅▇▇█████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▃▅▆▃▅▅▆▆█▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▂▃███▇▇▃█▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▆▇▇█████</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▆▇▇█████</td></tr><tr><td>Validation Loss</td><td>█▅▄▂▂▂▂▁▁▂▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▆▇▇█▇███</td></tr><tr><td>Validation Recall</td><td>▁▄▅▆▆▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85875</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81766</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.9042</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8125</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81874</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80635</td></tr><tr><td>Class_Negative_F1</td><td>0.86915</td></tr><tr><td>Class_Negative_Precision</td><td>0.91116</td></tr><tr><td>Class_Negative_Recall</td><td>0.83085</td></tr><tr><td>Class_Neutral_F1</td><td>0.83403</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83568</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83239</td></tr><tr><td>Class_Positive_F1</td><td>0.88446</td></tr><tr><td>Class_Positive_Precision</td><td>0.86561</td></tr><tr><td>Class_Positive_Recall</td><td>0.90415</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.91686</td></tr><tr><td>Train Loss</td><td>0.25341</td></tr><tr><td>Validation Accuracy</td><td>0.84694</td></tr><tr><td>Validation F1</td><td>0.85178</td></tr><tr><td>Validation Loss</td><td>0.48273</td></tr><tr><td>Validation Precision</td><td>0.84977</td></tr><tr><td>Validation Recall</td><td>0.85559</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/s7k8t63q' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/s7k8t63q</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_102935-s7k8t63q/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 11:11:30,193] Trial 2 finished with value: 0.847667638483965 and parameters: {'learning_rate': 4.75922576323816e-06, 'weight_decay': 8.019653132269685e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_111131-ux8y1box</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/ux8y1box' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/ux8y1box' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/ux8y1box</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6249, Val Acc: 0.7114, Val F1: 0.7206, Gap: -0.0864\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.7708, Val Acc: 0.7871, Val F1: 0.7951, Gap: -0.0163\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8265, Val Acc: 0.8022, Val F1: 0.8088, Gap: 0.0243\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8583, Val Acc: 0.8222, Val F1: 0.8280, Gap: 0.0362\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.8860, Val Acc: 0.8213, Val F1: 0.8265, Gap: 0.0647\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9042, Val Acc: 0.8412, Val F1: 0.8452, Gap: 0.0629\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9167, Val Acc: 0.8392, Val F1: 0.8426, Gap: 0.0775\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9317, Val Acc: 0.8461, Val F1: 0.8505, Gap: 0.0856\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9389, Val Acc: 0.8383, Val F1: 0.8414, Gap: 0.1006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9483, Val Acc: 0.8522, Val F1: 0.8555, Gap: 0.0961\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9547, Val Acc: 0.8513, Val F1: 0.8553, Gap: 0.1034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9603, Val Acc: 0.8495, Val F1: 0.8530, Gap: 0.1108\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆▇▇▇▇█▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▄▄▄▆▄▆▃█▆▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▂▆▇▆▄▇▄█▁▅▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▅▆▆▇▇█▇██▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▇▆▆▇█▆▇▆██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▄▅▅▆▄▇▅█▆▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▇▆▇▇█▇▇█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆██▆▆▇▇▆▆▇</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▂▁█▆▆▅██▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▆▆▇█▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▆▇█▇██▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▄▆▅▆█▆▇█▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▆▆▇█▇████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▁▄▂▃▆▄▆█▄▆</td></tr><tr><td>Class_Positive_Recall</td><td>▁▅▇▆▇▇▇▇▆▅█▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▆▇▇█▇███</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▆▇▇█▇███</td></tr><tr><td>Validation Loss</td><td>█▄▃▂▂▁▂▃▄▃▆▅</td></tr><tr><td>Validation Precision</td><td>▁▅▅▆▆▇▇▇▇█▇▇</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▇▇▇█▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85415</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.78992</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92974</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80574</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83541</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77811</td></tr><tr><td>Class_Negative_F1</td><td>0.86858</td></tr><tr><td>Class_Negative_Precision</td><td>0.89485</td></tr><tr><td>Class_Negative_Recall</td><td>0.84381</td></tr><tr><td>Class_Neutral_F1</td><td>0.84933</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84274</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85602</td></tr><tr><td>Class_Positive_F1</td><td>0.88729</td></tr><tr><td>Class_Positive_Precision</td><td>0.88931</td></tr><tr><td>Class_Positive_Recall</td><td>0.88528</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96031</td></tr><tr><td>Train Loss</td><td>0.13197</td></tr><tr><td>Validation Accuracy</td><td>0.84949</td></tr><tr><td>Validation F1</td><td>0.85302</td></tr><tr><td>Validation Loss</td><td>0.63414</td></tr><tr><td>Validation Precision</td><td>0.85045</td></tr><tr><td>Validation Recall</td><td>0.85859</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/ux8y1box' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/ux8y1box</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_111131-ux8y1box/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 11:53:20,746] Trial 3 finished with value: 0.8521622934888241 and parameters: {'learning_rate': 9.180284502887812e-06, 'weight_decay': 1.4418024242339149e-05, 'patience': 3, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_115321-aorf4n0a</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/aorf4n0a' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/aorf4n0a' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/aorf4n0a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.5878, Val Acc: 0.6809, Val F1: 0.6928, Gap: -0.0931\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.7335, Val Acc: 0.7309, Val F1: 0.7407, Gap: 0.0026\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.7871, Val Acc: 0.7680, Val F1: 0.7752, Gap: 0.0191\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8239, Val Acc: 0.7983, Val F1: 0.8058, Gap: 0.0256\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.8460, Val Acc: 0.8022, Val F1: 0.8102, Gap: 0.0438\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.8682, Val Acc: 0.8197, Val F1: 0.8262, Gap: 0.0485\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.8851, Val Acc: 0.8389, Val F1: 0.8440, Gap: 0.0462\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.8980, Val Acc: 0.8315, Val F1: 0.8370, Gap: 0.0665\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9115, Val Acc: 0.8310, Val F1: 0.8365, Gap: 0.0805\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9206, Val Acc: 0.8420, Val F1: 0.8462, Gap: 0.0786\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9293, Val Acc: 0.8448, Val F1: 0.8489, Gap: 0.0846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9387, Val Acc: 0.8236, Val F1: 0.8281, Gap: 0.1151\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▃▆▇▇█████▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▂▁▅▇▇█▇▇▇▇▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▆█▆▅▆▅▇▆▇▇█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▄▆▇▇█▇▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▄▇▇▇▇████</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▃▃▇▆▇█▇▆▆█▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▂▅▆▆▇▇▇▇▇█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▆▆▇███▇█▆▇▆</td></tr><tr><td>Class_Negative_Recall</td><td>▄▁▆▆▅▅▇▆▆██▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▅▆▅▇█▇▇██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▅▆▅▆▇▇▆▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃▅▆▅▇▇▇▇█▇▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▆▅▇█▇▇█▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▆▇▂▅▇▆▆█▆▄</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▂▂█▆▆▇▇▅▇█</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▆▇█▇▇██▇</td></tr><tr><td>Validation F1</td><td>▁▃▅▆▆▇█▇▇██▇</td></tr><tr><td>Validation Loss</td><td>█▆▄▃▃▂▁▁▂▂▂▄</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▆▇█████▇</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▆▇█▇▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84025</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.77735</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91423</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.79166</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81965</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.76551</td></tr><tr><td>Class_Negative_F1</td><td>0.85209</td></tr><tr><td>Class_Negative_Precision</td><td>0.87879</td></tr><tr><td>Class_Negative_Recall</td><td>0.82696</td></tr><tr><td>Class_Neutral_F1</td><td>0.80395</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84656</td></tr><tr><td>Class_Neutral_Recall</td><td>0.76543</td></tr><tr><td>Class_Positive_F1</td><td>0.85231</td></tr><tr><td>Class_Positive_Precision</td><td>0.78512</td></tr><tr><td>Class_Positive_Recall</td><td>0.93208</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.93871</td></tr><tr><td>Train Loss</td><td>0.19181</td></tr><tr><td>Validation Accuracy</td><td>0.82362</td></tr><tr><td>Validation F1</td><td>0.82805</td></tr><tr><td>Validation Loss</td><td>0.6391</td></tr><tr><td>Validation Precision</td><td>0.8215</td></tr><tr><td>Validation Recall</td><td>0.84084</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/aorf4n0a' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/aorf4n0a</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_115321-aorf4n0a/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 12:35:10,208] Trial 4 finished with value: 0.8447521865889213 and parameters: {'learning_rate': 5.975520854116029e-06, 'weight_decay': 2.941442601053814e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_123511-7os9nwng</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7os9nwng' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7os9nwng' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7os9nwng</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.7008, Val Acc: 0.8084, Val F1: 0.8151, Gap: -0.1076\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8315, Val Acc: 0.8267, Val F1: 0.8329, Gap: 0.0048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8795, Val Acc: 0.8260, Val F1: 0.8309, Gap: 0.0534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.9085, Val Acc: 0.8415, Val F1: 0.8476, Gap: 0.0671\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9244, Val Acc: 0.8375, Val F1: 0.8435, Gap: 0.0869\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9366, Val Acc: 0.8427, Val F1: 0.8475, Gap: 0.0940\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9444, Val Acc: 0.8435, Val F1: 0.8472, Gap: 0.1008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9514, Val Acc: 0.8439, Val F1: 0.8473, Gap: 0.1075\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9553, Val Acc: 0.8352, Val F1: 0.8391, Gap: 0.1201\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9601, Val Acc: 0.8421, Val F1: 0.8458, Gap: 0.1180\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9633, Val Acc: 0.8488, Val F1: 0.8524, Gap: 0.1146\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9674, Val Acc: 0.8421, Val F1: 0.8464, Gap: 0.1254\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▂▇▇█▇▅▄▃▆▅</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▃▁▅█▅▃▃▂▂▃▂</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▄█▆▁▆█▇▇▇▇▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▃▇█▇▇▆▅▄▆▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▂▁▅▅▅▇▆█▆▇▅▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃█▃▆▆▄▅▁▃▁▅▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆█▆▅▄▄▇▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▄▅▅█▆▃▂▂▁█▄▄</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▄▁▅▇█▆█▂▆▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▃▄▃▅▇▇▅▇█▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▇▄▄▆▄▄▇▃▅█</td></tr><tr><td>Class_Neutral_Recall</td><td>▂▃▁▄▂▃▇▇▂█▇▃</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▄▆▄▅▄█▆█▇▆</td></tr><tr><td>Class_Positive_Precision</td><td>▄▆▂▃▁▂█▄▃▄▇▄</td></tr><tr><td>Class_Positive_Recall</td><td>▃▃▇▇█▇▁▆▆▆▃▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▄▇▆▇▇▇▆▇█▇</td></tr><tr><td>Validation F1</td><td>▁▄▄▇▆▇▇▇▅▇█▇</td></tr><tr><td>Validation Loss</td><td>▃▃▂▁▄▅▆▄▅▇▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▃▇▇▆█▆▄▇█▆</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▆█▇█▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84777</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.78627</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91971</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80275</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81038</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.79526</td></tr><tr><td>Class_Negative_F1</td><td>0.8844</td></tr><tr><td>Class_Negative_Precision</td><td>0.88874</td></tr><tr><td>Class_Negative_Recall</td><td>0.8801</td></tr><tr><td>Class_Neutral_F1</td><td>0.82736</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87011</td></tr><tr><td>Class_Neutral_Recall</td><td>0.78862</td></tr><tr><td>Class_Positive_F1</td><td>0.8696</td></tr><tr><td>Class_Positive_Precision</td><td>0.84484</td></tr><tr><td>Class_Positive_Recall</td><td>0.89585</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96744</td></tr><tr><td>Train Loss</td><td>0.11599</td></tr><tr><td>Validation Accuracy</td><td>0.84208</td></tr><tr><td>Validation F1</td><td>0.84638</td></tr><tr><td>Validation Loss</td><td>0.73332</td></tr><tr><td>Validation Precision</td><td>0.84007</td></tr><tr><td>Validation Recall</td><td>0.85591</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7os9nwng' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/7os9nwng</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_123511-7os9nwng/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 13:17:06,609] Trial 5 finished with value: 0.8487609329446064 and parameters: {'learning_rate': 4.2098185784722224e-05, 'weight_decay': 5.650607876552994e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_131707-fmotj8yc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/fmotj8yc' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/fmotj8yc' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/fmotj8yc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.5569, Val Acc: 0.5980, Val F1: 0.6118, Gap: -0.0412\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.6941, Val Acc: 0.7211, Val F1: 0.7316, Gap: -0.0270\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.7504, Val Acc: 0.6905, Val F1: 0.7003, Gap: 0.0599\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.7879, Val Acc: 0.7749, Val F1: 0.7835, Gap: 0.0130\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.8149, Val Acc: 0.7762, Val F1: 0.7838, Gap: 0.0387\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.8338, Val Acc: 0.8038, Val F1: 0.8103, Gap: 0.0300\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.8538, Val Acc: 0.7817, Val F1: 0.7884, Gap: 0.0721\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.8682, Val Acc: 0.8060, Val F1: 0.8121, Gap: 0.0622\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.8804, Val Acc: 0.8174, Val F1: 0.8249, Gap: 0.0630\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.8943, Val Acc: 0.8369, Val F1: 0.8420, Gap: 0.0574\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9020, Val Acc: 0.8331, Val F1: 0.8387, Gap: 0.0689\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9123, Val Acc: 0.8335, Val F1: 0.8381, Gap: 0.0788\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▄▇▆▇▆▇████</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▃▆▅▆▅▅█▇▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>█▂█▄▇▆▇█▁▅▆▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▄▇▆▇▇▇████</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▆▆▆▆▇▇█▇██</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▃▇▆▇▆▇███▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▅▆▇▇▇▇▇███</td></tr><tr><td>Class_Negative_Precision</td><td>▁▂▆▆▇▇███▇█▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▄▆▆▇▆▆▆█▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▂▆▆▇▆▇▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▂▆▇▆▇▇▆▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▂▅▆▇▅▆▇█▇█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▂▆▆▇▅▇▇███</td></tr><tr><td>Class_Positive_Precision</td><td>▄▅▁▅▆▇▃▆▅█▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▄▇▅▆▅█▇▇▅▇▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▄▆▆▇▆▇▇███</td></tr><tr><td>Validation F1</td><td>▁▅▄▆▆▇▆▇▇███</td></tr><tr><td>Validation Loss</td><td>█▄▅▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▄▄▆▆▇▆▇████</td></tr><tr><td>Validation Recall</td><td>▁▄▄▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.8381</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.76725</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92336</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.7856</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80126</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.77055</td></tr><tr><td>Class_Negative_F1</td><td>0.86364</td></tr><tr><td>Class_Negative_Precision</td><td>0.8781</td></tr><tr><td>Class_Negative_Recall</td><td>0.84964</td></tr><tr><td>Class_Neutral_F1</td><td>0.82826</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83563</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82101</td></tr><tr><td>Class_Positive_F1</td><td>0.87466</td></tr><tr><td>Class_Positive_Precision</td><td>0.89432</td></tr><tr><td>Class_Positive_Recall</td><td>0.85585</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.9123</td></tr><tr><td>Train Loss</td><td>0.25918</td></tr><tr><td>Validation Accuracy</td><td>0.83345</td></tr><tr><td>Validation F1</td><td>0.83805</td></tr><tr><td>Validation Loss</td><td>0.52915</td></tr><tr><td>Validation Precision</td><td>0.83531</td></tr><tr><td>Validation Recall</td><td>0.84408</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/fmotj8yc' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/fmotj8yc</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_131707-fmotj8yc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 13:59:02,543] Trial 6 finished with value: 0.8368561710398446 and parameters: {'learning_rate': 4.144899759821672e-06, 'weight_decay': 1.4404174661789449e-06, 'patience': 3, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.4, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_135903-zwkj7rj5</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/zwkj7rj5' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/zwkj7rj5' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/zwkj7rj5</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6418, Val Acc: 0.7176, Val F1: 0.7289, Gap: -0.0758\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.7851, Val Acc: 0.7864, Val F1: 0.7934, Gap: -0.0014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8401, Val Acc: 0.8338, Val F1: 0.8399, Gap: 0.0063\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8715, Val Acc: 0.8384, Val F1: 0.8444, Gap: 0.0331\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.8973, Val Acc: 0.8531, Val F1: 0.8575, Gap: 0.0441\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9163, Val Acc: 0.8389, Val F1: 0.8441, Gap: 0.0774\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9311, Val Acc: 0.8388, Val F1: 0.8431, Gap: 0.0923\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9413, Val Acc: 0.8543, Val F1: 0.8589, Gap: 0.0870\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9495, Val Acc: 0.8328, Val F1: 0.8378, Gap: 0.1167\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9562, Val Acc: 0.8536, Val F1: 0.8568, Gap: 0.1026\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9607, Val Acc: 0.8426, Val F1: 0.8470, Gap: 0.1182\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9661, Val Acc: 0.8499, Val F1: 0.8536, Gap: 0.1162\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁▆▅▇▅▄▇▄█▄▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃█▃▇▃▇▇▄▇▁█▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▇▇█▇▇█▇█▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▆▇▆█▇▇▆▆▇█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▆▅█▅▆▇▅▇▅▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇▇█▇▆█▆▇▇▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄▅▆█▇▅▃▆▄▄▆▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▆▆▇▇▇▇▆█▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇█▇▇▇▇█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅▅▆▆█▇▇▆██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▆▇▇▆▅▆▅█▆▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▅▆▇▅▅▅▅█▅▇</td></tr><tr><td>Class_Positive_Recall</td><td>▅▁▆▆▅█▇██▃█▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇█▇▇█▇█▇█</td></tr><tr><td>Validation F1</td><td>▁▄▇▇█▇▇█▇█▇█</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▁▃▃▄▆▆▇█</td></tr><tr><td>Validation Precision</td><td>▁▄▇▇█▇▆▇▆█▇▇</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇████▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85886</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.8127</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.91058</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.8151</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84276</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78921</td></tr><tr><td>Class_Negative_F1</td><td>0.85669</td></tr><tr><td>Class_Negative_Precision</td><td>0.8316</td></tr><tr><td>Class_Negative_Recall</td><td>0.88334</td></tr><tr><td>Class_Neutral_F1</td><td>0.84486</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8648</td></tr><tr><td>Class_Neutral_Recall</td><td>0.82582</td></tr><tr><td>Class_Positive_F1</td><td>0.89249</td></tr><tr><td>Class_Positive_Precision</td><td>0.89216</td></tr><tr><td>Class_Positive_Recall</td><td>0.89283</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96605</td></tr><tr><td>Train Loss</td><td>0.1135</td></tr><tr><td>Validation Accuracy</td><td>0.84985</td></tr><tr><td>Validation F1</td><td>0.8536</td></tr><tr><td>Validation Loss</td><td>0.71557</td></tr><tr><td>Validation Precision</td><td>0.84881</td></tr><tr><td>Validation Recall</td><td>0.86036</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/zwkj7rj5' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/zwkj7rj5</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_135903-zwkj7rj5/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 14:40:59,983] Trial 7 finished with value: 0.8543488824101069 and parameters: {'learning_rate': 1.1580944703526558e-05, 'weight_decay': 2.924903932190811e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.1, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_144101-xklwr069</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/xklwr069' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/xklwr069' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/xklwr069</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6697, Val Acc: 0.7165, Val F1: 0.7250, Gap: -0.0467\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8151, Val Acc: 0.8094, Val F1: 0.8149, Gap: 0.0057\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8622, Val Acc: 0.8354, Val F1: 0.8408, Gap: 0.0268\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8940, Val Acc: 0.8386, Val F1: 0.8416, Gap: 0.0554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9164, Val Acc: 0.8467, Val F1: 0.8512, Gap: 0.0697\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9318, Val Acc: 0.8458, Val F1: 0.8506, Gap: 0.0860\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9440, Val Acc: 0.8452, Val F1: 0.8503, Gap: 0.0988\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9532, Val Acc: 0.8462, Val F1: 0.8498, Gap: 0.1070\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9564, Val Acc: 0.8508, Val F1: 0.8546, Gap: 0.1055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9631, Val Acc: 0.8446, Val F1: 0.8487, Gap: 0.1185\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9670, Val Acc: 0.8499, Val F1: 0.8539, Gap: 0.1171\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9723, Val Acc: 0.8508, Val F1: 0.8539, Gap: 0.1215\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▇▅▇▇██▇▆▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▆▃▅▆█▆▆▄▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▆▄█▆▅▁▆▅▇▅▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▇▆▇████▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▆█▇▇▇█▆▆█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▆▄▆▇▇▇█▆▅▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▄▆██▇▇██▇█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▄▅▇█▁▂▆▅▅▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▆▄▄██▆▆▆▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▇▇██▇▇▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▃▅▃▄▄██▆▄▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇▇██▇▇▆▇███</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇███▇▇████</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▇▇▇▇▆▅▇█▇█</td></tr><tr><td>Class_Positive_Recall</td><td>▆▁▃▅▄▆▇█▆▃▅▄</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇████████</td></tr><tr><td>Validation Loss</td><td>▇▂▁▂▂▃▄▅▅▇▆█</td></tr><tr><td>Validation Precision</td><td>▁▆▇▇███▇████</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇▇▇▇██▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84906</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.81131</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89051</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.80949</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83765</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78316</td></tr><tr><td>Class_Negative_F1</td><td>0.87382</td></tr><tr><td>Class_Negative_Precision</td><td>0.87927</td></tr><tr><td>Class_Negative_Recall</td><td>0.86844</td></tr><tr><td>Class_Neutral_F1</td><td>0.85057</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83601</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86565</td></tr><tr><td>Class_Positive_F1</td><td>0.88659</td></tr><tr><td>Class_Positive_Precision</td><td>0.90039</td></tr><tr><td>Class_Positive_Recall</td><td>0.87321</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97233</td></tr><tr><td>Train Loss</td><td>0.09881</td></tr><tr><td>Validation Accuracy</td><td>0.85083</td></tr><tr><td>Validation F1</td><td>0.85391</td></tr><tr><td>Validation Loss</td><td>0.73114</td></tr><tr><td>Validation Precision</td><td>0.85292</td></tr><tr><td>Validation Recall</td><td>0.85619</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/xklwr069' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/xklwr069</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_144101-xklwr069/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 15:22:54,655] Trial 8 finished with value: 0.8508260447035957 and parameters: {'learning_rate': 1.8947748172906224e-05, 'weight_decay': 1.5861830621313446e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 1 with value: 0.8605442176870748.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_152255-2osip27i</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/2osip27i' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/2osip27i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/2osip27i</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6938, Val Acc: 0.7785, Val F1: 0.7867, Gap: -0.0847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8314, Val Acc: 0.7988, Val F1: 0.8069, Gap: 0.0326\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8790, Val Acc: 0.8427, Val F1: 0.8467, Gap: 0.0363\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.9096, Val Acc: 0.8429, Val F1: 0.8471, Gap: 0.0666\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9293, Val Acc: 0.8551, Val F1: 0.8605, Gap: 0.0742\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9416, Val Acc: 0.8590, Val F1: 0.8631, Gap: 0.0826\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9488, Val Acc: 0.8379, Val F1: 0.8424, Gap: 0.1108\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9590, Val Acc: 0.8473, Val F1: 0.8524, Gap: 0.1117\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9624, Val Acc: 0.8587, Val F1: 0.8616, Gap: 0.1037\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9675, Val Acc: 0.8477, Val F1: 0.8499, Gap: 0.1199\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9725, Val Acc: 0.8524, Val F1: 0.8553, Gap: 0.1201\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9733, Val Acc: 0.8614, Val F1: 0.8652, Gap: 0.1119\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▅▇██▆▇▆▅▆▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▅▅▁▇▄▅▂▅███▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▅█▄▇▆█▆▃▂▃▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▄▇▇▇▅▇█▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▇▄▃▆█▆▄▃▅▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▅▁▇▇▆▁▅██▅▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▂▆█▅▇▇▅▃█</td></tr><tr><td>Class_Negative_Precision</td><td>▅▅█▁▇▆▆▇▅▂▁▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▃▇▄▆▄▄▆██▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▁▇▆▇█▆▇█▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▄██▇▅▆▅▆▆▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▁█▅▆▇▆▆█▇▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▂▁█▇██▇▇█▆██</td></tr><tr><td>Class_Positive_Precision</td><td>▂▁▇▅▆▆▅▅▇█▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▆█▄▇▅▆▆▆▃▁▅▅</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▆▇█▆▇█▇▇█</td></tr><tr><td>Validation F1</td><td>▁▃▆▆██▆▇█▇▇█</td></tr><tr><td>Validation Loss</td><td>▄▃▂▁▂▂▆▅▆▇██</td></tr><tr><td>Validation Precision</td><td>▁▂▆▆▇▇▅▆█▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▇▇██▇▇▇▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86688</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.87535</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.85858</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83221</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.82059</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84418</td></tr><tr><td>Class_Negative_F1</td><td>0.89168</td></tr><tr><td>Class_Negative_Precision</td><td>0.90909</td></tr><tr><td>Class_Negative_Recall</td><td>0.87492</td></tr><tr><td>Class_Neutral_F1</td><td>0.85188</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84437</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85952</td></tr><tr><td>Class_Positive_F1</td><td>0.88331</td></tr><tr><td>Class_Positive_Precision</td><td>0.88974</td></tr><tr><td>Class_Positive_Recall</td><td>0.87698</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.9733</td></tr><tr><td>Train Loss</td><td>0.0984</td></tr><tr><td>Validation Accuracy</td><td>0.86139</td></tr><tr><td>Validation F1</td><td>0.86519</td></tr><tr><td>Validation Loss</td><td>0.76746</td></tr><tr><td>Validation Precision</td><td>0.86783</td></tr><tr><td>Validation Recall</td><td>0.86283</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/2osip27i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/2osip27i</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_152255-2osip27i/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 16:04:49,424] Trial 9 finished with value: 0.8613945578231292 and parameters: {'learning_rate': 3.3155877070717394e-05, 'weight_decay': 2.77988245252064e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 9 with value: 0.8613945578231292.\n"]},{"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_160450-k20go7l7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/k20go7l7' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/k20go7l7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/k20go7l7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.5230, Val Acc: 0.6028, Val F1: 0.6152, Gap: -0.0798\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.6563, Val Acc: 0.6780, Val F1: 0.6907, Gap: -0.0217\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.7130, Val Acc: 0.7023, Val F1: 0.7140, Gap: 0.0107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.7482, Val Acc: 0.7222, Val F1: 0.7337, Gap: 0.0260\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.7718, Val Acc: 0.7511, Val F1: 0.7605, Gap: 0.0207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.7936, Val Acc: 0.7734, Val F1: 0.7817, Gap: 0.0202\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.8076, Val Acc: 0.7707, Val F1: 0.7785, Gap: 0.0369\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.8228, Val Acc: 0.7939, Val F1: 0.8011, Gap: 0.0289\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.8367, Val Acc: 0.7974, Val F1: 0.8040, Gap: 0.0393\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.8500, Val Acc: 0.8109, Val F1: 0.8176, Gap: 0.0391\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.8575, Val Acc: 0.7838, Val F1: 0.7924, Gap: 0.0737\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.8661, Val Acc: 0.8185, Val F1: 0.8247, Gap: 0.0476\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▅▆▆▆▇▇███</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▅▆▆▆▅▇▆█▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▁▄▅▄▆▇▆█▆█▇</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▅▅▆▇▇▇▇█▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▅▅▆▆▆▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▆▅▆▇▇█▇█▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▅▅▆▇▇▇████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅▆▆▆▆▇██▇██</td></tr><tr><td>Class_Negative_Recall</td><td>▃▁▃▃▆▇▅▇▇█▆▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▃▄▅▇▆▇▇█▆█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▄▆▆▇██▇▇█</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▃▅▅▇▆▇▇█▆█</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▄▅▆▆▆▇▇▇▆█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▁▂▄▇▅▆▇█▃█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▂▅▆▆▅▆▆▆▆█▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄▅▆▇▆▇▇█▇█</td></tr><tr><td>Validation F1</td><td>▁▄▄▅▆▇▆▇▇█▇█</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▂▃▂▂▁▂▁</td></tr><tr><td>Validation Precision</td><td>▁▄▄▅▆▇▆▇▇█▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▄▅▆▆▇▇▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83471</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.7995</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.87318</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.77996</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.77878</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78114</td></tr><tr><td>Class_Negative_F1</td><td>0.84672</td></tr><tr><td>Class_Negative_Precision</td><td>0.91304</td></tr><tr><td>Class_Negative_Recall</td><td>0.78937</td></tr><tr><td>Class_Neutral_F1</td><td>0.80224</td></tr><tr><td>Class_Neutral_Precision</td><td>0.78834</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81663</td></tr><tr><td>Class_Positive_F1</td><td>0.85993</td></tr><tr><td>Class_Positive_Precision</td><td>0.85353</td></tr><tr><td>Class_Positive_Recall</td><td>0.86642</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.86608</td></tr><tr><td>Train Loss</td><td>0.38007</td></tr><tr><td>Validation Accuracy</td><td>0.81851</td></tr><tr><td>Validation F1</td><td>0.82471</td></tr><tr><td>Validation Loss</td><td>0.52819</td></tr><tr><td>Validation Precision</td><td>0.82664</td></tr><tr><td>Validation Recall</td><td>0.82535</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/k20go7l7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/k20go7l7</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_160450-k20go7l7/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 16:46:46,754] Trial 10 finished with value: 0.8185131195335277 and parameters: {'learning_rate': 2.5279963856727298e-06, 'weight_decay': 1.3378781378434834e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 9 with value: 0.8613945578231292.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_164647-1aflbg0i</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/1aflbg0i' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/1aflbg0i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/1aflbg0i</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6768, Val Acc: 0.7332, Val F1: 0.7397, Gap: -0.0564\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8245, Val Acc: 0.8288, Val F1: 0.8342, Gap: -0.0043\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8743, Val Acc: 0.7979, Val F1: 0.8032, Gap: 0.0764\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8999, Val Acc: 0.8495, Val F1: 0.8523, Gap: 0.0504\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9189, Val Acc: 0.8607, Val F1: 0.8647, Gap: 0.0582\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9317, Val Acc: 0.8506, Val F1: 0.8543, Gap: 0.0812\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9424, Val Acc: 0.8084, Val F1: 0.8111, Gap: 0.1339\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9490, Val Acc: 0.8540, Val F1: 0.8567, Gap: 0.0950\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9542, Val Acc: 0.8410, Val F1: 0.8440, Gap: 0.1132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9589, Val Acc: 0.8638, Val F1: 0.8667, Gap: 0.0951\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9615, Val Acc: 0.8622, Val F1: 0.8660, Gap: 0.0992\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9660, Val Acc: 0.8584, Val F1: 0.8627, Gap: 0.1076\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▂▆▇▇▄▆▆▇██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▄▁█▇▇▂█▄▆▇▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▇█▁▄▄█▂▇▆▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▃▇█▇▄█▇███</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▄▂▁▃▅▇▆▅█▇▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▆▃██▆▃▇▅▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆▇█▄▆█▇█▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▅██▇█▁▅▆▆▆▄▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▄▅▅█▆▆▇▇██</td></tr><tr><td>Class_Neutral_F1</td><td>▁▇▆▇█▇▆▇▇██▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▇▄▆▆█▆▇▆▅▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▅█▇▇▄▇▅▇█▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▇▆███▅█▇██▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▆█▆▇▃▆▅▇█▅</td></tr><tr><td>Class_Positive_Recall</td><td>▇▂▄▁▅▄█▆▇▄▁▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▄▇█▇▅▇▇███</td></tr><tr><td>Validation F1</td><td>▁▆▄▇█▇▅▇▇███</td></tr><tr><td>Validation Loss</td><td>█▂▄▂▁▃▇▃▅▅▄▅</td></tr><tr><td>Validation Precision</td><td>▁▆▄██▇▅▇▆██▇</td></tr><tr><td>Validation Recall</td><td>▁▆▅▆█▇▆▇▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87416</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.8584</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89051</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83774</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84505</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.83056</td></tr><tr><td>Class_Negative_F1</td><td>0.88659</td></tr><tr><td>Class_Negative_Precision</td><td>0.88402</td></tr><tr><td>Class_Negative_Recall</td><td>0.88918</td></tr><tr><td>Class_Neutral_F1</td><td>0.83448</td></tr><tr><td>Class_Neutral_Precision</td><td>0.87362</td></tr><tr><td>Class_Neutral_Recall</td><td>0.79869</td></tr><tr><td>Class_Positive_F1</td><td>0.88057</td></tr><tr><td>Class_Positive_Precision</td><td>0.82791</td></tr><tr><td>Class_Positive_Recall</td><td>0.94038</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96597</td></tr><tr><td>Train Loss</td><td>0.11704</td></tr><tr><td>Validation Accuracy</td><td>0.85836</td></tr><tr><td>Validation F1</td><td>0.86271</td></tr><tr><td>Validation Loss</td><td>0.57953</td></tr><tr><td>Validation Precision</td><td>0.8578</td></tr><tr><td>Validation Recall</td><td>0.86986</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/1aflbg0i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/1aflbg0i</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_164647-1aflbg0i/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 17:29:01,471] Trial 11 finished with value: 0.863824101068999 and parameters: {'learning_rate': 2.2953688608487992e-05, 'weight_decay': 3.637802609071421e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 11 with value: 0.863824101068999.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_172902-mgc12ah7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/mgc12ah7' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/mgc12ah7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/mgc12ah7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6665, Val Acc: 0.7658, Val F1: 0.7737, Gap: -0.0993\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8144, Val Acc: 0.8293, Val F1: 0.8349, Gap: -0.0149\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8646, Val Acc: 0.8344, Val F1: 0.8398, Gap: 0.0302\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8924, Val Acc: 0.8376, Val F1: 0.8426, Gap: 0.0548\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9148, Val Acc: 0.8578, Val F1: 0.8614, Gap: 0.0570\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9290, Val Acc: 0.8548, Val F1: 0.8593, Gap: 0.0742\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9370, Val Acc: 0.8460, Val F1: 0.8506, Gap: 0.0910\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9458, Val Acc: 0.8608, Val F1: 0.8650, Gap: 0.0850\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9509, Val Acc: 0.8352, Val F1: 0.8385, Gap: 0.1158\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9549, Val Acc: 0.8438, Val F1: 0.8485, Gap: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12: Train Acc: 0.9582, Val Acc: 0.8551, Val F1: 0.8587, Gap: 0.1031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12: Train Acc: 0.9623, Val Acc: 0.8558, Val F1: 0.8588, Gap: 0.1065\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▅▆▇▇▇█▄█▇▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▆▂▃▇▅▄▇▁▄▅█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▂██▃▅▆▄█▇▅▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▄▅█▇▇█▄▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▄▆▇▅▇▇█▆█▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▆▄▄▇▇▅▇▁▆▄█</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▆█▇███▅▇▇</td></tr><tr><td>Class_Negative_Precision</td><td>▁▅█▇▇▃█▄█▇▂▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▄▄▆▇▅█▅▃▇▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▇▇██▇█▇▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▇▆▅█▇▇▇▇▇▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▅▆█▆▆▇▆▅▇▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▇▇█▆█▆▆█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▆▆██▅▇▅▄▇▇</td></tr><tr><td>Class_Positive_Recall</td><td>▃▂▄▄▁▂▇▄█▇▅▃</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▆██▇█▆▇██</td></tr><tr><td>Validation F1</td><td>▁▆▆▆██▇█▆▇██</td></tr><tr><td>Validation Loss</td><td>▇▂▂▁▁▁▄▄█▇▅▄</td></tr><tr><td>Validation Precision</td><td>▁▆▆▆█▇▆█▆▆▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇▇█▇█▇▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84978</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.90947</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.79745</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83289</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80671</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.86082</td></tr><tr><td>Class_Negative_F1</td><td>0.87671</td></tr><tr><td>Class_Negative_Precision</td><td>0.90483</td></tr><tr><td>Class_Negative_Recall</td><td>0.85029</td></tr><tr><td>Class_Neutral_F1</td><td>0.8466</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83489</td></tr><tr><td>Class_Neutral_Recall</td><td>0.85864</td></tr><tr><td>Class_Positive_F1</td><td>0.88806</td></tr><tr><td>Class_Positive_Precision</td><td>0.87823</td></tr><tr><td>Class_Positive_Recall</td><td>0.89811</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96226</td></tr><tr><td>Train Loss</td><td>0.12121</td></tr><tr><td>Validation Accuracy</td><td>0.85581</td></tr><tr><td>Validation F1</td><td>0.85881</td></tr><tr><td>Validation Loss</td><td>0.52986</td></tr><tr><td>Validation Precision</td><td>0.86683</td></tr><tr><td>Validation Recall</td><td>0.85306</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/mgc12ah7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/mgc12ah7</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250807_172902-mgc12ah7/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[I 2025-08-07 18:10:58,529] Trial 12 finished with value: 0.8607871720116618 and parameters: {'learning_rate': 1.8381424470950094e-05, 'weight_decay': 4.5194022378745654e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 11 with value: 0.863824101068999.\n"]},{"name":"stdout","output_type":"stream","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250807_181059-8lce0koa</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/8lce0koa' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/8lce0koa' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.1/runs/8lce0koa</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1/12: Train Acc: 0.6968, Val Acc: 0.7625, Val F1: 0.7708, Gap: -0.0657\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  2/12: Train Acc: 0.8342, Val Acc: 0.8455, Val F1: 0.8506, Gap: -0.0113\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  3/12: Train Acc: 0.8731, Val Acc: 0.8303, Val F1: 0.8374, Gap: 0.0428\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  4/12: Train Acc: 0.8953, Val Acc: 0.8534, Val F1: 0.8583, Gap: 0.0419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  5/12: Train Acc: 0.9097, Val Acc: 0.8454, Val F1: 0.8505, Gap: 0.0644\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  6/12: Train Acc: 0.9196, Val Acc: 0.8637, Val F1: 0.8677, Gap: 0.0559\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  7/12: Train Acc: 0.9280, Val Acc: 0.8599, Val F1: 0.8638, Gap: 0.0681\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  8/12: Train Acc: 0.9335, Val Acc: 0.8553, Val F1: 0.8607, Gap: 0.0782\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  9/12: Train Acc: 0.9384, Val Acc: 0.8562, Val F1: 0.8605, Gap: 0.0822\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12: Train Acc: 0.9416, Val Acc: 0.8584, Val F1: 0.8628, Gap: 0.0832\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 6.1:\")\n","study6 = optuna.create_study(direction=\"maximize\")\n","study6.optimize(objective, n_trials=15)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study6.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model6.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WHsXjrP2xdrC","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e0964517f6c5425a81c95f529a553bcd","7954b2052e574404b0b5f12a403d5c07","c4f14e8cf9394b189a2d2729518c55a7","a1c276769a364416ab70bbe6553fe98d","655c1b29d98e465db3d2863d1cb4885f","2bf68f5a9fac47dd9e6aa8c4b6f6d93c","ee997ff56b234037b1fdefcacd3f821d","b3c8c864a4734048851ca77ac1bf8d8b","1fde0b0b20324d3b98c0f2f2b091bfc2","86618747dc7b40deaecf9592d269a69b","6e2a53171fc3425586fbab2691f01247","b99707bfb5844cd990e156169a958954","da1d0ea09f4b48d880924599c5d46c5a","84204124b4a642a5a123ce370a578186","18a5c032485541cfad910920d0810a02","c009789e306c4499bb12147e14cfd990","7ce256e2ae37495e943cf904b4fa6b90","c3fc74edd965431d8c47c1cbe909030e","b9293830855a471bbccc471c43e3143d","50ac0bd9971f462fbf9b4c7d5fc0024f","bbb4478b93fa4e66a05ff86b630d583a","49168f0f15ab4a6b9816cacc6f6a68a2","39bccbe411fc44f8b994625e0287f725","02b974dac0e147e6bf2172b98cecc054","3e396691527542949b0b7430c2cb2b1a","b7605436aee740de9b7b5e814b7a610e","efa5297fcc624dd89564c1f6376198f8","93882e600e8343839de30adf344f9ca2","93e43276d9af4ef096d49089189ca22e","0e7bea3b2a54417c885847ac7e2d19f5","483638e2bf204fd5b715315ffda8f3c5","1e1b723af5c541989c9bfd5337a737f1","db1bc0a7b20544a18c8d66d7bec14dec","c07e0e2a6dfd478aaa38b9b738621afb","c74f626b258a4361a035319338bca01d","65b1d9cb7b344951b91af0fbd750d857","7a23e3c39f714009974248a3406e6fd7","118fa81936254b068d58f45c47bf839f","f51ae58675264f2e95980ded68f30c7d","7d6d5fb5831f45a1a574091c2509a40b","d81798bb9e9647cc87352158870359f7","a933c4d0b6694e9a880df41e8b49d6d8","309e84dda8c64f05a97b59b48d71ca4e","2df0d38791ef43cda3bc6b11c748f662","70b2eebe64c6492093737736decb4fcd","78942584b19649be9a6e3bfe54199977","64d33a84656e437fb90655e8db5c0d4a","80bd089020bd4a35b96f64bbce76388e","989b32489c564282bebaf589f0640ace","4198efb8d81c4b67bc7444a93772301b","e811061ffb8b4f8fb483933d8454b48f","c6ebe7b9da3447b9918a73c23aa385b5","db98a8c9e85647428a55abfcfadf85d4","0fc5ab35374a4aa2a6f904f06555660d","e7c858e2e1524281a6a474afee2656f1","e3da3071ec2245c9b474be00e87d5a2f","0fd604ff63cc40e0829cc86b3d269ef7","37ea95b8677845ea84265f7195bbdf40","fc0bb09f0f3f4f9888291f310e33579b","82c55bc4e29844cc903493811971cb39","f8183a9b57b041e6b7bc12b715560747","8d0fa6f790bb4263adecb52f85e355a6","9f3314158fed41f2a003271befbf5e07","8d095878fea54ab99edd7c7654ec3205","aee3e4d8bc3747728e3bd7e046d6e018","91656a2bae9d4adbb64604491c9d3cdd"]},"executionInfo":{"status":"ok","timestamp":1754869107977,"user_tz":-180,"elapsed":36938505,"user":{"displayName":"Yarden Revivo","userId":"08445056656820833143"}},"outputId":"131d9326-aa6f-49b2-c921-ad5e1f7fa89f"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[I 2025-08-10 13:15:18,551] A new study created in memory with name: no-name-19f0a79f-cb07-47be-ac74-ea51e05c03f9\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Starting Study 6.2:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0964517f6c5425a81c95f529a553bcd","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b99707bfb5844cd990e156169a958954","version_major":2,"version_minor":0},"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39bccbe411fc44f8b994625e0287f725","version_major":2,"version_minor":0},"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c07e0e2a6dfd478aaa38b9b738621afb","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70b2eebe64c6492093737736decb4fcd","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Using standard CrossEntropyLoss\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3da3071ec2245c9b474be00e87d5a2f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.21.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_131526-08io9wzk</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/08io9wzk' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/08io9wzk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/08io9wzk</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6697, Val Acc: 0.7010, Val F1: 0.7110, Gap: -0.0313\n","Epoch  2/12: Train Acc: 0.8085, Val Acc: 0.7715, Val F1: 0.7780, Gap: 0.0370\n","Epoch  3/12: Train Acc: 0.8518, Val Acc: 0.8441, Val F1: 0.8486, Gap: 0.0076\n","Epoch  4/12: Train Acc: 0.8771, Val Acc: 0.8477, Val F1: 0.8515, Gap: 0.0294\n","Epoch  5/12: Train Acc: 0.8879, Val Acc: 0.8332, Val F1: 0.8388, Gap: 0.0547\n","Epoch  6/12: Train Acc: 0.9007, Val Acc: 0.8533, Val F1: 0.8578, Gap: 0.0474\n","Epoch  7/12: Train Acc: 0.9066, Val Acc: 0.8542, Val F1: 0.8588, Gap: 0.0524\n","Epoch  8/12: Train Acc: 0.9112, Val Acc: 0.8428, Val F1: 0.8481, Gap: 0.0684\n","Epoch  9/12: Train Acc: 0.9127, Val Acc: 0.8539, Val F1: 0.8583, Gap: 0.0588\n","Epoch 10/12: Train Acc: 0.9163, Val Acc: 0.8508, Val F1: 0.8540, Gap: 0.0655\n","Epoch 11/12: Train Acc: 0.9203, Val Acc: 0.8392, Val F1: 0.8438, Gap: 0.0811\n","Epoch 12/12: Train Acc: 0.9200, Val Acc: 0.8619, Val F1: 0.8661, Gap: 0.0581\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▁▇▇▆▇█▇█▆▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁▆██▆▇▇▇▅▆▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆█▅▂▁▆▅▄▅▇▆▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▁▇█▇▇█▇█▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▄▁▆▆▅▆▇▅██▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂▇█▇▇▇█▇▆▇█</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇▆▅█▇▆▇█▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▁▄▅▂█▆▃█▄▇▂▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▆▆▃▆▇▃▇▇██</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆██▇██▇▇█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁█▅▅▄▇▇▆▆▆█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄██▇▇▇▇▇▇▅█</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▇▇██▇▇█▆█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▇█▆▇▆▆▆▇▅█</td></tr><tr><td>Class_Positive_Recall</td><td>█▆▂▁▆▆▇▆▇▆█▃</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▇▇██▇██▇█</td></tr><tr><td>Validation F1</td><td>▁▄▇▇▇██▇█▇▇█</td></tr><tr><td>Validation Loss</td><td>█▅▁▁▂▁▂▂▂▂▃▂</td></tr><tr><td>Validation Precision</td><td>▁▄▇█▇▇▇▇▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▇▇▆██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87123</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84862</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.89507</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83316</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84043</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82602</td></tr><tr><td>Class_Negative_F1</td><td>0.88149</td></tr><tr><td>Class_Negative_Precision</td><td>0.88816</td></tr><tr><td>Class_Negative_Recall</td><td>0.87492</td></tr><tr><td>Class_Neutral_F1</td><td>0.85168</td></tr><tr><td>Class_Neutral_Precision</td><td>0.83692</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86696</td></tr><tr><td>Class_Positive_F1</td><td>0.89279</td></tr><tr><td>Class_Positive_Precision</td><td>0.92339</td></tr><tr><td>Class_Positive_Recall</td><td>0.86415</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.92001</td></tr><tr><td>Train Loss</td><td>0.24194</td></tr><tr><td>Validation Accuracy</td><td>0.86188</td></tr><tr><td>Validation F1</td><td>0.86607</td></tr><tr><td>Validation Loss</td><td>0.45604</td></tr><tr><td>Validation Precision</td><td>0.8675</td></tr><tr><td>Validation Recall</td><td>0.86542</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/08io9wzk' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/08io9wzk</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_131526-08io9wzk/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 13:57:27,182] Trial 0 finished with value: 0.8618804664723032 and parameters: {'learning_rate': 1.8272216320386246e-05, 'weight_decay': 7.883231135969847e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 0 with value: 0.8618804664723032.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_135729-3oxq9lv8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/3oxq9lv8' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/3oxq9lv8' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/3oxq9lv8</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6798, Val Acc: 0.7733, Val F1: 0.7807, Gap: -0.0936\n","Epoch  2/12: Train Acc: 0.8208, Val Acc: 0.8152, Val F1: 0.8204, Gap: 0.0056\n","Epoch  3/12: Train Acc: 0.8694, Val Acc: 0.8466, Val F1: 0.8515, Gap: 0.0228\n","Epoch  4/12: Train Acc: 0.8974, Val Acc: 0.8486, Val F1: 0.8532, Gap: 0.0487\n","Epoch  5/12: Train Acc: 0.9172, Val Acc: 0.8565, Val F1: 0.8606, Gap: 0.0607\n","Epoch  6/12: Train Acc: 0.9329, Val Acc: 0.8574, Val F1: 0.8614, Gap: 0.0755\n","Epoch  7/12: Train Acc: 0.9425, Val Acc: 0.8522, Val F1: 0.8561, Gap: 0.0904\n","Epoch  8/12: Train Acc: 0.9491, Val Acc: 0.8612, Val F1: 0.8658, Gap: 0.0879\n","Epoch  9/12: Train Acc: 0.9550, Val Acc: 0.8478, Val F1: 0.8517, Gap: 0.1072\n","Epoch 10/12: Train Acc: 0.9612, Val Acc: 0.8480, Val F1: 0.8515, Gap: 0.1132\n","Epoch 11/12: Train Acc: 0.9640, Val Acc: 0.8624, Val F1: 0.8661, Gap: 0.1017\n","Epoch 12/12: Train Acc: 0.9692, Val Acc: 0.8440, Val F1: 0.8499, Gap: 0.1252\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▇▆▇███▇▆▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▁█▄▅▇▇█▅▄▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄█▁▇▆▃▃▃▇█▄▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▇▇▇███▇▆█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▄▆▇▆▆▆█▇▅▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▂█▆▅▇▇▇▄▄▇▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆██▇▅▇▅▆▇▆</td></tr><tr><td>Class_Negative_Precision</td><td>▂▇█▇▆▄▁▇▂▄▆█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▁▅▆▇█▄▇▅▅▂</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▇▇▇▇▇▇█▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▃▆▆▇█▄▇▇▆▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▇▆▇▆▆█▆▇█▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▆▆▇▇▇█▇██▅</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▇▅▅▆▆▇▄▇█▁</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▂▄▅▅▄▄▇▅▄█</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▇██▇█▇▇█▇</td></tr><tr><td>Validation F1</td><td>▁▄▇▇██▇█▇▇█▇</td></tr><tr><td>Validation Loss</td><td>▅▂▁▁▂▂▃▂▄▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▄▇▆▇▇▇█▆▆█▆</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇██▇██▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87042</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85289</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88869</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82308</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83725</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80938</td></tr><tr><td>Class_Negative_F1</td><td>0.87305</td></tr><tr><td>Class_Negative_Precision</td><td>0.9362</td></tr><tr><td>Class_Negative_Recall</td><td>0.81789</td></tr><tr><td>Class_Neutral_F1</td><td>0.81566</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81999</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81138</td></tr><tr><td>Class_Positive_F1</td><td>0.86743</td></tr><tr><td>Class_Positive_Precision</td><td>0.80115</td></tr><tr><td>Class_Positive_Recall</td><td>0.94566</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96918</td></tr><tr><td>Train Loss</td><td>0.10916</td></tr><tr><td>Validation Accuracy</td><td>0.84402</td></tr><tr><td>Validation F1</td><td>0.84993</td></tr><tr><td>Validation Loss</td><td>0.73999</td></tr><tr><td>Validation Precision</td><td>0.8495</td></tr><tr><td>Validation Recall</td><td>0.8546</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/3oxq9lv8' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/3oxq9lv8</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_135729-3oxq9lv8/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 14:39:31,339] Trial 1 finished with value: 0.8623663751214772 and parameters: {'learning_rate': 1.972170855167735e-05, 'weight_decay': 3.0054019230719973e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 1 with value: 0.8623663751214772.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_143933-k2znmqwb</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/k2znmqwb' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/k2znmqwb' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/k2znmqwb</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6653, Val Acc: 0.7743, Val F1: 0.7833, Gap: -0.1090\n","Epoch  2/12: Train Acc: 0.8121, Val Acc: 0.7655, Val F1: 0.7742, Gap: 0.0466\n","Epoch  3/12: Train Acc: 0.8618, Val Acc: 0.8522, Val F1: 0.8565, Gap: 0.0097\n","Epoch  4/12: Train Acc: 0.8885, Val Acc: 0.8390, Val F1: 0.8429, Gap: 0.0495\n","Epoch  5/12: Train Acc: 0.9094, Val Acc: 0.8435, Val F1: 0.8487, Gap: 0.0659\n","Epoch  6/12: Train Acc: 0.9237, Val Acc: 0.8369, Val F1: 0.8420, Gap: 0.0869\n","Epoch  7/12: Train Acc: 0.9310, Val Acc: 0.8687, Val F1: 0.8724, Gap: 0.0623\n","Epoch  8/12: Train Acc: 0.9376, Val Acc: 0.8649, Val F1: 0.8694, Gap: 0.0727\n","Epoch  9/12: Train Acc: 0.9465, Val Acc: 0.8615, Val F1: 0.8664, Gap: 0.0849\n","Epoch 10/12: Train Acc: 0.9499, Val Acc: 0.8422, Val F1: 0.8464, Gap: 0.1077\n","Epoch 11/12: Train Acc: 0.9542, Val Acc: 0.8568, Val F1: 0.8606, Gap: 0.0974\n","Epoch 12/12: Train Acc: 0.9559, Val Acc: 0.8592, Val F1: 0.8616, Gap: 0.0967\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▆▄▇▄▇██▆▇▅</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▆▁▇▂▆▂▇▇▇▅▅█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▇▃█▅█▄▅▅▅▆▃</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▁▇▄▇▄███▆▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▅▆▆▄▆▇█▆▇▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▁█▃▇▄█▇▇▆▅█</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▇▇█▇▇▃▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▄▇▅▇█▆▆▇▆▁▃▃</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▅▅▅▆▇▆▆▆▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▃▁▇▇▆▇██▇▇██</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▆▇██▇▇▇▇█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▆▁█▇▅▆█▇▇▇▇█</td></tr><tr><td>Class_Positive_F1</td><td>▄▁▇▇▅▇██▇▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▅▁▇▆▄▇▇▆▅▇▇█</td></tr><tr><td>Class_Positive_Recall</td><td>▁█▃▅█▃▄▇▇▂▅▂</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▂▁▇▆▆▆███▆▇▇</td></tr><tr><td>Validation F1</td><td>▂▁▇▆▆▆███▆▇▇</td></tr><tr><td>Validation Loss</td><td>██▁▅▃▅▁▂▄▇▅▅</td></tr><tr><td>Validation Precision</td><td>▃▁▇▅▆▅██▇▆▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▇▇▇▇███▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85182</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.92144</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.79197</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83329</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.80747</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.86082</td></tr><tr><td>Class_Negative_F1</td><td>0.87737</td></tr><tr><td>Class_Negative_Precision</td><td>0.85626</td></tr><tr><td>Class_Negative_Recall</td><td>0.89955</td></tr><tr><td>Class_Neutral_F1</td><td>0.85769</td></tr><tr><td>Class_Neutral_Precision</td><td>0.838</td></tr><tr><td>Class_Neutral_Recall</td><td>0.87834</td></tr><tr><td>Class_Positive_F1</td><td>0.88773</td></tr><tr><td>Class_Positive_Precision</td><td>0.95086</td></tr><tr><td>Class_Positive_Recall</td><td>0.83245</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.95593</td></tr><tr><td>Train Loss</td><td>0.14586</td></tr><tr><td>Validation Accuracy</td><td>0.85921</td></tr><tr><td>Validation F1</td><td>0.86158</td></tr><tr><td>Validation Loss</td><td>0.5415</td></tr><tr><td>Validation Precision</td><td>0.87481</td></tr><tr><td>Validation Recall</td><td>0.85262</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/k2znmqwb' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/k2znmqwb</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_143933-k2znmqwb/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 15:21:37,521] Trial 2 finished with value: 0.8686831875607386 and parameters: {'learning_rate': 1.8149806751171474e-05, 'weight_decay': 6.047267108136898e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 2 with value: 0.8686831875607386.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_152139-1yyhhjeu</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/1yyhhjeu' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/1yyhhjeu' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/1yyhhjeu</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6780, Val Acc: 0.7901, Val F1: 0.7983, Gap: -0.1120\n","Epoch  2/12: Train Acc: 0.8203, Val Acc: 0.8155, Val F1: 0.8209, Gap: 0.0048\n","Epoch  3/12: Train Acc: 0.8667, Val Acc: 0.8362, Val F1: 0.8408, Gap: 0.0304\n","Epoch  4/12: Train Acc: 0.8963, Val Acc: 0.8635, Val F1: 0.8675, Gap: 0.0329\n","Epoch  5/12: Train Acc: 0.9162, Val Acc: 0.8505, Val F1: 0.8563, Gap: 0.0657\n","Epoch  6/12: Train Acc: 0.9274, Val Acc: 0.8658, Val F1: 0.8689, Gap: 0.0616\n","Epoch  7/12: Train Acc: 0.9388, Val Acc: 0.8516, Val F1: 0.8562, Gap: 0.0873\n","Epoch  8/12: Train Acc: 0.9466, Val Acc: 0.8478, Val F1: 0.8530, Gap: 0.0988\n","Epoch  9/12: Train Acc: 0.9530, Val Acc: 0.8614, Val F1: 0.8639, Gap: 0.0916\n","Epoch 10/12: Train Acc: 0.9570, Val Acc: 0.8666, Val F1: 0.8709, Gap: 0.0904\n","Epoch 11/12: Train Acc: 0.9592, Val Acc: 0.8619, Val F1: 0.8654, Gap: 0.0974\n","Epoch 12/12: Train Acc: 0.9607, Val Acc: 0.8580, Val F1: 0.8612, Gap: 0.1027\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▂▄▇█▇▅▇▅█▇▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▁▂▆▅▇▃▅█▅▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃██▄▇▄▇▆▁▇▄▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▄▇▆█▅▆▇▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▇█▇█▇▆▆▇▇▇▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄▁▂▇▅█▅▆▆▇▇▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▇▆▆▇▃▇█▅▆</td></tr><tr><td>Class_Negative_Precision</td><td>▃▆▆▄▇▃▆█▄▆▁▃</td></tr><tr><td>Class_Negative_Recall</td><td>▃▄▅▇▅▇▆▁▇▇█▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▆█▆█▇▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▃▅▃█▅▃▃▆█▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▆▇▅▅▆▆█▆▅▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▃▅▇▅▇▇▇█▇▇▅</td></tr><tr><td>Class_Positive_Precision</td><td>▂▁▃█▂▄▇▄▆▅▅▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇▇▃██▄█▇▆▇▂</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅█▇█▇▆███▇</td></tr><tr><td>Validation F1</td><td>▁▃▅█▇█▇▆▇█▇▇</td></tr><tr><td>Validation Loss</td><td>▇▄▃▁▃▂▄▆▆▆█▇</td></tr><tr><td>Validation Precision</td><td>▁▃▅█▆█▆▆█▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇▇▆▆█▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86707</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.88053</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.85401</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83584</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.81867</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.85376</td></tr><tr><td>Class_Negative_F1</td><td>0.87504</td></tr><tr><td>Class_Negative_Precision</td><td>0.87646</td></tr><tr><td>Class_Negative_Recall</td><td>0.87362</td></tr><tr><td>Class_Neutral_F1</td><td>0.85172</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84029</td></tr><tr><td>Class_Neutral_Recall</td><td>0.86346</td></tr><tr><td>Class_Positive_F1</td><td>0.87638</td></tr><tr><td>Class_Positive_Precision</td><td>0.91605</td></tr><tr><td>Class_Positive_Recall</td><td>0.84</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.9607</td></tr><tr><td>Train Loss</td><td>0.13465</td></tr><tr><td>Validation Accuracy</td><td>0.85799</td></tr><tr><td>Validation F1</td><td>0.86121</td></tr><tr><td>Validation Loss</td><td>0.58719</td></tr><tr><td>Validation Precision</td><td>0.8664</td></tr><tr><td>Validation Recall</td><td>0.85697</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/1yyhhjeu' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/1yyhhjeu</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_152139-1yyhhjeu/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 16:03:44,458] Trial 3 finished with value: 0.8666180758017493 and parameters: {'learning_rate': 2.0865476749953735e-05, 'weight_decay': 2.1354077619041e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 2 with value: 0.8686831875607386.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_160346-vzs3lkyv</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/vzs3lkyv' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/vzs3lkyv' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/vzs3lkyv</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6781, Val Acc: 0.7402, Val F1: 0.7484, Gap: -0.0620\n","Epoch  2/12: Train Acc: 0.8179, Val Acc: 0.7907, Val F1: 0.7947, Gap: 0.0272\n","Epoch  3/12: Train Acc: 0.8698, Val Acc: 0.8454, Val F1: 0.8506, Gap: 0.0244\n","Epoch  4/12: Train Acc: 0.9001, Val Acc: 0.8270, Val F1: 0.8314, Gap: 0.0731\n","Epoch  5/12: Train Acc: 0.9204, Val Acc: 0.8474, Val F1: 0.8511, Gap: 0.0729\n","Epoch  6/12: Train Acc: 0.9353, Val Acc: 0.8629, Val F1: 0.8666, Gap: 0.0724\n","Epoch  7/12: Train Acc: 0.9463, Val Acc: 0.8608, Val F1: 0.8646, Gap: 0.0855\n","Epoch  8/12: Train Acc: 0.9547, Val Acc: 0.8692, Val F1: 0.8730, Gap: 0.0855\n","Epoch  9/12: Train Acc: 0.9607, Val Acc: 0.8517, Val F1: 0.8562, Gap: 0.1091\n","Epoch 10/12: Train Acc: 0.9632, Val Acc: 0.8379, Val F1: 0.8413, Gap: 0.1252\n","Epoch 11/12: Train Acc: 0.9697, Val Acc: 0.8581, Val F1: 0.8617, Gap: 0.1115\n","Epoch 12/12: Train Acc: 0.9738, Val Acc: 0.8394, Val F1: 0.8446, Gap: 0.1344\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▁▆▅▇█▇█▇▆▇▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▂▁█▄▇█▇▇▆▄▇▅</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅█▁▆▂▃▄▄▆▇▅▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▇▅▇█▇█▇▆▇▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▃▇▆▇▅▆▇██▁</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▁█▄▇▇██▆▅▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇▆▇▇▇██▆▆▆</td></tr><tr><td>Class_Negative_Precision</td><td>▄█▇▇▆▃▇▆▇▄▁█</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▅▄▅▇▅▆▅▆█▃</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▆▇███▇▇█▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▆▅▃▇▇█▇▇██</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▅▅█▇▇▇▆▅▆▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▆▅▇██▆▆▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▅▄█▆▇▇▅▅▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>█▇▆█▁▅▆▆▇▇▆▅</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▆▇███▇▆▇▆</td></tr><tr><td>Validation F1</td><td>▁▄▇▆▇███▇▆▇▆</td></tr><tr><td>Validation Loss</td><td>▅▄▁▂▂▁▂▂▄▆▅█</td></tr><tr><td>Validation Precision</td><td>▁▄▇▆████▇▆▇▆</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▆█▇█▇▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.84443</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.77599</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92609</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.79127</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.7703</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.81341</td></tr><tr><td>Class_Negative_F1</td><td>0.87148</td></tr><tr><td>Class_Negative_Precision</td><td>0.92758</td></tr><tr><td>Class_Negative_Recall</td><td>0.82178</td></tr><tr><td>Class_Neutral_F1</td><td>0.83629</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85886</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81488</td></tr><tr><td>Class_Positive_F1</td><td>0.87939</td></tr><tr><td>Class_Positive_Precision</td><td>0.88958</td></tr><tr><td>Class_Positive_Recall</td><td>0.86943</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97376</td></tr><tr><td>Train Loss</td><td>0.09518</td></tr><tr><td>Validation Accuracy</td><td>0.83941</td></tr><tr><td>Validation F1</td><td>0.84457</td></tr><tr><td>Validation Loss</td><td>0.84633</td></tr><tr><td>Validation Precision</td><td>0.84446</td></tr><tr><td>Validation Recall</td><td>0.84912</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/vzs3lkyv' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/vzs3lkyv</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_160346-vzs3lkyv/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 16:45:52,998] Trial 4 finished with value: 0.8691690962099126 and parameters: {'learning_rate': 2.08371793648536e-05, 'weight_decay': 9.080837423383063e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_164555-esmjuo9t</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/esmjuo9t' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/esmjuo9t' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/esmjuo9t</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6795, Val Acc: 0.7591, Val F1: 0.7675, Gap: -0.0796\n","Epoch  2/12: Train Acc: 0.8189, Val Acc: 0.7748, Val F1: 0.7837, Gap: 0.0441\n","Epoch  3/12: Train Acc: 0.8650, Val Acc: 0.8294, Val F1: 0.8344, Gap: 0.0356\n","Epoch  4/12: Train Acc: 0.8936, Val Acc: 0.8582, Val F1: 0.8630, Gap: 0.0354\n","Epoch  5/12: Train Acc: 0.9108, Val Acc: 0.8446, Val F1: 0.8492, Gap: 0.0662\n","Epoch  6/12: Train Acc: 0.9251, Val Acc: 0.8568, Val F1: 0.8610, Gap: 0.0683\n","Epoch  7/12: Train Acc: 0.9323, Val Acc: 0.8539, Val F1: 0.8573, Gap: 0.0784\n","Epoch  8/12: Train Acc: 0.9398, Val Acc: 0.8529, Val F1: 0.8560, Gap: 0.0869\n","Epoch  9/12: Train Acc: 0.9458, Val Acc: 0.8354, Val F1: 0.8411, Gap: 0.1104\n","Epoch 10/12: Train Acc: 0.9504, Val Acc: 0.8486, Val F1: 0.8525, Gap: 0.1018\n","Early stopping at epoch 10\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▆█▆████▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃▄▇▃▆▆█▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▆▅▃█▅▄▁▄▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▆█▆█▇█▆▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▄▅▃▆▇▄█▅</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▆▇▆▇▆█▄▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇███▇▇▆▆</td></tr><tr><td>Class_Negative_Precision</td><td>▆▇▄▇▇█▁▆▂▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▆▆▇▆█▆▇▇</td></tr><tr><td>Class_Neutral_F1</td><td>▃▁▆█▇███▆█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▇▅█▆▇▅▅▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▅▁▄▇▅▆▆█▆▆</td></tr><tr><td>Class_Positive_F1</td><td>▄▁▆████▆▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▄▁▄▇▆▅▆█▄▆</td></tr><tr><td>Class_Positive_Recall</td><td>▅█▇▄▆▇▇▁█▆</td></tr><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▆█▇███▆▇</td></tr><tr><td>Validation F1</td><td>▁▂▆█▇██▇▆▇</td></tr><tr><td>Validation Loss</td><td>█▇▂▁▂▂▂▃▇▇</td></tr><tr><td>Validation Precision</td><td>▁▂▅█▆▇▇█▆▆</td></tr><tr><td>Validation Recall</td><td>▁▃▆▇███▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86287</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.84261</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88412</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81818</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83359</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80333</td></tr><tr><td>Class_Negative_F1</td><td>0.86015</td></tr><tr><td>Class_Negative_Precision</td><td>0.84586</td></tr><tr><td>Class_Negative_Recall</td><td>0.87492</td></tr><tr><td>Class_Neutral_F1</td><td>0.83967</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86355</td></tr><tr><td>Class_Neutral_Recall</td><td>0.81707</td></tr><tr><td>Class_Positive_F1</td><td>0.88167</td></tr><tr><td>Class_Positive_Precision</td><td>0.85421</td></tr><tr><td>Class_Positive_Recall</td><td>0.91094</td></tr><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.9504</td></tr><tr><td>Train Loss</td><td>0.15607</td></tr><tr><td>Validation Accuracy</td><td>0.84864</td></tr><tr><td>Validation F1</td><td>0.85251</td></tr><tr><td>Validation Loss</td><td>0.59326</td></tr><tr><td>Validation Precision</td><td>0.84797</td></tr><tr><td>Validation Recall</td><td>0.85808</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/esmjuo9t' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/esmjuo9t</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_164555-esmjuo9t/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 17:20:54,437] Trial 5 finished with value: 0.8582361516034985 and parameters: {'learning_rate': 2.062202820169765e-05, 'weight_decay': 6.232306473933979e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_172056-bsdhfkb7</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/bsdhfkb7' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/bsdhfkb7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/bsdhfkb7</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6724, Val Acc: 0.7925, Val F1: 0.7998, Gap: -0.1201\n","Epoch  2/12: Train Acc: 0.8178, Val Acc: 0.8273, Val F1: 0.8322, Gap: -0.0095\n","Epoch  3/12: Train Acc: 0.8685, Val Acc: 0.8342, Val F1: 0.8394, Gap: 0.0343\n","Epoch  4/12: Train Acc: 0.9005, Val Acc: 0.8326, Val F1: 0.8363, Gap: 0.0679\n","Epoch  5/12: Train Acc: 0.9191, Val Acc: 0.8571, Val F1: 0.8622, Gap: 0.0620\n","Epoch  6/12: Train Acc: 0.9336, Val Acc: 0.8523, Val F1: 0.8558, Gap: 0.0813\n","Epoch  7/12: Train Acc: 0.9446, Val Acc: 0.8575, Val F1: 0.8622, Gap: 0.0871\n","Epoch  8/12: Train Acc: 0.9531, Val Acc: 0.8516, Val F1: 0.8559, Gap: 0.1016\n","Epoch  9/12: Train Acc: 0.9577, Val Acc: 0.8558, Val F1: 0.8604, Gap: 0.1019\n","Epoch 10/12: Train Acc: 0.9616, Val Acc: 0.8512, Val F1: 0.8547, Gap: 0.1104\n","Epoch 11/12: Train Acc: 0.9661, Val Acc: 0.8384, Val F1: 0.8439, Gap: 0.1277\n","Epoch 12/12: Train Acc: 0.9690, Val Acc: 0.8642, Val F1: 0.8681, Gap: 0.1048\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▃▅▄▇▆█▇█▆██</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▄█▃▁▄▃▇▄▅▄▆█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▂▁▇█▇▇▅▇▇▆▅▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▄▄▆▆▇▆▇▆▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▅▇▇▆▅▆▇▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▄█▄▁▅▅█▆▆▄▅▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆█▇▇▇████</td></tr><tr><td>Class_Negative_Precision</td><td>▁▆▇▂▆▅▇▃█▅▄▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▂▇▆▅▄▇▃▇█▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▅▅▇██▇▇▇▃█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▅█▅▇▆█▆▇▇▄</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▃▄▂▆▆▆▄▅▅▁█</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▅▅█▇▇▇▇▇▂▇</td></tr><tr><td>Class_Positive_Precision</td><td>▆▄▄▄▇▇▇▆▅▅▁█</td></tr><tr><td>Class_Positive_Recall</td><td>▁▆▅▇▅▄▄▄▆▆█▃</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▅▇▇▇▇▇▇▅█</td></tr><tr><td>Validation F1</td><td>▁▄▅▅▇▇▇▇▇▇▆█</td></tr><tr><td>Validation Loss</td><td>▄▂▁▃▁▂▃▄▄▆█▅</td></tr><tr><td>Validation Precision</td><td>▁▄▄▃▆▆▇▆▆▅▄█</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇█▇▇███▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87079</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.89423</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.84854</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83869</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84232</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.8351</td></tr><tr><td>Class_Negative_F1</td><td>0.88911</td></tr><tr><td>Class_Negative_Precision</td><td>0.9115</td></tr><tr><td>Class_Negative_Recall</td><td>0.86779</td></tr><tr><td>Class_Neutral_F1</td><td>0.85467</td></tr><tr><td>Class_Neutral_Precision</td><td>0.80891</td></tr><tr><td>Class_Neutral_Recall</td><td>0.90591</td></tr><tr><td>Class_Positive_F1</td><td>0.88704</td></tr><tr><td>Class_Positive_Precision</td><td>0.93406</td></tr><tr><td>Class_Positive_Recall</td><td>0.84453</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.969</td></tr><tr><td>Train Loss</td><td>0.10452</td></tr><tr><td>Validation Accuracy</td><td>0.86419</td></tr><tr><td>Validation F1</td><td>0.86806</td></tr><tr><td>Validation Loss</td><td>0.60953</td></tr><tr><td>Validation Precision</td><td>0.8782</td></tr><tr><td>Validation Recall</td><td>0.86037</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/bsdhfkb7' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/bsdhfkb7</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_172056-bsdhfkb7/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 18:02:54,591] Trial 6 finished with value: 0.8641885325558795 and parameters: {'learning_rate': 2.0594429606083194e-05, 'weight_decay': 2.7814766462153523e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 1.0, 'use_class_weights': True}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_180256-usg48lb2</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/usg48lb2' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/usg48lb2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/usg48lb2</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6720, Val Acc: 0.7283, Val F1: 0.7379, Gap: -0.0562\n","Epoch  2/12: Train Acc: 0.8171, Val Acc: 0.8358, Val F1: 0.8415, Gap: -0.0186\n","Epoch  3/12: Train Acc: 0.8681, Val Acc: 0.8015, Val F1: 0.8067, Gap: 0.0666\n","Epoch  4/12: Train Acc: 0.8976, Val Acc: 0.8257, Val F1: 0.8288, Gap: 0.0719\n","Epoch  5/12: Train Acc: 0.9199, Val Acc: 0.8015, Val F1: 0.8057, Gap: 0.1184\n","Epoch  6/12: Train Acc: 0.9339, Val Acc: 0.8471, Val F1: 0.8528, Gap: 0.0868\n","Epoch  7/12: Train Acc: 0.9444, Val Acc: 0.8591, Val F1: 0.8629, Gap: 0.0853\n","Epoch  8/12: Train Acc: 0.9516, Val Acc: 0.8251, Val F1: 0.8285, Gap: 0.1266\n","Epoch  9/12: Train Acc: 0.9550, Val Acc: 0.8570, Val F1: 0.8606, Gap: 0.0980\n","Epoch 10/12: Train Acc: 0.9608, Val Acc: 0.8520, Val F1: 0.8548, Gap: 0.1088\n","Epoch 11/12: Train Acc: 0.9657, Val Acc: 0.8489, Val F1: 0.8524, Gap: 0.1169\n","Epoch 12/12: Train Acc: 0.9686, Val Acc: 0.8492, Val F1: 0.8501, Gap: 0.1193\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▃▃▂▇█▅█▇▇▄</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▅▂▂▁▄▆▃▅▅▄█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▆▅█▇█▇▅▇▆▆▆▁</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▆▃▄▃▆█▅█▇▇▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▁▃▅▆▁▆█▆▆▅▃</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▇▃▃▁▇▇▃▇▆▆█</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▇█▆▇▇▅▆▇▆▇</td></tr><tr><td>Class_Negative_Precision</td><td>▃▆▇▆██▃▂▁▅▁▂</td></tr><tr><td>Class_Negative_Recall</td><td>▁▃▄▆▃▄█▆█▆▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▇▆▇▆██▇████</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▇█▆█▅▆▇▅█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▄▆▅▆█▆▇█▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▁█▅▇▆██▇█▇██</td></tr><tr><td>Class_Positive_Precision</td><td>▁▇▄▅▄▇█▅▇█▆▆</td></tr><tr><td>Class_Positive_Recall</td><td>▆▄▇▆█▄▂▇▃▁▆▆</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▇▅▆▅▇█▆██▇▇</td></tr><tr><td>Validation F1</td><td>▁▇▅▆▅▇█▆██▇▇</td></tr><tr><td>Validation Loss</td><td>▆▁▂▁▄▂▂▆▄▅▅█</td></tr><tr><td>Validation Precision</td><td>▁▇▄▆▅▇█▆██▇█</td></tr><tr><td>Validation Recall</td><td>▁▇▆▇▆██▇█▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.82305</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.9434</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.72993</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.81929</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.79629</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.84367</td></tr><tr><td>Class_Negative_F1</td><td>0.87492</td></tr><tr><td>Class_Negative_Precision</td><td>0.86172</td></tr><tr><td>Class_Negative_Recall</td><td>0.88853</td></tr><tr><td>Class_Neutral_F1</td><td>0.84795</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84777</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84814</td></tr><tr><td>Class_Positive_F1</td><td>0.88539</td></tr><tr><td>Class_Positive_Precision</td><td>0.85989</td></tr><tr><td>Class_Positive_Recall</td><td>0.91245</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96856</td></tr><tr><td>Train Loss</td><td>0.11001</td></tr><tr><td>Validation Accuracy</td><td>0.84925</td></tr><tr><td>Validation F1</td><td>0.85012</td></tr><tr><td>Validation Loss</td><td>0.77551</td></tr><tr><td>Validation Precision</td><td>0.86181</td></tr><tr><td>Validation Recall</td><td>0.84454</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/usg48lb2' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/usg48lb2</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_180256-usg48lb2/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 18:44:58,660] Trial 7 finished with value: 0.859086491739553 and parameters: {'learning_rate': 2.0356034681538667e-05, 'weight_decay': 8.85734487105513e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_184500-4775ewm4</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/4775ewm4' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/4775ewm4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/4775ewm4</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6699, Val Acc: 0.7711, Val F1: 0.7796, Gap: -0.1013\n","Epoch  2/12: Train Acc: 0.8108, Val Acc: 0.8243, Val F1: 0.8299, Gap: -0.0135\n","Epoch  3/12: Train Acc: 0.8632, Val Acc: 0.8455, Val F1: 0.8510, Gap: 0.0177\n","Epoch  4/12: Train Acc: 0.8905, Val Acc: 0.8542, Val F1: 0.8591, Gap: 0.0363\n","Epoch  5/12: Train Acc: 0.9146, Val Acc: 0.8344, Val F1: 0.8366, Gap: 0.0802\n","Epoch  6/12: Train Acc: 0.9267, Val Acc: 0.8543, Val F1: 0.8589, Gap: 0.0724\n","Epoch  7/12: Train Acc: 0.9377, Val Acc: 0.8483, Val F1: 0.8508, Gap: 0.0895\n","Epoch  8/12: Train Acc: 0.9456, Val Acc: 0.8551, Val F1: 0.8591, Gap: 0.0905\n","Epoch  9/12: Train Acc: 0.9519, Val Acc: 0.8537, Val F1: 0.8556, Gap: 0.0981\n","Epoch 10/12: Train Acc: 0.9573, Val Acc: 0.8494, Val F1: 0.8536, Gap: 0.1079\n","Epoch 11/12: Train Acc: 0.9607, Val Acc: 0.8462, Val F1: 0.8495, Gap: 0.1145\n","Epoch 12/12: Train Acc: 0.9630, Val Acc: 0.8624, Val F1: 0.8662, Gap: 0.1006\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▅▆█▃█▅▇▅▇▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▃█▆▁▆▂▆█▇▄█</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▅▆▂▅█▆█▅▁▄▇▃</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▄▇▇▄▇▆▇▇▇▇█</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▅▅▇▇▇▇▄▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▂▂▇▇▁▅▃▅█▅▃▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▇█▇▇█▇▇▆▅▇</td></tr><tr><td>Class_Negative_Precision</td><td>▅▇██▅▆▇▆▄▄▁▆</td></tr><tr><td>Class_Negative_Recall</td><td>▁▄▄▅▇▅▆▅▇▆█▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇▇▇█▇█▇▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▄▆▇▄▇▅▇▅█▅</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▆▆▅▄█▅▇▆▅▃█</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▇▇▆▇▇██▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▄▄▁▆▁▅█▁▁▇</td></tr><tr><td>Class_Positive_Recall</td><td>▁▃▆▅▇▄█▆▄▇█▅</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇▆▇▇▇▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▇▇▆▇▇▇▇▇▇█</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▄▄▅▅▇█▇▇</td></tr><tr><td>Validation Precision</td><td>▁▅▇▇▅▇▆▇▇▆▆█</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▇▇██▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.87097</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.90711</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.83759</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83848</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84866</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.82854</td></tr><tr><td>Class_Negative_F1</td><td>0.87851</td></tr><tr><td>Class_Negative_Precision</td><td>0.88545</td></tr><tr><td>Class_Negative_Recall</td><td>0.87168</td></tr><tr><td>Class_Neutral_F1</td><td>0.85273</td></tr><tr><td>Class_Neutral_Precision</td><td>0.81467</td></tr><tr><td>Class_Neutral_Recall</td><td>0.89453</td></tr><tr><td>Class_Positive_F1</td><td>0.89035</td></tr><tr><td>Class_Positive_Precision</td><td>0.91481</td></tr><tr><td>Class_Positive_Recall</td><td>0.86717</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96295</td></tr><tr><td>Train Loss</td><td>0.12858</td></tr><tr><td>Validation Accuracy</td><td>0.86237</td></tr><tr><td>Validation F1</td><td>0.86621</td></tr><tr><td>Validation Loss</td><td>0.5841</td></tr><tr><td>Validation Precision</td><td>0.87414</td></tr><tr><td>Validation Recall</td><td>0.8599</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/4775ewm4' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/4775ewm4</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_184500-4775ewm4/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 19:27:03,052] Trial 8 finished with value: 0.8623663751214772 and parameters: {'learning_rate': 1.8435841974290052e-05, 'weight_decay': 1.8078400214564795e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': False}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Computing class weights...\n","Computing class weights for 39030 samples\n","Label distribution: [6273 7934 8716 9137 6970]\n","Class weights computed:\n","Extremely Negative (0): 1.244\n","Extremely Positive (1): 0.984\n","Negative (2): 0.896\n","Neutral (3): 0.854\n","Positive (4): 1.120\n","Using weighted CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_192705-j4d8b8ib</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/j4d8b8ib' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/j4d8b8ib' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/j4d8b8ib</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6683, Val Acc: 0.7847, Val F1: 0.7924, Gap: -0.1165\n","Epoch  2/12: Train Acc: 0.8149, Val Acc: 0.7844, Val F1: 0.7929, Gap: 0.0305\n","Epoch  3/12: Train Acc: 0.8648, Val Acc: 0.8440, Val F1: 0.8509, Gap: 0.0208\n","Epoch  4/12: Train Acc: 0.8915, Val Acc: 0.8415, Val F1: 0.8465, Gap: 0.0500\n","Epoch  5/12: Train Acc: 0.9133, Val Acc: 0.8405, Val F1: 0.8450, Gap: 0.0728\n","Epoch  6/12: Train Acc: 0.9257, Val Acc: 0.8517, Val F1: 0.8557, Gap: 0.0740\n","Epoch  7/12: Train Acc: 0.9360, Val Acc: 0.8421, Val F1: 0.8475, Gap: 0.0939\n","Epoch  8/12: Train Acc: 0.9438, Val Acc: 0.8155, Val F1: 0.8210, Gap: 0.1283\n","Epoch  9/12: Train Acc: 0.9491, Val Acc: 0.8491, Val F1: 0.8537, Gap: 0.1000\n","Epoch 10/12: Train Acc: 0.9526, Val Acc: 0.8506, Val F1: 0.8538, Gap: 0.1020\n","Epoch 11/12: Train Acc: 0.9579, Val Acc: 0.8595, Val F1: 0.8631, Gap: 0.0984\n","Epoch 12/12: Train Acc: 0.9617, Val Acc: 0.8533, Val F1: 0.8569, Gap: 0.1084\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄█▇▆▆▇▆█▅▇█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▂▃▄▃▂▅▂▄▁█▇</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁▆▇▆▆▇▅▇▇█▁▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▃▅▆▆▆▆▅▇▅██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▅▂▄▇▅▆█▆▆▃▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▁▅▅▃▄▄▁▅▃█▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▅▆▆▆█▆▅▇██▅</td></tr><tr><td>Class_Negative_Precision</td><td>▃▇▇▅▆██▄▆▇█▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▂▃▅▄▅▃▅▅▄▄█</td></tr><tr><td>Class_Neutral_F1</td><td>▃▁▇▆▆▇▆▄▇███</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▃▇█▆▇▅▅█▇▇▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▅▁▇▅▆▇▇▄▆█▇█</td></tr><tr><td>Class_Positive_F1</td><td>▄▁█▆▆█▇▄▆█▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▅▁▇▅▅▆▅▃▅▇▆█</td></tr><tr><td>Class_Positive_Recall</td><td>▃█▃▆▇▅▇▇▇▅▆▁</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁▇▆▆▇▆▄▇▇█▇</td></tr><tr><td>Validation F1</td><td>▁▁▇▆▆▇▆▄▇▇█▇</td></tr><tr><td>Validation Loss</td><td>▆▆▁▂▂▁▄█▄▇▇▇</td></tr><tr><td>Validation Precision</td><td>▁▁▆▅▅▆▆▃▆▆█▇</td></tr><tr><td>Validation Recall</td><td>▁▃▇▇▇█▇▅███▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86843</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.88531</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.85219</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.83342</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83174</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.8351</td></tr><tr><td>Class_Negative_F1</td><td>0.86082</td></tr><tr><td>Class_Negative_Precision</td><td>0.81675</td></tr><tr><td>Class_Negative_Recall</td><td>0.90992</td></tr><tr><td>Class_Neutral_F1</td><td>0.84555</td></tr><tr><td>Class_Neutral_Precision</td><td>0.84298</td></tr><tr><td>Class_Neutral_Recall</td><td>0.84814</td></tr><tr><td>Class_Positive_F1</td><td>0.87605</td></tr><tr><td>Class_Positive_Precision</td><td>0.93493</td></tr><tr><td>Class_Positive_Recall</td><td>0.82415</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.96167</td></tr><tr><td>Train Loss</td><td>0.12577</td></tr><tr><td>Validation Accuracy</td><td>0.85326</td></tr><tr><td>Validation F1</td><td>0.85685</td></tr><tr><td>Validation Loss</td><td>0.58747</td></tr><tr><td>Validation Precision</td><td>0.86234</td></tr><tr><td>Validation Recall</td><td>0.8539</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/j4d8b8ib' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/j4d8b8ib</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_192705-j4d8b8ib/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 20:09:07,593] Trial 9 finished with value: 0.8594509232264335 and parameters: {'learning_rate': 1.8096107997421157e-05, 'weight_decay': 2.5863955768891947e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.2, 'gradient_clip_val': 0.5, 'use_class_weights': True}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_200909-5liiooje</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/5liiooje' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/5liiooje' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/5liiooje</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6692, Val Acc: 0.7642, Val F1: 0.7734, Gap: -0.0950\n","Epoch  2/12: Train Acc: 0.8180, Val Acc: 0.7983, Val F1: 0.8047, Gap: 0.0196\n","Epoch  3/12: Train Acc: 0.8667, Val Acc: 0.8403, Val F1: 0.8461, Gap: 0.0265\n","Epoch  4/12: Train Acc: 0.8982, Val Acc: 0.8457, Val F1: 0.8506, Gap: 0.0525\n","Epoch  5/12: Train Acc: 0.9190, Val Acc: 0.8511, Val F1: 0.8556, Gap: 0.0679\n","Epoch  6/12: Train Acc: 0.9346, Val Acc: 0.8497, Val F1: 0.8541, Gap: 0.0849\n","Epoch  7/12: Train Acc: 0.9452, Val Acc: 0.8458, Val F1: 0.8510, Gap: 0.0994\n","Epoch  8/12: Train Acc: 0.9554, Val Acc: 0.8584, Val F1: 0.8625, Gap: 0.0971\n","Epoch  9/12: Train Acc: 0.9623, Val Acc: 0.8576, Val F1: 0.8617, Gap: 0.1047\n","Epoch 10/12: Train Acc: 0.9665, Val Acc: 0.8522, Val F1: 0.8563, Gap: 0.1143\n","Epoch 11/12: Train Acc: 0.9721, Val Acc: 0.8540, Val F1: 0.8584, Gap: 0.1181\n","Epoch 12/12: Train Acc: 0.9754, Val Acc: 0.8502, Val F1: 0.8543, Gap: 0.1251\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▁▆▆▆▇▇█▇██▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▁█▅▆▅▇▇▇▇▇▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄█▁▆▅▇▄▅▄▅▅▅</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▂▇▇▇▇███▇█▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▄▁▅▅▅▇▆█▆▆▆█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▄▇▇▇▆█▇█▇▇▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆▇▇▇▇▇█▆▆█</td></tr><tr><td>Class_Negative_Precision</td><td>▂█▇█▆▆▇▃▆▁▃▆</td></tr><tr><td>Class_Negative_Recall</td><td>▂▁▄▅▆▆▅▇▇█▇▇</td></tr><tr><td>Class_Neutral_F1</td><td>▁▅▆▇█▇▆████▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▆▄██▇█▇▇▇▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▃█▅▇▆▄▇█▇█▆</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▇▇█▇▆█▇▇█▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▅▆▅▇▅▃▆▇██▄</td></tr><tr><td>Class_Positive_Recall</td><td>▄▃▄▆▄▅█▅▃▁▂▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▇▇▇▇▇████▇</td></tr><tr><td>Validation F1</td><td>▁▃▇▇▇▇▇████▇</td></tr><tr><td>Validation Loss</td><td>▄▃▁▁▁▃▂▃▄▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▃▇▇▇▇▇██▇█▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇█▇██▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.85853</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.83035</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.88869</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82089</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86062</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.78467</td></tr><tr><td>Class_Negative_F1</td><td>0.88859</td></tr><tr><td>Class_Negative_Precision</td><td>0.91257</td></tr><tr><td>Class_Negative_Recall</td><td>0.86585</td></tr><tr><td>Class_Neutral_F1</td><td>0.83304</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82765</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83851</td></tr><tr><td>Class_Positive_F1</td><td>0.87022</td></tr><tr><td>Class_Positive_Precision</td><td>0.82677</td></tr><tr><td>Class_Positive_Recall</td><td>0.91849</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97535</td></tr><tr><td>Train Loss</td><td>0.09147</td></tr><tr><td>Validation Accuracy</td><td>0.85022</td></tr><tr><td>Validation F1</td><td>0.85425</td></tr><tr><td>Validation Loss</td><td>0.81565</td></tr><tr><td>Validation Precision</td><td>0.85159</td></tr><tr><td>Validation Recall</td><td>0.85924</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/5liiooje' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/5liiooje</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_200909-5liiooje/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 20:51:07,696] Trial 10 finished with value: 0.858357628765792 and parameters: {'learning_rate': 1.9262831588409542e-05, 'weight_decay': 2.3239435148241033e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_205109-g5lup2hz</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/g5lup2hz' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/g5lup2hz' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/g5lup2hz</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6739, Val Acc: 0.7360, Val F1: 0.7454, Gap: -0.0621\n","Epoch  2/12: Train Acc: 0.8160, Val Acc: 0.8133, Val F1: 0.8182, Gap: 0.0027\n","Epoch  3/12: Train Acc: 0.8647, Val Acc: 0.8364, Val F1: 0.8410, Gap: 0.0283\n","Epoch  4/12: Train Acc: 0.8944, Val Acc: 0.8443, Val F1: 0.8493, Gap: 0.0501\n","Epoch  5/12: Train Acc: 0.9159, Val Acc: 0.8320, Val F1: 0.8359, Gap: 0.0839\n","Epoch  6/12: Train Acc: 0.9321, Val Acc: 0.8296, Val F1: 0.8334, Gap: 0.1025\n","Epoch  7/12: Train Acc: 0.9449, Val Acc: 0.8485, Val F1: 0.8517, Gap: 0.0964\n","Epoch  8/12: Train Acc: 0.9533, Val Acc: 0.8547, Val F1: 0.8588, Gap: 0.0986\n","Epoch  9/12: Train Acc: 0.9616, Val Acc: 0.8543, Val F1: 0.8584, Gap: 0.1072\n","Epoch 10/12: Train Acc: 0.9650, Val Acc: 0.8540, Val F1: 0.8578, Gap: 0.1110\n","Epoch 11/12: Train Acc: 0.9717, Val Acc: 0.8576, Val F1: 0.8619, Gap: 0.1141\n","Epoch 12/12: Train Acc: 0.9736, Val Acc: 0.8288, Val F1: 0.8322, Gap: 0.1448\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▄▆▆▅▄▆▇▇██▅</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁▂▇▅▃▂▄▆▅██▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▃▆▁▅██▇▄▅▂▃▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▅▇▇▆▅▆▇▇██▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▄▆▄▆▅▇▅▅▇█▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁▅▇█▆▅▆████▅</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆█▇█▇▇█▆█▅</td></tr><tr><td>Class_Negative_Precision</td><td>▅▇▄█▇▇▅▆▇▃▅▁</td></tr><tr><td>Class_Negative_Recall</td><td>▁▅▆▆▆▇▇▇▆█▇█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▆▆▇▆▇███▇▇▆</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▆▇▇█▇▇▆▇▇▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▅▅▆▄▄▇▇█▆▆▄</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▆▇▆▇██▇▇▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁▄▄▅▄▄▆▆█▅▅▅</td></tr><tr><td>Class_Positive_Recall</td><td>▅▅▇▆██▆▆▁▇█▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇▇▆▇████▆</td></tr><tr><td>Validation F1</td><td>▁▅▇▇▆▆▇████▆</td></tr><tr><td>Validation Loss</td><td>▆▂▁▁▃▅▃▄▆▅▇█</td></tr><tr><td>Validation Precision</td><td>▁▅▇▇▆▆▇████▆</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇▇██▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83299</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.7569</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.92609</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.7908</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.85339</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.73676</td></tr><tr><td>Class_Negative_F1</td><td>0.85546</td></tr><tr><td>Class_Negative_Precision</td><td>0.82035</td></tr><tr><td>Class_Negative_Recall</td><td>0.89371</td></tr><tr><td>Class_Neutral_F1</td><td>0.81376</td></tr><tr><td>Class_Neutral_Precision</td><td>0.86806</td></tr><tr><td>Class_Neutral_Recall</td><td>0.76586</td></tr><tr><td>Class_Positive_F1</td><td>0.86783</td></tr><tr><td>Class_Positive_Precision</td><td>0.82186</td></tr><tr><td>Class_Positive_Recall</td><td>0.91925</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97361</td></tr><tr><td>Train Loss</td><td>0.0974</td></tr><tr><td>Validation Accuracy</td><td>0.82884</td></tr><tr><td>Validation F1</td><td>0.83217</td></tr><tr><td>Validation Loss</td><td>0.80359</td></tr><tr><td>Validation Precision</td><td>0.82411</td></tr><tr><td>Validation Recall</td><td>0.84834</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/g5lup2hz' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/g5lup2hz</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_205109-g5lup2hz/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 21:32:52,612] Trial 11 finished with value: 0.8576287657920311 and parameters: {'learning_rate': 1.917664365116795e-05, 'weight_decay': 4.290611770774633e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_213254-rtgredbd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/rtgredbd' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/rtgredbd' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/rtgredbd</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6731, Val Acc: 0.7724, Val F1: 0.7805, Gap: -0.0992\n","Epoch  2/12: Train Acc: 0.8180, Val Acc: 0.7945, Val F1: 0.8001, Gap: 0.0235\n","Epoch  3/12: Train Acc: 0.8667, Val Acc: 0.8330, Val F1: 0.8363, Gap: 0.0337\n","Epoch  4/12: Train Acc: 0.8992, Val Acc: 0.8372, Val F1: 0.8410, Gap: 0.0619\n","Epoch  5/12: Train Acc: 0.9200, Val Acc: 0.8299, Val F1: 0.8350, Gap: 0.0901\n","Epoch  6/12: Train Acc: 0.9351, Val Acc: 0.8458, Val F1: 0.8501, Gap: 0.0893\n","Epoch  7/12: Train Acc: 0.9466, Val Acc: 0.8505, Val F1: 0.8547, Gap: 0.0962\n","Epoch  8/12: Train Acc: 0.9550, Val Acc: 0.8548, Val F1: 0.8588, Gap: 0.1002\n","Epoch  9/12: Train Acc: 0.9622, Val Acc: 0.8575, Val F1: 0.8617, Gap: 0.1047\n","Epoch 10/12: Train Acc: 0.9670, Val Acc: 0.8438, Val F1: 0.8474, Gap: 0.1232\n","Epoch 11/12: Train Acc: 0.9726, Val Acc: 0.8360, Val F1: 0.8401, Gap: 0.1366\n","Epoch 12/12: Train Acc: 0.9736, Val Acc: 0.8582, Val F1: 0.8622, Gap: 0.1154\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▂▁▃▄▇▆▇▇█▆▅█</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▃▁▂▃▅█▅█▇▄▃▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▄▇▇▆▇▁▇▂▄▇█▆</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▁▅▄▆▇▆██▆▄▇</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▆▇▅▇▄▇▅█▇▆▇</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▃▁▄▄▅█▅█▇▅▄▆</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▆▆▇▇▆██▆▇█</td></tr><tr><td>Class_Negative_Precision</td><td>▂▇▄█▄▇▂▆█▁▁▃</td></tr><tr><td>Class_Negative_Recall</td><td>▁▁▅▄▆▄▇▇▅▇██</td></tr><tr><td>Class_Neutral_F1</td><td>▁▄▇█▅▇██▇█▇█</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▂▄▅▇▅▇▆▆▅█▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▄▇█▂▇▆▇▇▇▅▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▄▇▇▄▇█▇█▇▇█</td></tr><tr><td>Class_Positive_Precision</td><td>▁▂▇█▁▆▆▆▄█▅▇</td></tr><tr><td>Class_Positive_Recall</td><td>▄▇▃▂█▅▆▄█▁▆▄</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▆▆▇▇██▇▆█</td></tr><tr><td>Validation F1</td><td>▁▃▆▆▆▇▇██▇▆█</td></tr><tr><td>Validation Loss</td><td>▄▂▁▁▃▂▃▄▄▅█▆</td></tr><tr><td>Validation Precision</td><td>▁▃▆▆▅▇▇██▇▆█</td></tr><tr><td>Validation Recall</td><td>▁▃▆▆▆▆█▇█▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86568</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.82426</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.9115</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82247</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.83708</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80837</td></tr><tr><td>Class_Negative_F1</td><td>0.88703</td></tr><tr><td>Class_Negative_Precision</td><td>0.87858</td></tr><tr><td>Class_Negative_Recall</td><td>0.89566</td></tr><tr><td>Class_Neutral_F1</td><td>0.84866</td></tr><tr><td>Class_Neutral_Precision</td><td>0.85952</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83807</td></tr><tr><td>Class_Positive_F1</td><td>0.88703</td></tr><tr><td>Class_Positive_Precision</td><td>0.89417</td></tr><tr><td>Class_Positive_Recall</td><td>0.88</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97361</td></tr><tr><td>Train Loss</td><td>0.09509</td></tr><tr><td>Validation Accuracy</td><td>0.85824</td></tr><tr><td>Validation F1</td><td>0.86218</td></tr><tr><td>Validation Loss</td><td>0.73694</td></tr><tr><td>Validation Precision</td><td>0.85872</td></tr><tr><td>Validation Recall</td><td>0.86672</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/rtgredbd' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/rtgredbd</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_213254-rtgredbd/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 22:14:51,381] Trial 12 finished with value: 0.8582361516034985 and parameters: {'learning_rate': 1.9896869731023e-05, 'weight_decay': 1.0845015059825479e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_221453-74cee64i</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/74cee64i' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/74cee64i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/74cee64i</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6669, Val Acc: 0.7273, Val F1: 0.7363, Gap: -0.0604\n","Epoch  2/12: Train Acc: 0.8130, Val Acc: 0.8314, Val F1: 0.8364, Gap: -0.0184\n","Epoch  3/12: Train Acc: 0.8665, Val Acc: 0.8191, Val F1: 0.8252, Gap: 0.0474\n","Epoch  4/12: Train Acc: 0.8949, Val Acc: 0.8509, Val F1: 0.8568, Gap: 0.0439\n","Epoch  5/12: Train Acc: 0.9178, Val Acc: 0.8478, Val F1: 0.8517, Gap: 0.0700\n","Epoch  6/12: Train Acc: 0.9330, Val Acc: 0.8522, Val F1: 0.8562, Gap: 0.0808\n","Epoch  7/12: Train Acc: 0.9452, Val Acc: 0.8575, Val F1: 0.8615, Gap: 0.0877\n","Epoch  8/12: Train Acc: 0.9538, Val Acc: 0.8511, Val F1: 0.8550, Gap: 0.1027\n","Epoch  9/12: Train Acc: 0.9602, Val Acc: 0.8410, Val F1: 0.8442, Gap: 0.1192\n","Epoch 10/12: Train Acc: 0.9658, Val Acc: 0.8562, Val F1: 0.8606, Gap: 0.1097\n","Epoch 11/12: Train Acc: 0.9687, Val Acc: 0.8535, Val F1: 0.8584, Gap: 0.1152\n","Epoch 12/12: Train Acc: 0.9734, Val Acc: 0.8395, Val F1: 0.8429, Gap: 0.1339\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▆▄█▆▇▇▇▆▇▇▆</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▁█▃▇▅▆▇▇▅▇▆▄</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▇▁█▆▇▆▅▅▆▅▆█</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▁▇▅█▇▇██▇█▇▆</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▂▁▄▇▆▆▇▆▅▄█</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▁█▅█▆▆▇▆▅▇▇▄</td></tr><tr><td>Class_Negative_F1</td><td>▁▆▆██▇█▆▆▇█▇</td></tr><tr><td>Class_Negative_Precision</td><td>▄▅█▅▇▅▆▁▂▆▆▅</td></tr><tr><td>Class_Negative_Recall</td><td>▁▆▄▇▆▆▆█▇▆▆▆</td></tr><tr><td>Class_Neutral_F1</td><td>▁▇▇▇███████▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▄▇▆▅▇▆▇▇▇█▆</td></tr><tr><td>Class_Neutral_Recall</td><td>▁▇▅▆█▇█▇▆▇▆▇</td></tr><tr><td>Class_Positive_F1</td><td>▁▆▇▇▇██▇▇██▇</td></tr><tr><td>Class_Positive_Precision</td><td>▁█▆▇▇▆▇▆▆▇▆▅</td></tr><tr><td>Class_Positive_Recall</td><td>▇▁▇▄▄▆▅▇▇▇▇█</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▇▆█▇███▇██▇</td></tr><tr><td>Validation F1</td><td>▁▇▆█▇███▇██▇</td></tr><tr><td>Validation Loss</td><td>▇▁▃▁▂▁▄▄▇▇██</td></tr><tr><td>Validation Precision</td><td>▁▇▆█▇▇█▇▇█▇▇</td></tr><tr><td>Validation Recall</td><td>▁▅▆█▇███▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.83973</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.75308</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.94891</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.78865</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.86938</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.72163</td></tr><tr><td>Class_Negative_F1</td><td>0.8719</td></tr><tr><td>Class_Negative_Precision</td><td>0.90341</td></tr><tr><td>Class_Negative_Recall</td><td>0.84251</td></tr><tr><td>Class_Neutral_F1</td><td>0.83428</td></tr><tr><td>Class_Neutral_Precision</td><td>0.82923</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83939</td></tr><tr><td>Class_Positive_F1</td><td>0.87977</td></tr><tr><td>Class_Positive_Precision</td><td>0.84102</td></tr><tr><td>Class_Positive_Recall</td><td>0.92226</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97341</td></tr><tr><td>Train Loss</td><td>0.09709</td></tr><tr><td>Validation Accuracy</td><td>0.83953</td></tr><tr><td>Validation F1</td><td>0.84286</td></tr><tr><td>Validation Loss</td><td>0.71161</td></tr><tr><td>Validation Precision</td><td>0.83922</td></tr><tr><td>Validation Recall</td><td>0.85494</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/74cee64i' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/74cee64i</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_221453-74cee64i/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 22:56:37,711] Trial 13 finished with value: 0.8575072886297376 and parameters: {'learning_rate': 1.882790193071207e-05, 'weight_decay': 7.85903305966131e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["Using standard CrossEntropyLoss\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250810_225639-snecvs1d</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/snecvs1d' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/snecvs1d' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/snecvs1d</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch  1/12: Train Acc: 0.6703, Val Acc: 0.7771, Val F1: 0.7835, Gap: -0.1068\n","Epoch  2/12: Train Acc: 0.8114, Val Acc: 0.7953, Val F1: 0.8014, Gap: 0.0161\n","Epoch  3/12: Train Acc: 0.8641, Val Acc: 0.8335, Val F1: 0.8390, Gap: 0.0306\n","Epoch  4/12: Train Acc: 0.8944, Val Acc: 0.8310, Val F1: 0.8367, Gap: 0.0633\n","Epoch  5/12: Train Acc: 0.9178, Val Acc: 0.8390, Val F1: 0.8439, Gap: 0.0788\n","Epoch  6/12: Train Acc: 0.9338, Val Acc: 0.8345, Val F1: 0.8387, Gap: 0.0993\n","Epoch  7/12: Train Acc: 0.9444, Val Acc: 0.8466, Val F1: 0.8509, Gap: 0.0978\n","Epoch  8/12: Train Acc: 0.9533, Val Acc: 0.8514, Val F1: 0.8555, Gap: 0.1019\n","Epoch  9/12: Train Acc: 0.9609, Val Acc: 0.8507, Val F1: 0.8551, Gap: 0.1102\n","Epoch 10/12: Train Acc: 0.9661, Val Acc: 0.8475, Val F1: 0.8503, Gap: 0.1186\n","Epoch 11/12: Train Acc: 0.9683, Val Acc: 0.8467, Val F1: 0.8516, Gap: 0.1216\n","Epoch 12/12: Train Acc: 0.9742, Val Acc: 0.8512, Val F1: 0.8548, Gap: 0.1230\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>▁▁▅▆▆▅▆██▆█▇</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>▅▁▄▅▄▃▄█▅▄▆▆</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>▁█▇▅▇▇█▂▇█▅▄</td></tr><tr><td>Class_Extremely Positive_F1</td><td>▂▁▅▆▆▆▇█▇▆██</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>▁▃▄▆▇▆▅▆▆█▇▆</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>▆▁▅▄▄▅▆█▇▂▆▇</td></tr><tr><td>Class_Negative_F1</td><td>▁▃▇▇▇▇█▆▆▆▅▆</td></tr><tr><td>Class_Negative_Precision</td><td>▁█▇▆▇▄▇▂▅▁▃▃</td></tr><tr><td>Class_Negative_Recall</td><td>▄▁▄▅▆▇▆█▆█▆█</td></tr><tr><td>Class_Neutral_F1</td><td>▁▃▆▄▅▅▇▇▇█▆▇</td></tr><tr><td>Class_Neutral_Precision</td><td>▁▅▅▅▅██▇▇▅▅▇</td></tr><tr><td>Class_Neutral_Recall</td><td>▃▂▅▄▄▁▃▅▄█▅▅</td></tr><tr><td>Class_Positive_F1</td><td>▁▅▇▆▇▆▇▇██▇▇</td></tr><tr><td>Class_Positive_Precision</td><td>█▂▆▁▂▁▃▄▄▇▄▄</td></tr><tr><td>Class_Positive_Recall</td><td>▁▇▆████▇▇▆▇▇</td></tr><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▆▇▆██████</td></tr><tr><td>Validation F1</td><td>▁▃▆▆▇▆███▇██</td></tr><tr><td>Validation Loss</td><td>▅▃▁▂▃▄▄▃▆█▆█</td></tr><tr><td>Validation Precision</td><td>▁▁▆▅▆▅▇█▇▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇█▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Extremely Negative_F1</td><td>0.86023</td></tr><tr><td>Class_Extremely Negative_Precision</td><td>0.85027</td></tr><tr><td>Class_Extremely Negative_Recall</td><td>0.87044</td></tr><tr><td>Class_Extremely Positive_F1</td><td>0.82338</td></tr><tr><td>Class_Extremely Positive_Precision</td><td>0.84114</td></tr><tr><td>Class_Extremely Positive_Recall</td><td>0.80635</td></tr><tr><td>Class_Negative_F1</td><td>0.87379</td></tr><tr><td>Class_Negative_Precision</td><td>0.8682</td></tr><tr><td>Class_Negative_Recall</td><td>0.87946</td></tr><tr><td>Class_Neutral_F1</td><td>0.83985</td></tr><tr><td>Class_Neutral_Precision</td><td>0.8479</td></tr><tr><td>Class_Neutral_Recall</td><td>0.83195</td></tr><tr><td>Class_Positive_F1</td><td>0.87651</td></tr><tr><td>Class_Positive_Precision</td><td>0.85185</td></tr><tr><td>Class_Positive_Recall</td><td>0.90264</td></tr><tr><td>Epoch</td><td>12</td></tr><tr><td>Train Accuracy</td><td>0.97417</td></tr><tr><td>Train Loss</td><td>0.09581</td></tr><tr><td>Validation Accuracy</td><td>0.85119</td></tr><tr><td>Validation F1</td><td>0.85475</td></tr><tr><td>Validation Loss</td><td>0.73781</td></tr><tr><td>Validation Precision</td><td>0.85187</td></tr><tr><td>Validation Recall</td><td>0.85817</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_14</strong> at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/snecvs1d' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3/runs/snecvs1d</a><br> View project at: <a href='https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3' target=\"_blank\">https://wandb.ai/yardenr1-tel-aviv-university/cardiffnlp_new5_6.3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250810_225639-snecvs1d/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-08-10 23:38:24,881] Trial 14 finished with value: 0.8514334305150631 and parameters: {'learning_rate': 1.872077428520276e-05, 'weight_decay': 3.803908202135172e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 0, 'dropout_rate': 0.3, 'gradient_clip_val': 1.0, 'use_class_weights': False}. Best is trial 4 with value: 0.8691690962099126.\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Best Results:\n","Validation Accuracy: 0.8692\n","Best hyperparameters:\n","  learning_rate: 2.08371793648536e-05\n","  weight_decay: 9.080837423383063e-06\n","  patience: 5\n","  batch_size: 32\n","  num_layers: 0\n","  dropout_rate: 0.3\n","  gradient_clip_val: 1.0\n","  use_class_weights: False\n","\n","Best model saved: best_model_trial_4.pt\n"]}],"source":["# ============ RUN THE STUDY ============\n","print(\"Starting Study 6.2:\")\n","study6 = optuna.create_study(direction=\"maximize\")\n","study6.optimize(objective, n_trials=15)\n","\n","\n","# ============ RUN THE STUDY ============\n","best_trial = study6.best_trial\n","best_model_path = f\"best_model_trial_{best_trial.number}.pt\"\n","print(f\"\\n Best Results:\")\n","print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n","print(f\"Best hyperparameters:\")\n","for key, value in best_trial.params.items():\n","    print(f\"  {key}: {value}\")\n","save_path = \"drive/MyDrive/deep_learning/best_model6.pt\"\n","model = RobertaWithDropout(\n","    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","    num_labels=5,\n","    dropout_rate=0.2\n",")\n","model.load_state_dict(torch.load(best_model_path))\n","torch.save(model.state_dict(), save_path)\n","print(f\"\\nBest model saved: {best_model_path}\")\n"]},{"cell_type":"markdown","source":["**Per-Class Recall Comparison — Study 5 (Dirty Data) vs. Study 6 (Dirty Data + Augmentations)**\n","\n","| Class                  | Recall (S5) | Recall (S6) | Δ (S6 - S5) | Interpretation                                                 |\n","| ---------------------- | ----------- | ----------- | ----------- | -------------------------------------------------------------- |\n","| Extremely Negative     | 0.853       | 0.857       | +0.004      | Negligible improvement, not directly targeted by augmentations |\n","| Negative               | 0.894       | 0.903       | +0.009      | Slight gain, likely a side effect of overall training          |\n","| **Neutral**            | **0.858**   | **0.874**   | **+0.016**  | Clear improvement, aligns with augmentation goal               |\n","| Positive               | 0.916       | 0.913       | −0.003      | Minor drop, negligible impact on overall performance           |\n","| **Extremely Positive** | **0.827**   | **0.846**   | **+0.019**  | Clear improvement, aligns with augmentation goal               |\n","\n","**Summary:**\n","Compared to Study 5, the augmentations in Study 6 achieved their primary objective — improving recall for the **Neutral** (+1.6%) and **Extremely Positive** (+1.9%) classes, which were previously underperforming. Other classes showed only minor fluctuations, with no significant negative effects on overall performance.\n"],"metadata":{"id":"ip4jg5i1BVAW"}},{"cell_type":"code","source":[],"metadata":{"id":"E-Zea1P-BZW4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01739522664242e49f6c561d18b600d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03a767631ae846fa8e20af9d9b9ac6bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"092780a508194683830af1279095ff7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a95338ce99e4dc0a77996949caee2d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"109363b6296b452982d78646bd17f7f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_791cc64adb534880b67734d732f0d471","placeholder":"​","style":"IPY_MODEL_fe58d4cdfb8b4d2f94bdad4cc99fc110","value":" 899k/? [00:00&lt;00:00, 16.7MB/s]"}},"12695d407ed5430c88baf20ed959f166":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12efb49319e44b8393eb69e2132bc03e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1466877b92be4f98b7121edbb110f8ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51bbe88d4b5945328d67b860b2566724","IPY_MODEL_48c6b416dbff4514a9eed4c2b3c137ff","IPY_MODEL_8a28070c383c415a89c5980b38a53877"],"layout":"IPY_MODEL_85e0b5f025ed47a79ca9c1b492e252aa"}},"150b56419f80417ba9b7b51c26f50f5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"159452003ca0492083c1599f8d6ea10c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15dad39514274f82a5794215d3bd48c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18e60b0b0da4417889aef85cf05e6945":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"190d37c386a24f8cab59a2f29ef89aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87efe0ed8046428191ffdd223a16db8d","placeholder":"​","style":"IPY_MODEL_f75d69fd415347c6a7fd40abb95002e9","value":" 501M/501M [00:01&lt;00:00, 445MB/s]"}},"19370daece5c4826a61bd9042b2c4ab2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e8dfa98cdad4f72a5b98d761fa9e7a2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_648f8170f41f43f58b4e7da88d4970d8","value":1}},"1ba01c503ebe49c0bc127d75b55f2e40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1bbb8a9cde71442db9729c09917465f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c5928899c104666a5f0eb4bc78a6807":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c76d54a59c294ffeaf8c1072a27fbbe8","IPY_MODEL_80d9885b0047485cba2065e991df80a9","IPY_MODEL_f2e290021d434cc6971431a14c1d92d7"],"layout":"IPY_MODEL_150b56419f80417ba9b7b51c26f50f5e"}},"1d2b14c8c2fd46bf92ee5bb12a0ba54b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1e5347f5e5144eb9228ba73877ed8cb","IPY_MODEL_52c952a3f1b543e095f0a93d31f2b460","IPY_MODEL_d9be2e5ef396465a8e7ab0309dbe07b4"],"layout":"IPY_MODEL_dce829ac8582421a9b3f0aa94cbe6eda"}},"1d4b073383e0476c867fb14bd161db06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fed3dd5dcce47d5880985b37274e326":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ace3d620091f4c68930f2bb473fe92f2","IPY_MODEL_e2b14fd81169483f9018364518cf7c9e","IPY_MODEL_2f93590d95af46b5aa269ffc97b5b5e9"],"layout":"IPY_MODEL_b6d435ccbf6e4b59be8df6a7a3287cee"}},"20b9f65792794bfd8ff110f132df34cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27c0e6b10d124ef58cad459ee4dfa944":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2968bfadfd10433f830471b0fb03e3ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2d24a98d67794f42a43bf5f83357a512":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_344ca8403271494f81827e22d7c8cc5c","placeholder":"​","style":"IPY_MODEL_f087a9445b9149fda56b23499967b06c","value":"model.safetensors: 100%"}},"2f31616899994b32a74683ad8c2d21f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f93590d95af46b5aa269ffc97b5b5e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a95338ce99e4dc0a77996949caee2d3","placeholder":"​","style":"IPY_MODEL_5821809aafc140529d0d2762370ab705","value":" 929/929 [00:00&lt;00:00, 109kB/s]"}},"303b2446c0674b1b99a35240c3f83483":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31243a99909b4863827c6444f8c01666":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bf0923fc37f4578bcce249c7dd5674a","IPY_MODEL_58e2dddda9b141d78cfba42d0c6a4064","IPY_MODEL_77670cb4c59e4a38b19a55a5168bbc69"],"layout":"IPY_MODEL_67936f439d8e43aa89240cf5af1e7b9a"}},"33af6287da9e49df82e4bf305c046cca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"344ca8403271494f81827e22d7c8cc5c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"349610bc77e248e0bfb3f8a9a4d7509e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a9589ca4b1e4fc9bac5cb706fd3833f","max":500982668,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8acd37462834e9c8459e9d433c55b0d","value":500982668}},"377cacad40e64e2e8e035f852665b0ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33af6287da9e49df82e4bf305c046cca","placeholder":"​","style":"IPY_MODEL_b1b67821d153465580c3c20868bca55b","value":" 501M/501M [00:01&lt;00:00, 512MB/s]"}},"3a9589ca4b1e4fc9bac5cb706fd3833f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b88faaca1f74a6ba14ef067ad65e7aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d24a98d67794f42a43bf5f83357a512","IPY_MODEL_6559806323e1431985757064ae58d8ce","IPY_MODEL_d9fd993d20414e9aa44b0ad9b0fd7fd5"],"layout":"IPY_MODEL_8291f2f253544bdcbb770d7552ac8989"}},"3bf0923fc37f4578bcce249c7dd5674a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6543cc2a33334618a555b235020b3761","placeholder":"​","style":"IPY_MODEL_d02430754b884da69c9917e3eda428ab","value":"special_tokens_map.json: 100%"}},"3da7ad155db043239b0f4e487b7d920e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_987de168da8842bdacb7a9d1e5411dc8","max":501045531,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20b9f65792794bfd8ff110f132df34cc","value":501045531}},"3df03553cdba445ebf0a35f4fd675b0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e817f64314845578f32f8eb992d4363":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40c39840d6d34b3b8123b6f16c9a0c9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db8c270765ef4365b29040fc015ef8e4","IPY_MODEL_7c1a1da55e0d4c78b9c2f4de2cec231c","IPY_MODEL_94136b082b224ed1b9a3edd8d341b807"],"layout":"IPY_MODEL_e3f73063f6a64fa0a64ca3b61280a631"}},"42c218c1d4bf4ed29bc1ea52c9e62cd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c9f18bb6c6140a3a5345b8dd1c1c045","IPY_MODEL_51a90984dcc54c2d97337deda5acb726","IPY_MODEL_fd016b073bbf494e88bba6145a83feb6"],"layout":"IPY_MODEL_01739522664242e49f6c561d18b600d9"}},"489a262bc666462bbd3ffd0316fe9438":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48c6b416dbff4514a9eed4c2b3c137ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e848afb738b465aa6bf8dcc15b924d0","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8404354b03b949afb17be7ea59fa466f","value":239}},"49aa6d67c3924651ada463cf952dbd2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_092780a508194683830af1279095ff7c","max":929,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7fa77fb5704f4e508d96ff6aded73f4c","value":929}},"4a1120808a994f5597d1bc72eee1ba06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e67156223544a108af30d99aef4a4d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e321fefb3f8143548c9aeb437f053ed1","IPY_MODEL_f222ef630b874b909aa68ab5b0be5515","IPY_MODEL_baf943f525714289aa4fd6a6830c2d2f"],"layout":"IPY_MODEL_9beebd8546aa419eb7c4a3e1a5d37bd0"}},"51a90984dcc54c2d97337deda5acb726":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc441f5da03c47349616063f802409b4","max":500982668,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6a9ef42d68f41b5bb8c3d843faffaf1","value":500982668}},"51bbe88d4b5945328d67b860b2566724":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3d1dfb73974f56a82fd0601d136b58","placeholder":"​","style":"IPY_MODEL_b8fadbb248ea46798ae565cb7f2546a2","value":"special_tokens_map.json: 100%"}},"52c952a3f1b543e095f0a93d31f2b460":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2968bfadfd10433f830471b0fb03e3ce","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6907f3604564578ac7af0dfc7bf2db8","value":1}},"535f2a3d8bc249cd8ddc0de7e59cc602":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"544775c9c728446b84d412c1aa309b78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5821809aafc140529d0d2762370ab705":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"588b467cb0ee4275baa04b3fb4de0da1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58e2dddda9b141d78cfba42d0c6a4064":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a481a32941a4417d812aec82e110d4e3","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8854d44b6444c11919eb6e38821cb7a","value":239}},"5bb25d0c047d4e77b18ff7397cfffd40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1cabdf2befd4180986a68c3cd278deb","placeholder":"​","style":"IPY_MODEL_dce87bf63bb3422fb308e05ffac3190d","value":"model.safetensors: 100%"}},"5bf341947c4d4b398b031418e25336ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5c9f18bb6c6140a3a5345b8dd1c1c045":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12efb49319e44b8393eb69e2132bc03e","placeholder":"​","style":"IPY_MODEL_bc1884ca4bce4bc0bad7efdd8f3d761e","value":"model.safetensors: 100%"}},"5d525f6bcae14db6844e01c709487fc2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b6e54b1acd94d799e3ce29cf02a6dcf","IPY_MODEL_3da7ad155db043239b0f4e487b7d920e","IPY_MODEL_377cacad40e64e2e8e035f852665b0ba"],"layout":"IPY_MODEL_b24ae0dd31da4f178791e480890409a0"}},"614676d031c640dd8c2061f7b199c2cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"648f8170f41f43f58b4e7da88d4970d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6543cc2a33334618a555b235020b3761":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6559806323e1431985757064ae58d8ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3df03553cdba445ebf0a35f4fd675b0b","max":500982668,"min":0,"orientation":"horizontal","style":"IPY_MODEL_614676d031c640dd8c2061f7b199c2cc","value":500982668}},"66a49f64e258489099edeb3ce00d1501":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67366159964541148d94ae24b0b3c4d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84c6f8d7aa034c6da5664b106b441a6b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9854c0f9ee6b493799795a009ce47d44","value":1}},"67936f439d8e43aa89240cf5af1e7b9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"682361786687425181abd36e3534094d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d4b073383e0476c867fb14bd161db06","placeholder":"​","style":"IPY_MODEL_15dad39514274f82a5794215d3bd48c4","value":"pytorch_model.bin: 100%"}},"68752be6a8f94661b0442a7561488549":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"692d90f342cd4b119395b69ef5950698":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b2a5d9790834621a33c6c72fe47970b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b6e54b1acd94d799e3ce29cf02a6dcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e53df7c354a4ac99d129e68dbcb2343","placeholder":"​","style":"IPY_MODEL_780023a8cf244c5aac0e23f5feaece4e","value":"pytorch_model.bin: 100%"}},"6ba9beb1c69c4c799e56f7ef57a9c1f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_682361786687425181abd36e3534094d","IPY_MODEL_9ae3337a7fc24d329d31a3b09da927ed","IPY_MODEL_190d37c386a24f8cab59a2f29ef89aca"],"layout":"IPY_MODEL_d2c19f9bfdfd412f9fd2b85cd089e9c5"}},"6c0e421be8b3418c8904f3db2c6d1aef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c43a9b19d9048cbbc29c4ce53fa9bfb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74e6dc2bd47d49f0b63f374b77187e98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75bfbc56ce794f7f84e8e3ac0ed9e257":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74e6dc2bd47d49f0b63f374b77187e98","placeholder":"​","style":"IPY_MODEL_c2bb406eeef54c22a9d428c85d444c6f","value":" 456k/? [00:00&lt;00:00, 35.6MB/s]"}},"77670cb4c59e4a38b19a55a5168bbc69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f31616899994b32a74683ad8c2d21f2","placeholder":"​","style":"IPY_MODEL_9e65aa16b1494f1e82d70993b0f5d3f2","value":" 239/239 [00:00&lt;00:00, 32.8kB/s]"}},"780023a8cf244c5aac0e23f5feaece4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7901646085674b61b7dc220ff74df2b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"791cc64adb534880b67734d732f0d471":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b59fd6bff20474cbd9dc47687dcf772":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0875cb432ae46f2a35be6fb71f13660","placeholder":"​","style":"IPY_MODEL_9e3f513097244e028d97e86b1db0afd7","value":" 456k/? [00:00&lt;00:00, 32.1MB/s]"}},"7b8412b7b9b74791a3b31de5cd19167a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c1a1da55e0d4c78b9c2f4de2cec231c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bf341947c4d4b398b031418e25336ca","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7901646085674b61b7dc220ff74df2b2","value":1}},"7e0f94c87a92477181b4c80144421cf3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fa77fb5704f4e508d96ff6aded73f4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80d9885b0047485cba2065e991df80a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b8412b7b9b74791a3b31de5cd19167a","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86afc1a9c2f146e8a97b30c8642c375e","value":239}},"80f9a69033fb483dafad4205a1522b31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"823c657b1d6b4854beef959796b2cb95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8291f2f253544bdcbb770d7552ac8989":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"834b16fcef1b416a9d924465fe3ca5a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8404354b03b949afb17be7ea59fa466f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84507535a8274756bd1ce86eca45f9aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84c6f8d7aa034c6da5664b106b441a6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"85e0b5f025ed47a79ca9c1b492e252aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"862c1c6aad5f488e80b18982f2b3b5fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8696082903eb488cb8d7f9f01618183d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90a8de76d56043c2a484a371ee9125ad","IPY_MODEL_67366159964541148d94ae24b0b3c4d4","IPY_MODEL_75bfbc56ce794f7f84e8e3ac0ed9e257"],"layout":"IPY_MODEL_03a767631ae846fa8e20af9d9b9ac6bd"}},"86afc1a9c2f146e8a97b30c8642c375e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87efe0ed8046428191ffdd223a16db8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"892f8b68d1bf488381a3b0dc95147a32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_588b467cb0ee4275baa04b3fb4de0da1","placeholder":"​","style":"IPY_MODEL_ea0cf48df68c4aeeb497469ecac9db80","value":"vocab.json: "}},"8a28070c383c415a89c5980b38a53877":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc9e9728e7df496c839d078b4d3951ff","placeholder":"​","style":"IPY_MODEL_535f2a3d8bc249cd8ddc0de7e59cc602","value":" 239/239 [00:00&lt;00:00, 32.2kB/s]"}},"8da0fe58ec0d4cdda1bf373a753a7d79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_159452003ca0492083c1599f8d6ea10c","placeholder":"​","style":"IPY_MODEL_9ecb50add3bf4e538086000798a53cc1","value":"config.json: 100%"}},"8e53df7c354a4ac99d129e68dbcb2343":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e848afb738b465aa6bf8dcc15b924d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e8dfa98cdad4f72a5b98d761fa9e7a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8f657983937a40b38a03374ae927ae52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cabfe531a42342b29da1bdd34531c97b","placeholder":"​","style":"IPY_MODEL_fe0d00a5ce254f20aca70ed013baf782","value":"config.json: 100%"}},"90a8de76d56043c2a484a371ee9125ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0e421be8b3418c8904f3db2c6d1aef","placeholder":"​","style":"IPY_MODEL_84507535a8274756bd1ce86eca45f9aa","value":"merges.txt: "}},"94136b082b224ed1b9a3edd8d341b807":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a08249c6a6174f20bc04d482180597d2","placeholder":"​","style":"IPY_MODEL_27c0e6b10d124ef58cad459ee4dfa944","value":" 456k/? [00:00&lt;00:00, 34.5MB/s]"}},"9452caa3cff943c4a702dadb7ed32e5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9647881014394c2f984bb5c6195c6575":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9791d4e213a94e5d9f67faf4e8234468":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9854c0f9ee6b493799795a009ce47d44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"987de168da8842bdacb7a9d1e5411dc8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9934cabfa2e14d4f9ad3f424db3e3357":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae3337a7fc24d329d31a3b09da927ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9791d4e213a94e5d9f67faf4e8234468","max":501045531,"min":0,"orientation":"horizontal","style":"IPY_MODEL_489a262bc666462bbd3ffd0316fe9438","value":501045531}},"9bded0129477418ba560056b71c15ff1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9beebd8546aa419eb7c4a3e1a5d37bd0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9df2883543dc455da9572e7f3bf31992":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e3f513097244e028d97e86b1db0afd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e5974812c3d495a972d5b2c14a6fa2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e65aa16b1494f1e82d70993b0f5d3f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ecb50add3bf4e538086000798a53cc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a08249c6a6174f20bc04d482180597d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a28ed6546f3b4f729a9acd134e4d110c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e0f94c87a92477181b4c80144421cf3","placeholder":"​","style":"IPY_MODEL_68752be6a8f94661b0442a7561488549","value":" 501M/501M [00:06&lt;00:00, 100MB/s]"}},"a460d6d3df2649cbbfffcb82949d4989":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a481a32941a4417d812aec82e110d4e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6907f3604564578ac7af0dfc7bf2db8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ace3d620091f4c68930f2bb473fe92f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3a837165cfa41139ec9206ee2f02a59","placeholder":"​","style":"IPY_MODEL_12695d407ed5430c88baf20ed959f166","value":"config.json: 100%"}},"ae53fbd8bee349fe9827d81e35570937":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae62a159c71b4bc88ffd98e88f2f39fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbb53446b54448c2a5203940f4a88706","placeholder":"​","style":"IPY_MODEL_f1cf1504e2fc47abb93039192ac9fe7b","value":"pytorch_model.bin: 100%"}},"b117c854525c4707b26cc36bb434b862":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bb25d0c047d4e77b18ff7397cfffd40","IPY_MODEL_349610bc77e248e0bfb3f8a9a4d7509e","IPY_MODEL_a28ed6546f3b4f729a9acd134e4d110c"],"layout":"IPY_MODEL_862c1c6aad5f488e80b18982f2b3b5fa"}},"b15b00097c2a4230a04afe3f89dddd35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b67821d153465580c3c20868bca55b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1cabdf2befd4180986a68c3cd278deb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b24ae0dd31da4f178791e480890409a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3d1c6de9d3644a8aa45ad6a75abb4de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc6dc64feb834315bb54f82a6d941c9f","IPY_MODEL_efc8a7925fa8401ebeace69b0681934b","IPY_MODEL_7b59fd6bff20474cbd9dc47687dcf772"],"layout":"IPY_MODEL_fe14ed43bb084dc9bcd180bc873fbc6b"}},"b550033498e345199086a7f83df35a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b2a5d9790834621a33c6c72fe47970b","max":929,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd5a57fd06b74c97a9085bde0aa5e36e","value":929}},"b6d435ccbf6e4b59be8df6a7a3287cee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7119493b85c44b79fb913c7af82d4db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b71bb3888cb14577888645bd81047c55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8fadbb248ea46798ae565cb7f2546a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba78ab20dc9946bf915e7f9fcfd8fb7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"baf943f525714289aa4fd6a6830c2d2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c485c30b4d2745048eb93adb3465a0e8","placeholder":"​","style":"IPY_MODEL_9647881014394c2f984bb5c6195c6575","value":" 899k/? [00:00&lt;00:00, 42.0MB/s]"}},"bb3d1dfb73974f56a82fd0601d136b58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbb53446b54448c2a5203940f4a88706":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc164ee4d46644a1b3dbc295839cc5c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f657983937a40b38a03374ae927ae52","IPY_MODEL_49aa6d67c3924651ada463cf952dbd2a","IPY_MODEL_dd3b4596496c4439a72599a5040732fe"],"layout":"IPY_MODEL_b15b00097c2a4230a04afe3f89dddd35"}},"bc1884ca4bce4bc0bad7efdd8f3d761e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc410b8865104ebca5ec34a77f4dea96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc6dc64feb834315bb54f82a6d941c9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b71bb3888cb14577888645bd81047c55","placeholder":"​","style":"IPY_MODEL_e517ea0cd925457b9c1fb57607887b2a","value":"merges.txt: "}},"bd5a57fd06b74c97a9085bde0aa5e36e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be3f32a3b0494412aa904f3abfe1104a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf506cbae7a24f67b4a926b016d75438":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_823c657b1d6b4854beef959796b2cb95","placeholder":"​","style":"IPY_MODEL_692d90f342cd4b119395b69ef5950698","value":" 501M/501M [00:01&lt;00:00, 511MB/s]"}},"c1d4188d4215420c9027fa081c42426c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2bb406eeef54c22a9d428c85d444c6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c406ea9a9d4c4c6fb1c806110f390f3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c485c30b4d2745048eb93adb3465a0e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a9ef42d68f41b5bb8c3d843faffaf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c76d54a59c294ffeaf8c1072a27fbbe8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1d4188d4215420c9027fa081c42426c","placeholder":"​","style":"IPY_MODEL_66a49f64e258489099edeb3ce00d1501","value":"special_tokens_map.json: 100%"}},"cabfe531a42342b29da1bdd34531c97b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf697038d0e34a27bac98b6be9bd36a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfbb940492014becb9a69a69352772e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d02430754b884da69c9917e3eda428ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1e5347f5e5144eb9228ba73877ed8cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed31faa94e284f839c4fc5aa0dd427f3","placeholder":"​","style":"IPY_MODEL_80f9a69033fb483dafad4205a1522b31","value":"vocab.json: "}},"d2c19f9bfdfd412f9fd2b85cd089e9c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d52142340819447c95e7c14bac28e116":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_892f8b68d1bf488381a3b0dc95147a32","IPY_MODEL_19370daece5c4826a61bd9042b2c4ab2","IPY_MODEL_109363b6296b452982d78646bd17f7f4"],"layout":"IPY_MODEL_544775c9c728446b84d412c1aa309b78"}},"d950f50f528a4dc39dbfe79224ac5d22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9be2e5ef396465a8e7ab0309dbe07b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7119493b85c44b79fb913c7af82d4db","placeholder":"​","style":"IPY_MODEL_3e817f64314845578f32f8eb992d4363","value":" 899k/? [00:00&lt;00:00, 19.6MB/s]"}},"d9fd993d20414e9aa44b0ad9b0fd7fd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a1120808a994f5597d1bc72eee1ba06","placeholder":"​","style":"IPY_MODEL_c406ea9a9d4c4c6fb1c806110f390f3c","value":" 501M/501M [00:04&lt;00:00, 89.0MB/s]"}},"db8c270765ef4365b29040fc015ef8e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bbb8a9cde71442db9729c09917465f2","placeholder":"​","style":"IPY_MODEL_fc5c718df6c24d04aac42241539cf99b","value":"merges.txt: "}},"dc9e9728e7df496c839d078b4d3951ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcaa88787cef443292e482a4c6591833":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a460d6d3df2649cbbfffcb82949d4989","placeholder":"​","style":"IPY_MODEL_9bded0129477418ba560056b71c15ff1","value":" 929/929 [00:00&lt;00:00, 109kB/s]"}},"dce829ac8582421a9b3f0aa94cbe6eda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce87bf63bb3422fb308e05ffac3190d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd3b4596496c4439a72599a5040732fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf697038d0e34a27bac98b6be9bd36a2","placeholder":"​","style":"IPY_MODEL_f18730ab599541bbbc9c2b62b92c3882","value":" 929/929 [00:00&lt;00:00, 119kB/s]"}},"df0c9da553cf4c6390ba791c38e0911b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2b14fd81169483f9018364518cf7c9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_834b16fcef1b416a9d924465fe3ca5a3","max":929,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfbb940492014becb9a69a69352772e5","value":929}},"e321fefb3f8143548c9aeb437f053ed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df0c9da553cf4c6390ba791c38e0911b","placeholder":"​","style":"IPY_MODEL_bc410b8865104ebca5ec34a77f4dea96","value":"vocab.json: "}},"e3f73063f6a64fa0a64ca3b61280a631":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e517ea0cd925457b9c1fb57607887b2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e94ae55261ba48eab7af2aa18802e084":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_303b2446c0674b1b99a35240c3f83483","max":501045531,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9452caa3cff943c4a702dadb7ed32e5c","value":501045531}},"ea0cf48df68c4aeeb497469ecac9db80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed31faa94e284f839c4fc5aa0dd427f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc8a7925fa8401ebeace69b0681934b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ba01c503ebe49c0bc127d75b55f2e40","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e5974812c3d495a972d5b2c14a6fa2a","value":1}},"f0875cb432ae46f2a35be6fb71f13660":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f087a9445b9149fda56b23499967b06c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f18730ab599541bbbc9c2b62b92c3882":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1cf1504e2fc47abb93039192ac9fe7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f222ef630b874b909aa68ab5b0be5515":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba78ab20dc9946bf915e7f9fcfd8fb7f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d950f50f528a4dc39dbfe79224ac5d22","value":1}},"f2e290021d434cc6971431a14c1d92d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c43a9b19d9048cbbc29c4ce53fa9bfb","placeholder":"​","style":"IPY_MODEL_18e60b0b0da4417889aef85cf05e6945","value":" 239/239 [00:00&lt;00:00, 30.6kB/s]"}},"f2ea1e3adda84b9caaddb06c9b74679f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae62a159c71b4bc88ffd98e88f2f39fe","IPY_MODEL_e94ae55261ba48eab7af2aa18802e084","IPY_MODEL_bf506cbae7a24f67b4a926b016d75438"],"layout":"IPY_MODEL_9df2883543dc455da9572e7f3bf31992"}},"f3a837165cfa41139ec9206ee2f02a59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f75d69fd415347c6a7fd40abb95002e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8854d44b6444c11919eb6e38821cb7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8acd37462834e9c8459e9d433c55b0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc441f5da03c47349616063f802409b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc5c718df6c24d04aac42241539cf99b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd00d5b11db54d22a8265393d9d83ac1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8da0fe58ec0d4cdda1bf373a753a7d79","IPY_MODEL_b550033498e345199086a7f83df35a2a","IPY_MODEL_dcaa88787cef443292e482a4c6591833"],"layout":"IPY_MODEL_9934cabfa2e14d4f9ad3f424db3e3357"}},"fd016b073bbf494e88bba6145a83feb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be3f32a3b0494412aa904f3abfe1104a","placeholder":"​","style":"IPY_MODEL_ae53fbd8bee349fe9827d81e35570937","value":" 501M/501M [00:01&lt;00:00, 134MB/s]"}},"fe0d00a5ce254f20aca70ed013baf782":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe14ed43bb084dc9bcd180bc873fbc6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe58d4cdfb8b4d2f94bdad4cc99fc110":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0964517f6c5425a81c95f529a553bcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7954b2052e574404b0b5f12a403d5c07","IPY_MODEL_c4f14e8cf9394b189a2d2729518c55a7","IPY_MODEL_a1c276769a364416ab70bbe6553fe98d"],"layout":"IPY_MODEL_655c1b29d98e465db3d2863d1cb4885f"}},"7954b2052e574404b0b5f12a403d5c07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bf68f5a9fac47dd9e6aa8c4b6f6d93c","placeholder":"​","style":"IPY_MODEL_ee997ff56b234037b1fdefcacd3f821d","value":"config.json: 100%"}},"c4f14e8cf9394b189a2d2729518c55a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3c8c864a4734048851ca77ac1bf8d8b","max":929,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fde0b0b20324d3b98c0f2f2b091bfc2","value":929}},"a1c276769a364416ab70bbe6553fe98d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86618747dc7b40deaecf9592d269a69b","placeholder":"​","style":"IPY_MODEL_6e2a53171fc3425586fbab2691f01247","value":" 929/929 [00:00&lt;00:00, 108kB/s]"}},"655c1b29d98e465db3d2863d1cb4885f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bf68f5a9fac47dd9e6aa8c4b6f6d93c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee997ff56b234037b1fdefcacd3f821d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3c8c864a4734048851ca77ac1bf8d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fde0b0b20324d3b98c0f2f2b091bfc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86618747dc7b40deaecf9592d269a69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e2a53171fc3425586fbab2691f01247":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b99707bfb5844cd990e156169a958954":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da1d0ea09f4b48d880924599c5d46c5a","IPY_MODEL_84204124b4a642a5a123ce370a578186","IPY_MODEL_18a5c032485541cfad910920d0810a02"],"layout":"IPY_MODEL_c009789e306c4499bb12147e14cfd990"}},"da1d0ea09f4b48d880924599c5d46c5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ce256e2ae37495e943cf904b4fa6b90","placeholder":"​","style":"IPY_MODEL_c3fc74edd965431d8c47c1cbe909030e","value":"vocab.json: "}},"84204124b4a642a5a123ce370a578186":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9293830855a471bbccc471c43e3143d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50ac0bd9971f462fbf9b4c7d5fc0024f","value":1}},"18a5c032485541cfad910920d0810a02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbb4478b93fa4e66a05ff86b630d583a","placeholder":"​","style":"IPY_MODEL_49168f0f15ab4a6b9816cacc6f6a68a2","value":" 899k/? [00:00&lt;00:00, 36.8MB/s]"}},"c009789e306c4499bb12147e14cfd990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ce256e2ae37495e943cf904b4fa6b90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3fc74edd965431d8c47c1cbe909030e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9293830855a471bbccc471c43e3143d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"50ac0bd9971f462fbf9b4c7d5fc0024f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bbb4478b93fa4e66a05ff86b630d583a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49168f0f15ab4a6b9816cacc6f6a68a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39bccbe411fc44f8b994625e0287f725":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02b974dac0e147e6bf2172b98cecc054","IPY_MODEL_3e396691527542949b0b7430c2cb2b1a","IPY_MODEL_b7605436aee740de9b7b5e814b7a610e"],"layout":"IPY_MODEL_efa5297fcc624dd89564c1f6376198f8"}},"02b974dac0e147e6bf2172b98cecc054":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93882e600e8343839de30adf344f9ca2","placeholder":"​","style":"IPY_MODEL_93e43276d9af4ef096d49089189ca22e","value":"merges.txt: "}},"3e396691527542949b0b7430c2cb2b1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e7bea3b2a54417c885847ac7e2d19f5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_483638e2bf204fd5b715315ffda8f3c5","value":1}},"b7605436aee740de9b7b5e814b7a610e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e1b723af5c541989c9bfd5337a737f1","placeholder":"​","style":"IPY_MODEL_db1bc0a7b20544a18c8d66d7bec14dec","value":" 456k/? [00:00&lt;00:00, 35.2MB/s]"}},"efa5297fcc624dd89564c1f6376198f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93882e600e8343839de30adf344f9ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93e43276d9af4ef096d49089189ca22e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e7bea3b2a54417c885847ac7e2d19f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"483638e2bf204fd5b715315ffda8f3c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e1b723af5c541989c9bfd5337a737f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db1bc0a7b20544a18c8d66d7bec14dec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c07e0e2a6dfd478aaa38b9b738621afb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c74f626b258a4361a035319338bca01d","IPY_MODEL_65b1d9cb7b344951b91af0fbd750d857","IPY_MODEL_7a23e3c39f714009974248a3406e6fd7"],"layout":"IPY_MODEL_118fa81936254b068d58f45c47bf839f"}},"c74f626b258a4361a035319338bca01d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f51ae58675264f2e95980ded68f30c7d","placeholder":"​","style":"IPY_MODEL_7d6d5fb5831f45a1a574091c2509a40b","value":"special_tokens_map.json: 100%"}},"65b1d9cb7b344951b91af0fbd750d857":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d81798bb9e9647cc87352158870359f7","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a933c4d0b6694e9a880df41e8b49d6d8","value":239}},"7a23e3c39f714009974248a3406e6fd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_309e84dda8c64f05a97b59b48d71ca4e","placeholder":"​","style":"IPY_MODEL_2df0d38791ef43cda3bc6b11c748f662","value":" 239/239 [00:00&lt;00:00, 31.2kB/s]"}},"118fa81936254b068d58f45c47bf839f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f51ae58675264f2e95980ded68f30c7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d6d5fb5831f45a1a574091c2509a40b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d81798bb9e9647cc87352158870359f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a933c4d0b6694e9a880df41e8b49d6d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"309e84dda8c64f05a97b59b48d71ca4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2df0d38791ef43cda3bc6b11c748f662":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70b2eebe64c6492093737736decb4fcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78942584b19649be9a6e3bfe54199977","IPY_MODEL_64d33a84656e437fb90655e8db5c0d4a","IPY_MODEL_80bd089020bd4a35b96f64bbce76388e"],"layout":"IPY_MODEL_989b32489c564282bebaf589f0640ace"}},"78942584b19649be9a6e3bfe54199977":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4198efb8d81c4b67bc7444a93772301b","placeholder":"​","style":"IPY_MODEL_e811061ffb8b4f8fb483933d8454b48f","value":"pytorch_model.bin: 100%"}},"64d33a84656e437fb90655e8db5c0d4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ebe7b9da3447b9918a73c23aa385b5","max":501045531,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db98a8c9e85647428a55abfcfadf85d4","value":501045531}},"80bd089020bd4a35b96f64bbce76388e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fc5ab35374a4aa2a6f904f06555660d","placeholder":"​","style":"IPY_MODEL_e7c858e2e1524281a6a474afee2656f1","value":" 501M/501M [00:02&lt;00:00, 434MB/s]"}},"989b32489c564282bebaf589f0640ace":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4198efb8d81c4b67bc7444a93772301b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e811061ffb8b4f8fb483933d8454b48f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6ebe7b9da3447b9918a73c23aa385b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db98a8c9e85647428a55abfcfadf85d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0fc5ab35374a4aa2a6f904f06555660d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c858e2e1524281a6a474afee2656f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3da3071ec2245c9b474be00e87d5a2f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fd604ff63cc40e0829cc86b3d269ef7","IPY_MODEL_37ea95b8677845ea84265f7195bbdf40","IPY_MODEL_fc0bb09f0f3f4f9888291f310e33579b"],"layout":"IPY_MODEL_82c55bc4e29844cc903493811971cb39"}},"0fd604ff63cc40e0829cc86b3d269ef7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8183a9b57b041e6b7bc12b715560747","placeholder":"​","style":"IPY_MODEL_8d0fa6f790bb4263adecb52f85e355a6","value":"model.safetensors: 100%"}},"37ea95b8677845ea84265f7195bbdf40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f3314158fed41f2a003271befbf5e07","max":500982668,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d095878fea54ab99edd7c7654ec3205","value":500982668}},"fc0bb09f0f3f4f9888291f310e33579b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aee3e4d8bc3747728e3bd7e046d6e018","placeholder":"​","style":"IPY_MODEL_91656a2bae9d4adbb64604491c9d3cdd","value":" 501M/501M [00:02&lt;00:00, 324MB/s]"}},"82c55bc4e29844cc903493811971cb39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8183a9b57b041e6b7bc12b715560747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d0fa6f790bb4263adecb52f85e355a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f3314158fed41f2a003271befbf5e07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d095878fea54ab99edd7c7654ec3205":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aee3e4d8bc3747728e3bd7e046d6e018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91656a2bae9d4adbb64604491c9d3cdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}